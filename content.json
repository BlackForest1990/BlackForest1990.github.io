{"meta":{"title":"黑暗森林","subtitle":"谁是猎物，谁是猎人？","description":"程序&读书","author":"BlackForest1990","url":"https://blackforest1990.github.io","root":"/"},"pages":[{"title":"categories","date":"2023-03-14T09:15:12.000Z","updated":"2023-03-14T09:15:42.088Z","comments":true,"path":"categories/index.html","permalink":"https://blackforest1990.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2023-03-14T08:49:03.000Z","updated":"2023-03-14T08:59:35.881Z","comments":true,"path":"tags/index.html","permalink":"https://blackforest1990.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"main memory","slug":"mainmemory","date":"2024-03-19T03:49:14.000Z","updated":"2024-03-19T06:18:37.638Z","comments":true,"path":"2024/03/19/mainmemory/","link":"","permalink":"https://blackforest1990.github.io/2024/03/19/mainmemory/","excerpt":"","text":"背景 内存是现代计算机系统运行的核心。内存由大量的字节组成，每个字节都有自己的地址。CPU根据程序计数器的值从内存中获取指令。这些指令可能会导致从特定的内存地址进行额外的加载和存储。 我们从讨论与管理内存相关的几个问题开始讨论：基本硬件、符号内存地址与实际物理地址的绑定，以及逻辑地址和物理地址之间的区别。以讨论动态链接和共享库来结束这个blog。 基本硬件 主存储器和内置于处理器中的寄存器是 CPU 可直接访问的唯一通用存储器。有一些机器指令以内存地址作为参数，但没有以磁盘地址作为参数的指令。因此，任何正在执行的指令以及指令正在使用的任何数据都必须位于这些直接访问存储设备之一中。如果数据不在内存中，则必须将其移至内存，然后 CPU 才能对其进行操作。 内置于 CPU 中的寄存器通常在 CPU 时钟周期内可访问。大多数 CPU 可以以每个时钟周期一个或多个操作的速率解码指令并对寄存器内容执行简单操作。而主存储器却不能这样，它是通过内存总线进行访问的。完成内存访问可能需要许多 CPU 时钟周期。在这种情况下，处理器通常需要停顿，因为它没有完成正在执行的指令所需的数据。由于内存访问的频率，这种情况是不可容忍的。解决的方法是在 CPU 和主存储器之间添加快速存储器，通常在 CPU 芯片上以实现快速访问。为了管理内置于 CPU 中的高速缓存，硬件会自动加速内存访问，无需任何操作系统控制。 我们不仅关注访问物理内存的相对速度，还必须确保正确操作。为了正确运行系统，我们必须保护操作系统免受用户进程的访问。在多用户系统中，我们还必须保护用户进程免受彼此的影响。这种保护必须由硬件提供，因为操作系统通常不会介入 CPU 和其内存访问之间（由于所产生的性能损失）。 首先，我们需要确保每个进程都拥有单独的内存空间。为了分隔内存空间，我们需要确定进程可以访问的合法地址范围，并确保进程只能访问这些合法地址。我们可以通过使用两个寄存器来提供这种保护，通常是一个基址寄存器和一个限界寄存器。基址寄存器保存最小的合法物理内存地址；限界寄存器指定了地址范围的大小。例如，如果基址寄存器保存了 300040，而限界寄存器是 120900，那么程序可以合法地访问从 300040 到 420939（包括边界）的所有地址。 通过让 CPU 硬件将用户模式下生成的每个地址与寄存器进行比较来实现对内存空间的保护。任何在用户模式下执行的程序企图访问操作系统内存或其他用户内存的尝试都会导致陷阱（trap）到操作系统，操作系统会将该尝试视为致命错误。这种方案可以防止用户程序修改操作系统或其他用户的代码或数据结构。 base和limit寄存器只能由操作系统加载，而操作系统使用特殊的特权指令进行加载，特权指令只能在内核模式下执行。该方案允许操作系统更改寄存器的值但不允许用户程序去修改。 在内核模式下执行的操作系统对操作系统内存和用户内存都具有无限制的访问权限。这项规定允许操作系统将用户程序加载到用户内存中，以便在出现错误时将这些程序卸载，访问和修改系统调用的参数，与用户内存进行 I/O 操作，并提供许多其他服务。例如，考虑一个多处理系统的操作系统必须执行上下文切换，在将下一个进程的上下文从主内存加载到寄存器之前，将一个进程的状态从寄存器存储到主内存中。 地址绑定 通常，一个程序以二进制可执行文件的形式存在于磁盘上。要执行该程序，必须将其加载到内存中，并放置到一个进程内。根据所使用的内存管理方式，在执行过程中，该进程可能会在磁盘和内存之间移动。等待被加载到内存以供执行的磁盘上的进程形成输入队列。正常的单任务处理过程是从输入队列中选择一个进程，并将该进程加载到内存中。随着进程的执行，它会从内存中访问指令和数据。最终，进程终止，其内存空间被声明为空闲。 大多数系统允许用户进驻驻留在物理内存的任何部分。因此，尽管计算机的地址空间可能从00000开始，但用户进程的第一个地址不一定是00000。 在大多数情况下，用户程序在执行前经历几个步骤：在这些步骤中，地址可以用不同方式表示。源程序中的地址通常是符号的(count), 编译器通常讲这些符号地址绑定到可重定位地址。(例如“从这个模块开头的14字节”)。链接器又将可重定向地址绑定到绝对地址(例如74014)。每个绑定都是从一个地址空间到另一个地址空间的映射。 传统上，指令和数据与内存地址的绑定可以在沿途的任何步骤中完成： 编译时：如果在编译时知道进程将驻留在内存中的位置，则可以生成绝对代码。 加载时：如果在编译时不知道进程将驻留在内存中的位置，则编译器必须生成可重定向代码。在这种情况下，最终的绑定被延迟到加载时。如果起始地址发生变化，我们只需要重新加载用户代码以将此更改的值纳入其中。 执行时：如果进程在执行过程中可以从一个内存段移动到另一个内存段，则绑定必须延迟到运行时。为了使这种方案正常工作，必须有特殊的硬件可用。大多数通用操作系统采用这种方案。 逻辑空间与物理空间 CPU生成的地址通常成为逻辑地址，而被内存单元看到的地址–即加载到内存地址寄存器中的地址–通常被称为物理地址。 编译时和加载时地址绑定方法生成相同的逻辑地址和物理地址。然而，执行时地址绑定方案导致不同的逻辑地址和物理地址。在这种情况下，我们通常将逻辑地址称为虚拟地址。在本文中，我们将逻辑地址和虚拟地址互换使用。由程序生成的所有逻辑地址的集合称为逻辑地址空间。与这些逻辑地址对应的所有物理地址的集合称为物理地址空间。 虚拟地址到物理地址的运行时映射是由称为内存管理单元（MMU）的硬件设备完成的。目前，我们将用一个简单的 MMU 方案来说明这种映射。现在，基址寄存器被称为重定位寄存器。在将用户进程生成的每个地址发送到内存时，重定位寄存器中的值会被添加到该地址上。例如，如果基址是 14000，那么用户试图访问位置 0 将被动态重定位到位置 14000；访问位置 346 将被映射到位置 14346。 用户程序永远不会看到真实的物理地址。程序可以创建一个指向位置 346 的指针，将其存储在内存中，对其进行操作，并将其与其他地址进行比较——所有这些都是作为数字 346。只有当它被用作内存地址（例如在间接加载或存储中）时，它才相对于基址寄存器进行重定位。用户程序处理逻辑地址。内存映射硬件将逻辑地址转换为物理地址。被引用的内存地址的最终位置直到引用被执行时才确定。 现在我们有两种不同类型的地址：逻辑地址（在范围 0 到 max 内）和物理地址（对于基址值 R，范围为 R + 0 到 R + max）。用户程序仅生成逻辑地址，并认为进程在位置 0 到 max 运行。然而，在使用这些逻辑地址之前，它们必须映射到物理地址。将逻辑地址空间绑定到单独的物理地址空间的概念是正确的内存管理的核心。 动态加载 到目前为止，在我们的讨论中，为了执行进程，进程的整个程序和所有数据都必须在物理内存中。因此，进程的大小被限制为物理内存的大小。为了获得更好的内存空间利用率，我们可以使用动态加载。使用动态加载，直到调用时才加载例程。所有例程以可重定位的加载格式保存在磁盘上。主程序被加载到内存中并执行。当一个例程需要调用另一个例程时，调用例程首先检查另一个例程是否已加载。如果没有，就调用可重定位链接加载器将所需的例程加载到内存中，并更新程序的地址表以反映此更改。然后控制传递给新加载的例程。 动态加载的优点是只有在需要时才加载例程。当需要大量代码来处理不经常发生的情况时，例如错误例程时，这种方法特别有用。在这种情况下，虽然总程序大小可能很大，但使用的部分（因此加载的部分）可能要小得多。 动态加载不需要操作系统的特殊支持。将程序设计为利用这种方法是用户的责任。然而，操作系统可能通过提供库例程来实现动态加载，从而帮助程序员。 动态链接和共享库 动态链接库是系统库，当用户程序运行时，它们会被链接到用户程序。一些操作系统仅支持静态链接，其中系统库被视为任何其他对象模块，并由加载程序合并到二进制程序图像中。相比之下，动态链接类似于动态加载。在这里，链接而不是加载被推迟到执行时期。此功能通常与系统库一起使用，例如语言子例程库。如果没有此功能，系统上的每个程序都必须在可执行映像中包含其语言库的副本。这个要求浪费了磁盘空间和主内存。 使用动态链接，每个库例程引用都包含在映像中的一个存根stub。存根是一小段代码，指示如何定位适当的内存驻留库例程，或者如何加载库，如果例程尚未存在的话。当存根执行时，它会检查所需的例程是否已经在内存中。如果没有，程序将例程加载到内存中。无论哪种方式，存根都将自身替换为例程的地址并执行该例程。因此，下一次达到特定的代码段时，库例程将直接执行，动态链接不会产生任何成本。在这个方案下，使用语言库的所有进程只执行一份库代码的副本。 **这个特性可以扩展到库的更新（如修复错误）。一个库可以被一个新版本替换，所有引用该库的程序将自动使用新版本。**如果没有动态链接，所有这些程序都需要重新链接才能访问新的库。为了防止程序意外执行新的不兼容版本的库，版本信息被包含在程序和库中。一个库的多个版本可能被加载到内存中，每个程序使用它的版本信息来决定使用哪个库副本。因此，只有使用新库版本编译的程序才会受到其中包含的任何不兼容更改的影响。在安装新库之前链接的其他程序将继续使用旧库。这个系统也被称为共享库。 与动态加载不同，动态链接和共享库通常需要操作系统的帮助。如果内存中的进程相互保护，则操作系统是唯一能够检查所需例程是否在另一个进程的内存空间中或允许多个进程访问相同内存地址的实体。 交换 一个进程必须在内存中执行。然而，一个进程可以暂时交换到后备存储中去，然后再次被带回内存继续执行。交换使得所有进程的总物理地址空间可以超过系统的真实内存，从而增加了多道程序设计的程度。 标准交换 标准交换涉及将进程在主内存和后备存储之间移动。后备存储通常是一个快速磁盘。它必须足够大，以容纳所有用户的所有内存镜像的副本，并且必须提供对这些内存镜像的直接访问。系统维护一个准备队列，其中包含所有内存镜像位于后备存储或内存中且准备运行的进程。每当 CPU 调度程序决定执行一个进程时，它就会调用调度程序。调度程序检查队列中的下一个进程是否在内存中。如果不是，并且没有空闲的内存区域，调度程序就会将当前在内存中的一个进程换出，并换入所需的进程。然后，它重新加载寄存器并将控制转移到所选的进程。 交换时间的主要开销在传输上。标准的交换在现代操作系统中不再使用。它需要太长的交换时间，提供的执行时间太少，无法成为合理的内存管理解决方案。然而，修改过的交换版本在许多系统上都可以找到，包括 UNIX、Linux 和 Windows。在一个常见的变体中，交换通常被禁用，但如果空闲内存的量（供操作系统或进程使用的未使用内存）低于一个阈值时，交换将开始。当空闲内存的量增加时，交换将停止。另一个变体涉及交换进程的部分而不是整个进程，以减少交换时间。通常，这些修改过的交换形式与虚拟内存一起使用。 移动系统交换 尽管大多数 PC 和服务器的操作系统支持某种修改过的交换版本，但移动系统通常不支持任何形式的交换。移动设备通常使用闪存而不是更宽敞的硬盘作为它们的持久存储。由此产生的空间限制是移动操作系统设计者避免交换的原因之一。其他原因包括闪存在变得不可靠之前所能容忍的有限写入次数，以及这些设备中主内存与闪存之间的低吞吐量。 当空闲内存下降到一定阈值以下时，苹果的iOS不使用交换，而是要求应用程序自愿释放分配的内存。只读数据（例如代码）从系统中删除，并在需要时从闪存中重新加载。已修改的数据（例如堆栈）永远不会被删除。然而，任何未能释放足够内存的应用程序可能会被操作系统终止。 Android 不支持交换，并采用了类似 iOS 的策略。如果内存不足，它可能会终止一个进程。然而，在终止进程之前，Android 会将其应用程序状态写入闪存，以便可以快速重新启动。 由于这些限制，移动系统的开发人员必须谨慎地分配和释放内存，以确保他们的应用程序不会使用过多的内存或遭受内存泄漏的问题。请注意，iOS 和 Android 都支持分页，因此它们确实具有内存管理能力。 连续内存分配 主内存必须容纳操作系统和各种用户进程。因此，我们需要以尽可能高效的方式分配主内存。本节将解释一种早期的方法，连续内存分配。 内存通常分为两个分区：一个用于驻留操作系统，另一个用于用户进程。我们可以将操作系统放置在低内存或高内存中。影响此决定的主要因素是中断向量的位置。由于中断向量通常位于低内存中，程序员通常也将操作系统放置在低内存中。 我们通常希望多个用户进程同时驻留在内存中。因此，我们需要考虑如何将可用内存分配给等待被载入内存的进程。在连续内存分配中，每个进程都包含在内存的一个单独部分中，该部分与包含下一个进程的部分相邻。 内存保护 在进一步讨论内存分配之前，我们必须讨论内存保护的问题。通过结合之前讨论过的两个想法，我们可以防止一个进程访问它不拥有的内存。如果我们有一个具有重定位寄存器和一个限制寄存器的系统，我们就可以实现我们的目标。重定位寄存器包含最小物理地址的值；限制寄存器包含逻辑地址的范围（例如，重定位 = 100040，限制 = 74600）。每个逻辑地址必须落在限制寄存器指定的范围内。内存管理单元（MMU）通过将重定位寄存器中的值添加到逻辑地址来动态地映射逻辑地址。这个映射地址被发送到内存。 当CPU调度程序选择一个进程进行执行时，调度程序作为上下文切换的一部分将重定位和限制寄存器加载为正确的值。因为CPU生成的每个地址都会与这些寄存器进行比较，所以我们可以保护操作系统和其他用户的程序和数据，防止该运行进程对其进行修改。 重定位寄存器方案提供了一种有效的方法来允许操作系统的大小动态变化。这种灵活性在许多情况下都是可取的。例如，操作系统包含设备驱动程序的代码和缓冲区空间。如果一个设备驱动程序（或其他操作系统服务）不常用，我们不希望保留代码和数据在内存中，因为我们可能能够将该空间用于其他用途。因此，在程序执行期间使用此代码会改变操作系统的大小。 内存分配 现在我们准备转向内存分配。一种最简单的内存分配方法是将内存分成几个固定大小的分区。每个分区可能包含一个进程。因此，多道程序设计的程度受到分区数量的限制。在这种多分区方法中，当一个分区为空闲时，从输入队列中选择一个进程，并将其加载到空闲分区中。当进程终止时，该分区变为另一个进程可用。这种方法现在已不再使用。接下来描述的方法是固定分区方案的一种泛化（称为MVT）；它主要用于批处理环境。这里提出的许多想法也适用于使用纯分段进行内存管理的分时环境。 在可变分区方案中，操作系统维护一张表，指示内存的哪些部分是可用的，哪些是占用的。最初，所有内存都可用于用户进程，并被视为一个可用内存的大块，一个空闲块。随着你将会看到的，内存最终包含了一组不同大小的空闲块。 当进程进入系统时，它们被放置在一个输入队列中。操作系统考虑每个进程的内存需求以及可用内存空间的数量，以确定哪些进程被分配内存。当一个进程被分配空间时，它被加载到内存中，然后可以竞争CPU时间。当一个进程终止时，它释放其内存，操作系统随后可以用来填充输入队列中的另一个进程。 因此，在任何给定时间，我们都有一个可用块大小的列表和一个输入队列。操作系统可以根据调度算法对输入队列进行排序。内存被分配给进程，直到最终无法满足下一个进程的内存需求为止，也就是说，没有足够大的可用内存块（或空闲块）来容纳该进程。然后，操作系统可以等待直到有足够大的块可用，或者可以跳过输入队列，看看是否可以满足其他一些进程的较小内存需求。 通常情况下，正如前面提到的，可用的内存块包括散布在整个内存中的一组不同大小的空闲块。当一个进程到达并需要内存时，系统会在这组空闲块中搜索一个足够大的空闲块来容纳该进程。如果空闲块太大，它将被分成两部分。一部分分配给到达的进程；另一部分则返回到空闲块集合中。当一个进程终止时，它释放其内存块，然后将其放回到空闲块集合中。如果新的空闲块与其他空闲块相邻，则这些相邻的空闲块将合并成一个更大的空闲块。此时，系统可能需要检查是否有等待内存的进程，以及这些新释放和合并的内存是否能够满足任何一个等待中的进程的需求。 这个过程是一种特殊情况，涉及到如何从一组空闲块中满足大小为n的请求的一般动态存储分配问题。对于这个问题有很多解决方案。首次适应、最佳适应和最坏适应策略是从可用空闲块集合中选择一个空闲块的最常用方法。 • 首次适应。分配第一个足够大的空闲块。搜索可以从空闲块集合的开头开始，也可以从上次首次适应搜索结束的位置开始。一旦找到一个足够大的空闲块，我们就可以停止搜索。 • 最佳适应。分配最小的足够大的空闲块。除非列表按大小排序，否则我们必须搜索整个列表。该策略产生的剩余空闲块最小。 • 最坏适应。分配最大的空闲块。同样，除非列表按大小排序，否则我们必须搜索整个列表。该策略产生的剩余空闲块最大，可能比最佳适应方法产生的较小剩余空闲块更有用。 模拟结果表明，在减少时间和存储利用方面，首次适应和最佳适应都优于最坏适应。在存储利用方面，首次适应和最佳适应都没有明显的优势，但是首次适应通常速度更快。 内存碎片化 首次适应和最佳适应的内存分配策略都存在外部碎片问题。随着进程被加载到内存中并从内存中移除，空闲内存空间被分割成小块。当总内存空间足够满足请求，但可用空间不连续时，就存在外部碎片化：存储被分割成大量小块。这种碎片化问题可能非常严重。在最坏的情况下，我们可能在每两个进程之间都有一块空闲（或浪费的）内存。如果所有这些小块内存都在一个大的空闲块中，我们可能能够运行更多的进程。 我们使用首次适应还是最佳适应策略都会影响碎片化的程度。另一个因素是空闲块的哪一端被分配。无论使用哪种算法，外部碎片化都将是一个问题。根据总内存存储量和平均进程大小的不同，外部碎片化可能是一个轻微或严重的问题。例如，对首次适应进行统计分析显示，即使进行了一些优化，对于给定的N个分配块，另外的0.5N块将被碎片化浪费。也就是说，有三分之一的内存可能无法使用！这一特性被称为50%规则。 内存碎片化不仅可以是外部的，还可以是内部的。考虑一个带有18,464字节空洞的多分区分配方案。假设下一个进程请求18,462字节。如果我们精确地分配所请求的块，就会剩下2字节的空洞。跟踪这个空洞的开销将远远大于空洞本身。避免这个问题的一般方法是将物理内存分成固定大小的块，并根据块大小单位分配内存。采用这种方法，分配给一个进程的内存可能略大于请求的内存。这两个数字之间的差异就是内部碎片化——分区内部未使用的内存。 解决外部碎片化问题的一个方法是压缩。其目标是重新排列内存内容，以便将所有的空闲内存放在一个大的块中。然而，压缩并非总是可行的。如果重定位是静态的，并且在汇编或加载时进行，那么无法进行压缩。只有在重定位是动态的，并且在执行时进行时才可能。如果地址是动态重定位的，则重定位仅需要移动程序和数据，然后更改基址寄存器以反映新的基址。当压缩是可能的时，我们必须确定其成本。最简单的压缩算法是将所有进程移向内存的一端；所有的空洞向另一个方向移动，产生一个大的可用内存空洞。 解决外部碎片化问题的另一个可能方法是允许进程的逻辑地址空间是非连续的，从而允许进程在任何可用的物理内存中分配内存。两种互补的技术实现了这个解决方案：分段和分页。 分段Segmentation Paging 页表结构 Example: Intel 32 and 64-bit Architectures Example: ARM Architecture","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blackforest1990.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"内存管理","slug":"内存管理","permalink":"https://blackforest1990.github.io/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"}]},{"title":"deadlock","slug":"deadlock","date":"2024-02-19T06:10:57.000Z","updated":"2024-02-19T07:16:09.737Z","comments":true,"path":"2024/02/19/deadlock/","link":"","permalink":"https://blackforest1990.github.io/2024/02/19/deadlock/","excerpt":"","text":"进程死锁算法 死锁问题 死锁问题 例子1：拥有2个磁盘驱动器的系统 假设有两个进程，P1和P2，每个进程持有一个磁盘驱动器，并且它们各自等待另一个进程持有的磁盘驱动器。这种情况创建了一个循环等待，因为P1正在等待P2持有的资源，反之亦然。 ​ ● P1持有磁盘驱动器1，等待磁盘驱动器2。 ​ ● P2持有磁盘驱动器2，等待磁盘驱动器1。 在这种情况下，循环等待条件得到满足，如果其他死锁条件也得到满足，就可能发生死锁。 例子2：信号量A和B，初始值为1 假设有两个信号量A和B，它们的初始值都为1。信号量通常用于控制对资源的访问。如果进程被设计为按照特定顺序获取这两个信号量，并以相反的顺序释放它们，可以防止死锁。然而，如果进程不遵循这个协议，就可能发生死锁。 ​ ● 进程P1获取信号量A，然后获取信号量B。 ​ ● 进程P2获取信号量B，然后获取信号量A。 如果P1持有信号量A并等待信号量B，而P2持有信号量B并等待信号量A，就会产生循环等待条件。 这两个例子强调了仔细管理资源的重要性，确保进程以受控的方式请求和释放资源，以避免循环等待和其他死锁条件。预防性的措施，比如仔细分配资源和使用同步机制，有助于减轻系统中死锁的风险。 桥梁交叉问题 桥梁交叉问题是一个经典的死锁场景，用于说明在资源争用的情况下可能发生的问题。这个例子描述了一座只允许单向交通的桥梁，桥上的每个部分都可以看作是一个资源。以下是该问题的一些关键要点： ​ 1. 交通只能单向： 只允许从一个方向通过桥梁，这意味着车辆只能按照特定的方向移动。 ​ 2. 桥上的每个部分是一个资源： 桥上的每个部分都可以被看作是一个独占资源，一次只能由一个车辆使用。 ​ 3. 死锁的解决： 如果发生死锁，可以通过一个车辆后退（放弃资源并回滚）来解决。也就是说，为了打破死锁，系统可以迫使某些车辆回到桥的起点，释放它们占用的资源。 ​ 4. 可能需要多个车辆后退： 如果死锁涉及多个车辆，可能需要多个车辆后退才能解除死锁。 ​ 5. 可能发生饥饿： 在解决死锁的过程中，某些车辆可能被迫多次后退，导致它们无法继续前进，从而可能发生饥饿问题。 在这个场景中，死锁可能发生在多个车辆试图同时通过桥梁的时候，由于资源争夺，它们彼此等待对方释放资源而无法继续前进。解决死锁的方法是引入一些机制，例如强制某些车辆后退，以打破循环等待并释放资源。 这个例子反映了在并发系统中管理资源的复杂性，以确保系统能够避免死锁和饥饿问题。 十字路口问题 在一个有四个停车标志的十字路口，通行权的规则通常旨在防止死锁，确保交通流畅。来自《加利福尼亚驾驶：道路规则和交通法规》的摘录提供了对规则的简明解释： 轮流通行： 驾驶员轮流通过十字路口，顺序是按照他们到达十字路口边缘的顺序。 同时到达： 如果两辆或更多车辆同时到达路口，让车辆靠右的原则生效，按照顺时针的次序通行。换句话说，靠你右边的驾驶员有通行权，先行驶。 特殊情况和谨慎驾驶： 摘录中承认这种方案可能不是绝对可靠的，特别是当四辆车同时到达的情况。在这种情况下，驾驶员需要保持警惕，密切关注，也许与其他驾驶员沟通，协调行车动作，确定谁先通过。 这些通行权规则有助于管理十字路口的交通，降低冲突或死锁的可能性。然而，正如提到的，驾驶员应该保持警惕，并准备适应特定情况，特别是在多辆车同时到达的情况下。沟通、眼神交流和耐心是顺利而安全地通过十字路口的关键因素。 System Model 死锁条件 互斥条件（Mutual Exclusion）： 同一时刻只有一个进程能够使用资源。这意味着资源是排它性的，不能被多个进程同时持有或使用。 持有等待条件（Hold and Wait）： 一个进程持有至少一个资源，并在等待获取其他被其他进程持有的资源。这就创造了一种资源占用和等待的情况，可能导致死锁。 无抢占条件（No Preemption）： 一个资源只能被持有它的进程主动释放，而且只有在该进程完成任务之后才能释放。系统不能强制性地从进程手中取走资源。 循环等待条件（Circular Wait）： 存在一个进程集合 &#123;P0, P1, …, P0&#125;，其中 P0 正在等待被 P1 持有的资源，P1 正在等待被 P2 持有的资源，以此类推，Pn-1 正在等待被 Pn 持有的资源，而 P0 正在等待被 P0 持有的资源。这形成了一个循环等待的环。 这四个条件的同时存在会导致死锁的发生。因此，在设计和管理系统时，通常需要采取措施来防止这些条件同时满足，以减少死锁的风险。这可能涉及到资源分配策略、死锁检测和恢复机制等。 处理死锁的方法 处理死锁的方法主要分为以下三种： 确保系统永远不会进入死锁状态： ​ ● 方法： 通过设计系统或引入合适的算法，以确保系统不会满足死锁发生的四个必要条件。这可能涉及合理的资源分配、资源请求顺序规定等。然而，这样的方法可能会导致系统资源利用率下降，因为它们可能需要较为保守的资源分配策略。 允许系统进入死锁状态，然后进行恢复： ​ ● 方法： 如果死锁已经发生，可以通过检测死锁的存在，选择性地终止一些进程，释放资源，并允许其他进程继续执行。这需要死锁检测和恢复机制，以及相应的策略来决定哪些进程应该被终止。 忽略问题，假装系统中不存在死锁： ​ ● 方法： 一些操作系统采用这种方法，即忽略死锁问题，假装死锁从不发生。这通常是因为死锁发生的频率相对较低，或者实施其他死锁处理方法可能导致系统过于保守，影响性能。虽然这是一种简单的方法，但也可能导致死锁时系统无法预测的行为。 每种方法都有其优缺点，选择取决于系统的需求、性能要求以及开发人员对死锁问题的处理偏好。在设计系统时，通常需要综合考虑这些方法，以找到适合特定场景的平衡点。 Deadlock Prevention (预防) 限制请求的方式： ​ ● 方法： 通过对进程请求资源的方式进行限制，可以防止死锁的发生。这可能包括对资源请求的顺序、数量或其他约束的限制。 互斥（Mutual Exclusion）： ​ ● 情况： 对于可共享的资源，互斥不是必需的；但对于不可共享的资源，互斥是必需的。 ​ ● 解释： 对于可共享的资源，多个进程可以同时持有，而对于不可共享的资源，只能由一个进程持有。这是死锁预防的一种方法。 持有和等待（Hold and Wait）： ​ ● 方法： 确保每当进程请求资源时，它不持有任何其他资源。 ​ ● 方式： 要求进程在开始执行之前请求并分配其所有资源，或者只允许进程在没有任何资源时请求资源（在请求任何其他资源之前释放所有当前资源）。 ​ ● 问题： 这可能导致资源利用率较低，且可能导致饥饿问题。 无抢占（No Preemption）： ​ ● 方法： 如果一个进程持有一些资源并请求另一个不能立即分配的资源，那么释放所有当前持有的资源。 ​ ● 操作： 被抢占的资源被添加到进程正在等待的资源列表中，只有在进程能够重新获得其旧资源以及新请求的资源时，才会重新启动该进程。 循环等待（Circular Wait）： ​ ● 方法： 强制对所有资源类型进行总排序，并要求每个进程按递增顺序枚举请求资源。 ​ ● 示例： 对于三种资源类型（磁带驱动器、磁盘驱动器和打印机），给定的排序如下： ​ i. F(tape drive) = 1 ​ ii. F(disk drive) = 5 ​ iii. F(printer) = 12 这些方法共同旨在通过限制资源的获取方式来防止死锁的发生。在设计系统时，选择适当的死锁预防策略可能取决于系统的性质和需求。 Deadlock Avoidance (避免) **死锁避免（Deadlock Avoidance）**是一种需要系统具有额外的先验信息的方法。其中，最简单且最有用的模型要求每个进程声明可能需要的每种类型资源的最大数量。死锁避免算法动态地检查资源分配状态，以确保永远不会发生循环等待条件。资源分配状态由可用资源数量、已分配资源数量以及进程对资源的最大需求定义。 具体而言，这个模型的主要特点包括： 先验信息： 每个进程在运行之前声明其可能需要的每种资源类型的最大数量。这是系统在运行时用于进行死锁避免的关键信息。 资源分配状态： 资源分配状态通过以下方面来定义： ​ ● 可用资源数量： 表示当前系统中未被任何进程占用的资源数量。 ​ ● 已分配资源数量： 表示已经被分配给进程的资源数量。 ​ ● 进程对资源的最大需求： 表示每个进程可能在未来请求的最大资源数量。 动态检查： 死锁避免算法会动态地检查资源分配状态，以确保不会形成循环等待条件。这意味着系统会根据当前的资源分配状态来判断是否允许某个进程继续请求资源，以防止死锁的发生。 总体而言，死锁避免方法试图在运行时动态地管理资源分配，以确保系统不会陷入死锁状态。这需要对资源需求和分配状态进行仔细的监测和控制。 Safe State 一个系统处于“安全状态（Safe State）”是指当一个进程请求一个可用资源时，系统必须决定是否立即分配该资源将系统置于安全状态。系统被认为处于安全状态，如果存在系统中所有进程的一个序列 &lt;P1, P2, …, Pn&gt;，使得对于每个进程 Pi，Pi 目前仍然可以请求的资源可以通过当前可用资源 + 所有 Pj 持有的资源来满足，其中 j &lt; i。 具体来说： ​ ● 如果进程 Pi 的资源需求当前不可用，那么 Pi 可以等待，直到所有 Pj 完成。 ​ ● 当 Pj 完成时，Pi 可以获取所需的资源，执行任务，释放分配的资源，然后终止。 ​ ● 当 Pi 终止时，Pi+1 可以获取其所需的资源，以此类推。 这种安全状态的概念是为了确保在系统进行资源分配时，不会出现死锁。通过仔细管理资源分配，系统可以保持在一个能够支持进程继续执行的状态，而不会进入死锁状态。在实际实现中，系统可能需要使用一些算法和数据结构来动态地维护和检查安全状态。 死锁避免算法 死锁避免算法通常分为两种情况，具体取决于资源类型的实例数： 单一实例的资源类型： ​ ● 算法： 在这种情况下，通常使用资源分配图（Resource Allocation Graph）来进行死锁避免。资源分配图是一个图形化表示，其中包含进程和资源之间的关系，通过请求边和分配边表示。通过分析图中的循环等待条件，可以预防死锁的发生。 多个实例的资源类型： ​ ● 算法： 在这种情况下，通常使用银行家算法（Banker’s Algorithm）。银行家算法是一种死锁避免的动态资源分配算法，它基于预先提供的信息（每个进程的最大资源需求）来判断在分配资源的情况下系统是否保持在安全状态。 ​ ● 原理： 银行家算法维护一个安全序列，该序列表示进程可以按顺序获取资源而不导致死锁。当一个进程请求资源时，系统模拟分配资源并检查是否仍然存在安全序列。如果存在，系统将实际分配资源；否则，请求将被推迟，直到满足安全性条件。 这两种算法分别适用于不同情况下的死锁避免。资源分配图适用于单一实例的资源类型，而银行家算法适用于多个实例的资源类型，其中有额外的信息可用于决策资源分配。选择适当的算法取决于系统的需求、资源类型和性能要求。 资源分配图方案（Resource-Allocation Graph Scheme） 通常用于表示系统中的资源分配情况和进程之间的关系。以下是关于资源分配图方案中一些关键元素的说明： 声明边（Claim Edge）： ​ ● 表示为 Pi → Rj，其中 Pi 表示进程，Rj 表示资源。 ​ ● 用虚线表示。 ​ ● 意味着进程 Pj 可能会请求资源 Rj。 请求边（Request Edge）： ​ ● 当进程请求资源时，声明边（Claim Edge）会转换为请求边。 ​ ● 表示为 Pi → Rj 的实线边。 ​ ● 表示进程 Pi请求资源 Rj。 分配边（Assignment Edge）： ​ ● 当资源被分配给进程时，请求边会转换为分配边。 ​ ● 表示为 Rj → Pi 的实线边。 ​ ● 表示资源 Rj 已被分配给进程 Pi。 释放资源： ​ ● 当进程释放资源时，分配边会重新转换为声明边（Claim Edge）。 ​ ● 表示资源 Rj 又可供其他进程请求。 资源的先验声明： ​ ● 系统中资源必须在先验声明（a priori）的情况下进行。 ​ ● 意味着在系统运行之前，资源的分配关系需要被预先声明。 这种资源分配图方案通常用于可视化和分析系统中的资源分配情况，特别是在处理死锁的上下文中。通过观察图中的边的转换，可以更好地理解进程之间的资源请求、分配和释放关系，从而有助于死锁的预防和管理。 银行家算法 银行家算法是一种用于死锁避免的动态资源分配算法。以下是银行家算法的基本假设： 多个实例： ​ ● 系统中存在多个资源实例，即每种类型的资源有多个实例可用。 先验声明最大需求： ​ ● 每个进程在运行之前必须先声明对每种类型资源的最大需求量。这是系统在运行时判断资源分配是否安全的关键信息。 请求资源可能需要等待： ​ ● 当一个进程请求资源时，如果系统当前无法满足其需求，进程可能需要等待，直到资源可用。 进程获取所有资源后有限时间内释放： ​ ● 当一个进程获得了其所需的所有资源后，它必须在有限的时间内释放这些资源。这确保了资源不会永远被某个进程占用，有助于避免死锁。 基于这些假设，银行家算法通过动态地检查每个进程的资源请求，判断系统是否能够保持安全状态，即是否存在一个安全序列，以确保没有死锁发生。算法基于以下原则： ● 安全状态判断： 如果进程请求资源后系统仍然能够找到一个安全序列，那么系统允许分配资源；否则，请求将被推迟，直到系统能够找到安全序列。 银行家算法的目标是防止死锁，同时尽可能满足进程的资源请求。这种方法需要维护有关进程和资源状态的信息，并根据这些信息做出动态决策，以确保系统的安全性。 数据结构 银行家算法需要维护一些关键的数据结构来进行动态的资源分配和死锁避免。以下是银行家算法中使用的主要数据结构： Available（可用资源向量）： ​ ● 类型：向量（Vector）。 ​ ● 长度：m，表示系统中每种资源类型的实例数。 ​ ● 意义：如果 Available[j] = k，则表示系统中有k个资源实例可用于资源类型Rj。 Max（最大需求矩阵）： ​ ● 类型：矩阵。 ​ ● 大小：n x m，其中n是进程数，m是资源类型数。 ​ ● 意义：如果 Max[i, j] = k，则表示进程Pi最多可能请求资源类型Rj的k个实例。 Allocation（分配矩阵）： ​ ● 类型：矩阵。 ​ ● 大小：n x m。 ​ ● 意义：如果 Allocation[i, j] = k，则表示进程Pi当前被分配了k个资源类型Rj的实例。 Need（需求矩阵）： ​ ● 类型：矩阵。 ​ ● 大小：n x m。 ​ ● 意义：如果 Need[i, j] = k，则表示进程Pi可能需要额外的k个资源类型Rj来完成其任务。 ​ ● 计算方式：Need[i, j] = Max[i, j] - Allocation[i, j]。 这些数据结构通过动态地跟踪系统中的资源状态和进程的需求，使银行家算法能够在运行时进行资源分配决策。通过比较 Need 和 Available 的值，算法可以判断是否可以满足某个进程的资源请求，以及该分配是否安全，从而避免死锁。 安全性算法 这是安全性算法的基本步骤，用于判断系统是否处于安全状态。这个算法用于银行家算法中，确保在动态分配资源的过程中系统不会陷入死锁。以下是步骤的详细解释： ​ 1. 初始化： ​ ● 让 Work 和 Finish 分别是长度为 m 和 n 的向量，其中 m 是资源类型的数量，n 是进程的数量。 ​ ● 初始化 Work 为 Available 向量的副本。 ​ ● 初始化 Finish[i] 为 false，表示没有进程已经完成。 ​ 2. 查找满足条件的进程 i： ​ ● 找到一个进程 i，使得： ​ ○ (a) Finish[i] = false（该进程尚未完成）。 ​ ○ (b) Need[i] ≤ Work（该进程的需求可以被当前可用资源满足）。 ​ ● 如果不存在这样的 i，则转到步骤 4。 ​ 3. 更新 Work 和 Finish： ​ ● 更新 Work 为 Work + Allocation[i]（释放资源给进程 i）。 ​ ● 将 Finish[i] 设置为 true，表示进程 i 已经完成。 ​ ● 返回到步骤 2，继续查找下一个满足条件的进程。 ​ 4. 检查所有进程是否都完成： ​ ● 如果 Finish[i] == true 对于所有 i（即，所有进程都已完成），则系统处于安全状态。 这个算法通过动态地模拟资源分配和释放的过程，以及进程的状态变化，来判断系统是否保持在一个安全状态。如果所有进程都能够完成并释放资源，那么系统被认为是安全的。这有助于避免潜在的死锁情况。 Deadlock Detection 等待图（wait-for graph） 在每个资源类型只有单个实例的情况下，可以使用等待图（wait-for graph）来检测死锁。以下是一些关键的步骤： 等待图的构建： ​ ● 节点： 图的节点表示进程。每个进程都是一个节点。 ​ ● 边： 如果进程 Pi 正在等待进程 Pj，那么在等待图中就有一条边 Pi → Pj。 定期检测循环： ​ ● 周期性地调用一个算法，该算法在等待图中搜索循环。如果存在循环，说明存在死锁。 循环检测算法： ​ ● 使用图论算法（例如深度优先搜索）来检测等待图中是否存在循环。如果找到了一个循环，那么系统处于死锁状态。 复杂度注意事项： ​ ● 检测图中循环的算法通常具有较高的时间复杂度，一般为 n^2，其中 n 是图中的节点数。这是因为通常需要遍历图的所有边和节点，寻找可能的循环。 使用等待图的方法是周期性地检查系统是否存在死锁。如果检测到循环，系统可以采取相应的措施来解决死锁，例如中断一个或多个进程，以破坏循环并解除死锁状态。 需要注意的是，尽管等待图是一种直观的死锁检测方法，但在大型系统中，由于其高时间复杂度，可能会导致性能问题。因此，在设计系统时，需要权衡使用这种方法的代价和效益。 深度优先搜索（Depth-First Search，DFS） 深度优先搜索（Depth-First Search，DFS）在死锁检测上的应用。在这里，等待图中的路径表示进程之间的等待关系，例如 P1 → P2 表示进程 P1 正在等待进程 P2。 DFS 是一种图遍历算法，它从起始节点开始，尽可能深入图中每个分支，直到达到最深的节点，然后回溯并探索其他分支。在死锁检测中，DFS 可以用于检查等待图中是否存在循环，从而判断系统是否处于死锁状态。 从您提供的示例中，以下是一些可能的路径： ​ 1. P1 → P2 → P3 → P4 → P1 ​ 2. P1 → P2 → P4 → P1 ​ 3. P1 → P2 → P5 ​ 4. P2 → P3 → P4 → P1 → P2 这些路径代表了等待图中的一些可能的循环。如果 DFS 在遍历等待图的过程中找到了任何形成循环的路径，就可以得出系统存在死锁的结论。 在实际应用中，DFS 可以用于周期性地检测等待图中的循环，从而提前发现潜在的死锁情况并采取相应的措施，例如中断某些进程以解除死锁。 Recovery from Deadlock 进程终止（Process Termination） 在死锁发生后，进程终止（Process Termination）是另一种可行的恢复机制。以下是使用进程终止来解决死锁的一些考虑因素和策略： 终止所有死锁进程： ​ ● 最直接的方法是终止所有死锁进程，释放它们占用的资源。这样可以消除死锁，但代价可能很高，因为它可能中断正在执行的进程。 逐个终止进程： ​ ● 逐个终止死锁进程，直到死锁循环被消除。这种方法更加灵活，可以选择性地中断进程，以最小化影响。 选择终止的顺序： ​ ● 在逐个终止进程的策略中，选择终止的顺序是关键的。以下是一些可能的选择标准： ​ ○ 进程优先级：选择优先级最低的进程。 ​ ○ 计算时间：选择计算时间最长或最短的进程。 ​ ○ 已使用资源：选择已使用资源最多或最少的进程。 ​ ○ 需要资源：选择需要资源最多或最少的进程。 ​ ○ 需要终止的进程数：选择需要终止的进程数最少的进程。 ​ ○ 交互性：考虑进程是交互式还是批处理。 实时性和用户体验： ​ ● 对于实时系统或交互式系统，需要权衡终止进程的紧急性和用户体验。有时可能需要中断对用户体验影响较小的进程。 资源回收： ​ ● 终止进程后，需要回收其使用的资源，以确保它们可供其他进程使用。 选择正确的终止策略和顺序取决于系统的特定要求、性能目标和用户体验。通常需要综合考虑多个因素，以最小化对系统整体性能和用户的影响。 资源抢占（Resource Preemption） 在死锁发生后，**资源剥夺（Resource Preemption）**是一种可能的恢复机制。这包括选择受害者进程，回滚其状态，然后重新启动。以下是相关的步骤和考虑因素： 选择受害者： ​ ● 选择哪个进程成为“受害者”是一个关键决策。通常，选择的标准是最小化代价。 ​ ● 代价可以包括回滚（Rollback）所需的成本，以及对系统整体性能的影响。 回滚操作： ​ ● 回滚是将进程的状态返回到先前的安全状态的过程。 ​ ● 回滚可能涉及释放已分配的资源，将进程状态还原到以前的状态，以及可能的清理工作。 成本因素： ​ ● 考虑到成本因素，选择受害者时需要综合考虑多个方面。可能的成本因素包括：回滚的步骤数。 ​ ○ 已分配资源的数量。 ​ ○ 对系统性能的影响。 ​ ○ 是否存在死锁的频率。 饥饿问题： ​ ● 在资源剥夺的过程中，存在一种可能性，即同一进程可能会一次又一次地成为受害者，导致饥饿问题。 ​ ● 为了解决这个问题，可以引入一些机制，例如在选择受害者时考虑其上一次回滚的次数，以确保资源剥夺是公平的。 实时性： ​ ● 对于实时系统，资源剥夺可能会影响任务的截止日期。因此，需要权衡实时性和系统状态的一致性。 资源剥夺是一种复杂的恢复机制，需要根据系统的需求和性能要求做出谨慎的决策。在实践中，选择合适的受害者和回滚策略是死锁处理中的关键问题。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blackforest1990.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"进程管理","slug":"进程管理","permalink":"https://blackforest1990.github.io/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"如何让英语成为你的工作语言","slug":"如何让英语成为你的工作语言","date":"2024-01-18T02:37:02.000Z","updated":"2024-01-19T02:26:34.766Z","comments":true,"path":"2024/01/18/如何让英语成为你的工作语言/","link":"","permalink":"https://blackforest1990.github.io/2024/01/18/%E5%A6%82%E4%BD%95%E8%AE%A9%E8%8B%B1%E8%AF%AD%E6%88%90%E4%B8%BA%E4%BD%A0%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%AF%AD%E8%A8%80/","excerpt":"","text":"​ 很多时候，使用英文去沟通能成为一个不错的优势，因为国内的内卷和资方过于强势，去跨国公司和外企现在看来是一个不错的选择，如何组织会议，沟通客户和本地员工，是一门很重要的课程。本人做一个在跨国公司7年的老员工，去过很多国家，做过一些英文交流，水平也不高，在这里提出一些自己的想法，共同提高，共同进步。 看美剧不如聊两句 ​ 很多时候从应试教育出来的人，很难把自己变成做应用的人，也即分数思维如何向解决问题思维转变呢，我记得我第一次出差时，去的国家是阿曼的马斯喀特，是阿曼电信聊Uportal的业务，当时准备了很久，说的时候头脑一篇空白，两个服务的兄弟很好，帮助了我很多，后来我就经常跟本地员工去聊业务，最后渐渐英文也流利了起来。 后来我想一想为什么这样的方式能练好英文，第一，固定topic， 第二，你在技术上有优势，心理上有把握， 第三，内容你熟悉，只是转换成英文去说，我认为如果能够采取这样的方式去练习英文，可能进步速度会快一点。 workshop如何hold住全场 ​ 工作中，很多时候你需要去讲你写的slide，作为一名产品经理，给客户提出你的解决方案是最重要的，如何去做呢，首先材料不要求多，一般正式的proposal要求最多20页，按照2min一页的速度去讲解，材料不要求面面俱到，但写在上面的需要正确和能够合理解释。跟客户私下传递也建议打印一份一页key point，写出方案的优劣点。下图为客户与总部专家workshop中交流情况。 ​ 行业上的词汇其实你应该要牢记掌握，如果你技术上的词汇说的不够地道，会降低会议的演示效果，比如我作为一个通信产品经理，以下词汇其实是经常会见到的： 大部分电信的解决方案胶片都有八股文可以炒，先阐述客户集团和子网的数字化战略，然后分析现网情况，再根据现网情况提出菊厂的方案，再阐述菊厂的战略和投入，在说明应用case，如果能做到这样简明清晰，那么就是一篇很好地方案八股文了：） 客户关系呢？ ​ 客户关系是第一生产力，良好的客户关系能够帮助你在商业上获取信息，影响客户的决策链，如何跟客户成为朋友呢？ ​ 首先你首先要在工作上支持你的客户，如果你活干的不好，你大概跟客户成为不了朋友，如果犯了大错，可能还会使客户倒向友商，所以优秀的工作是一切的前提，然后可以请客户吃吃饭，可以在吃饭的时候谈一些工作上的topic，了解一下客户的兴趣爱好，后面，可以进一步跟客户去打高尔夫啊，网球之类的，注意，每一次跟客户交往，你都要准备几个话题，几个无关痛痒的和一些工作上你需要传递的，这样客户跟你在一起既轻松又可以实现突破。 ​ 最后，如果客户邀请你去他家了，这是一个重大的里程碑，这代表你的客户关系达到亲密的等级，在客户家里要注意客户的宗教信仰，人种，文化背景，教育背景，需要得体而同时活泼，这个时候才是客户关系的第一步，所以良好的英文沟通，让客户信任你跟你聊得来，是非常重要滴。 商务谈判如何做 有一本书叫逆势谈判说的很好，谈判不是辩论，不需要巧舌如簧，谈判是寻求合作，沟通能力很重要，所以商务谈判中的英文，需要精准，而不需要很流利，适当留白让大家去思考反而更有助益。 谈判是冲突各方通过设定立场、提出建议、做出取舍,交换价值,并最终达成共识的过程。谈判更多关注的是如何能实现自己的目标，谈判者并不会纠结于谁对谁错。所以在谈判中，关注的不应该是人，而是在于条款，如何通过博弈或者协商规划出一条对于双方有利的条款，非常重要，所以商务谈判中的英语最好做到精准，职业，非情绪化。 总结 最重要的要去说 提前准备topic 客户关系要一步一步做 商务谈判务求精准","categories":[{"name":"经验总结","slug":"经验总结","permalink":"https://blackforest1990.github.io/categories/%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"工作语言","slug":"工作语言","permalink":"https://blackforest1990.github.io/tags/%E5%B7%A5%E4%BD%9C%E8%AF%AD%E8%A8%80/"}]},{"title":"如何建立销售铁军","slug":"如何建立一所销售铁军","date":"2024-01-18T02:36:40.000Z","updated":"2024-01-23T14:55:34.769Z","comments":true,"path":"2024/01/18/如何建立一所销售铁军/","link":"","permalink":"https://blackforest1990.github.io/2024/01/18/%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B%E4%B8%80%E6%89%80%E9%94%80%E5%94%AE%E9%93%81%E5%86%9B/","excerpt":"","text":"本人在华为做过3年的解决方案产品经理，在一家小型环保公司做过市场总监，即做过销售也做过销售leader，如何通过管理手段，锤炼出能打胜仗的铁军呢。 招合适的人 ​ 首先明确你的项目定位，ToB还是ToC的，是IT行业还是传统行业？人才梯度是怎样的，高级销售员是否需要自带资源？如何验证这些资源是否可靠？如果做一个IT行业的ToB的项目，恐怕他的技术能力和对生态的理解是很重要的，如果是做一个环保行业的ToG项目，恐怕他的政策理解和资源能力是很重要的。对于一个销售员如何判断他是否具备自主销售能力？恐怕重点要考察的是他对某一领域的拓展路径，以及遇到种种困难的处理方式。 如下是一些常见的评估销售员的要素： 销售技能： 包括沟通技巧、谈判技能、客户关系管理等方面的能力。 产品知识： 销售人员需要深入了解所销售的产品或服务，以便能够有效地向客户传达价值。 目标达成能力： 评估销售人员是否能够实现销售目标，并在规定时间内完成销售任务。 客户服务： 考察销售人员对客户需求的理解和满足客户期望的能力。 团队合作： 对于团队中的销售人员，评估他们在团队中的合作和协作能力。 销售策略： 能否制定有效的销售策略，并根据市场需求做出调整。 问题解决： 销售人员是否能够迅速而有效地解决客户和销售过程中出现的问题。 市场洞察： 是否具备对市场趋势和竞争情况的敏感性。 这些要素是否对于你的项目都重要？恐怕评估的时候要通过权重的方式去考虑。 制度比拍脑袋重要 ​ 好的销售队伍就是一只好的部队，令行禁止，能打硬仗，赏罚分明，这些都取决于制度建设，可以分为项目维度和客户群维度分开考核，比如菊厂的LTC，立项以后，卷积相关人员，基于项目角度去管理一只队伍，基于项目定期召开项目分析会，同时团队成员的项目奖金包也跟项目贡献相符。基于大客户群的管理，双方有稳固的关系，这个时候就可以成立销售团队去维护这个客户群，梳理出需要突破的关键客户，做团队运作，奖金包也跟这个客户群的销售收入与回款挂钩，格局突破与销售增长还可以定向加倍激励，总之，对于销售制度，激励是一切的基础。 “Leads to Cash”（潜在客户到现金）通常是指从潜在客户（Leads）的阶段开始，通过销售和业务过程，最终将这些潜在客户转化为实际的销售收入或现金。这涉及整个销售和营销生命周期的过程。 以下是“Leads to Cash”过程的一般步骤： 潜在客户（Leads）生成： 通过各种营销活动（如广告、社交媒体、市场活动等），公司吸引并获取潜在客户的信息。 潜在客户资格验证： 对潜在客户的信息进行验证和资格审查，以确保他们是有兴趣的、符合目标市场的潜在客户。 销售线索转化： 将合格的潜在客户转化为销售线索，开始进行个性化的销售活动。 销售活动和谈判： 销售团队与潜在客户互动，进行谈判、演示产品或服务，并解答他们的疑虑。 销售订单生成： 当潜在客户决定购买时，生成销售订单，明确交易的条款和条件。 交付产品或服务： 提供所销售的产品或服务，确保客户满意。 发票和付款： 发送发票，并确保客户按照协议的条件进行支付。 现金收款： 收到客户的支付，并将其转化为公司的现金收入。 整个过程涉及多个团队和部门，包括市场营销、销售、客户服务和财务等。通过有效的“Leads to Cash”流程，企业可以最大程度地优化他们的销售生命周期，提高客户满意度，并实现更好的财务绩效。 ​ 同样，惩罚措施重要吗，很重要，但是不必写入制度，制度上的制订要有灰度，不能轻易去惩罚员工，可以基于事情去批评员工，但是惩罚会使员工流失，不建议。 ​ 通过制度去流动和评判员工，而不是通过领导好恶，销售工作中，业绩是最重要的，同时，项目分析会和总结也需要纳入整体系统评价中，保证销售数据纳入系统。 执行力胜过一切，能抗住强大压力吗？ ​ 很多时候，销售是执行力的艺术，市场是瞬息万变的，强大的执行力和百折不挠的勇气让这支军队更强大，这也是评价销售人员能否晋升的评价因素，一个销售，水平低不怕，但是主管的要求执行不下去，恐怕也是要被淘汰的。回想我的职业生涯，如果能在非洲扛过强大的压力，努力提升自己，现在人生的境况会不同吗？ ​ 对于一线的客户关系，我感觉遗憾还是蛮大的，没有能跟客户在私下里有交往，Rohitash和Dogals我认为我当时真的是有机会发展成我自己的客户，他们对我的印象都挺好，但是当时我并没有主动去做客户关系，这主要还是执行力不够。在一线，我也没有真正去面对压力，总是逃避，造成了压力越来越大，最终崩溃，逃跑，这都是人生的血泪史。汉高于荥阳成皋，光武于昆阳河北，魏武于濮阳官渡，直面压力，才能获得最宝贵的东西。 总结 强大的销售铁军三要素： 合适的人 好的制度 优秀的执行力","categories":[{"name":"经验总结","slug":"经验总结","permalink":"https://blackforest1990.github.io/categories/%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"销售管理","slug":"销售管理","permalink":"https://blackforest1990.github.io/tags/%E9%94%80%E5%94%AE%E7%AE%A1%E7%90%86/"}]},{"title":"电信运营商产品经理复盘","slug":"电信运营商产品经理复盘","date":"2024-01-18T02:36:22.000Z","updated":"2024-01-18T06:07:38.928Z","comments":true,"path":"2024/01/18/电信运营商产品经理复盘/","link":"","permalink":"https://blackforest1990.github.io/2024/01/18/%E7%94%B5%E4%BF%A1%E8%BF%90%E8%90%A5%E5%95%86%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86%E5%A4%8D%E7%9B%98/","excerpt":"","text":"作为一名菊厂曾经的运营商一线产品经理，对于电信运营商的采购流程有一定了解，做为一个高可靠性，重资产项目，如何推进项目，如何立项，投标，如何影响客户决策链，笔者根据自己的项目经验，现做如下总结归纳。 电信运营商组织架构 电信运营商，即网络架设商，比如中国的移动，联通，电信就是此类运营商。根据传输方式，分为固定运营商和移动运营商。 运营商多采用集团-&gt;子网模式经营，因为运营商多在不同国家运营，所以会在每个国家建立子网子公司，由集团统一管理，下图为中国电信的集团与子网。 笔者曾经深度参与过MTN的项目，子网为乌干达，他的集团和子网架构是这样的。 子网话语权是根据收入来的，比如南非子网，他的CEO的权力就很大，集团也不能过多干涉，但是乌干达这个收入少的子网，很多战略上就不能跟基团相悖，基团会在每年Q1确定子网的预算，由子网做预算分析，确定下一年的Capex和Opex，200万美金以内的扩容项目可以在子网执行，搬迁和新建项目都要向基团汇报。 项目组织架构匹配 电信运营商菊厂主要是采用铁三角（AR+SR+FR）管理客户群的，AR为客户关系，SR为解决方案，FR为服务，主要采取层级一一对应。 子网： CEO/CTO -&gt; 系统部部长， CTO/网络Director -&gt; 客户经理和， 工程Director/CTO -&gt; PM/PD/TD, 网络Director -&gt;产品经理 集团也是同样，大T系统部需要按照层级一一对应。 客户网络Director客户画像 Dogals： 本地黑人，穆斯林，英国曼彻斯特大学硕士毕业，在MTN工作12年，为网络规划部 Director，精通核心网 IPcore IPran，团队8人（3人wireless + 3人固定 +2 人核心网），性格上比较绅士，基本上不会投诉，偏向菊厂，关系较好，能够正常出入客户办公室，可以周末去客户家里聚餐，邀请客户打高尔夫。 项目运作 菊厂对于电信项目有传统的三板斧，主要是指邀请客户参观公司总部、邀请客户参加峰会和展会，并与华为的高层形成互动，建立样板点并邀请客户参观，对于Uganda MTN搬迁现网CS，华为的电信云化解决方案，符合MTN集团CTO的数字化转型战略，同时Uganda MTN为经营比较好的子网，客户不吝于技术上的投入，本项目为经典的技术牵引商业。乌干达子网的经营数据如下： “EBITDA” 是 “Earnings Before Interest, Taxes, Depreciation, and Amortization” 的缩写，即利息、税项、折旧和摊销前利润。EBITDA是一种财务指标，用于衡量公司的经营绩效和盈利能力。 该项目具体运作方法如下： 项目 描述 概述 乌干达MTN语音网络设备老旧，已经面临转型，同时语音收入占总体收入一半以上，客户同样要求业务继承性以及交付的稳定性 战略 集团的数字化转型战略为不可逆的行为，现网EOL的设备都会走云化路线，菊厂内部立项，形成代表处-地区部-机关人员构成，确定职责，汇报方式，定期开项目分析会。 邀请客户参观公司总部 邀请子网客户CTO回国，通过跟总部研发和交付人员的密集交流，CTO打消的疑虑，认可了传统电信设备走云化转型的价值，同时对于稳定搬迁核心语音网络有了技术信心 引导发标 子网CTO向南非集团CTO汇报，发标搬迁现网CS网络，通过技术屏蔽了N和Z厂家 方案价值 现网PS云平台扩容，核心网一朵云，管理方便，考虑未来Uganda语音仍在增长，会节省Opex和Capex 标后澄清 跟子网CTO提出扩容割接方案，通过现网PS扩容，多采购一批硬件，用于CS，基于PS的PO启动CS交付，割接了10%的流量上来，现网运行稳定 商务谈判 子网正式中标，集团汇报过会，商务谈判中，对于搬迁部分给与折扣，后续扩容没有影响，考虑硬件部分已经在PS PO中执行完毕，主要优惠部分为客户现网用户license，所以本项目商务较为优秀 客户决策链如下 子网CTO -&gt; 集团CTO -&gt; 子网制作标书-&gt; 集团过会 -&gt; 子网发标 -&gt; 中标 -&gt; 商务谈判 -&gt; 子网采购流程 -&gt; PO 总结 战略永远是最重要的 客户的经营永远是第一驱动力 永远向着议标去努力，如果不行，合同条款是生命线","categories":[{"name":"经验总结","slug":"经验总结","permalink":"https://blackforest1990.github.io/categories/%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"电信运营商","slug":"电信运营商","permalink":"https://blackforest1990.github.io/tags/%E7%94%B5%E4%BF%A1%E8%BF%90%E8%90%A5%E5%95%86/"}]},{"title":"政府的生意怎么做","slug":"政府的生意怎么做","date":"2024-01-18T02:36:03.000Z","updated":"2024-01-22T12:01:28.434Z","comments":true,"path":"2024/01/18/政府的生意怎么做/","link":"","permalink":"https://blackforest1990.github.io/2024/01/18/%E6%94%BF%E5%BA%9C%E7%9A%84%E7%94%9F%E6%84%8F%E6%80%8E%E4%B9%88%E5%81%9A/","excerpt":"","text":"​ 很多时候，政府的生意都很难做，冗长的付款流程和期限，复杂的客户关系，回款风险较大，笔者在从事ToG的环保公司工作了一年，对于ToG领域有一定的了解，现在对于这个领域做出总结，希望能够帮到大家。 政府组织架构 ​ 首先确定项目的类型，比如笔者接触了一年的污水处理项目，国内污水处理项目基本分为三种模式，政府自投自建自营，收益为公共事业基金收益；特许经营模式，社会资本购买污水处理项目的特许经营权并获得污水处理厂的物权，特许经营期满移交回政府实施机构或政府指定机构；PPP模式，其中较为典型的模式是社会资本建设污水处理工程，并实施运营，期间获得使用者付费，收回建设投资并获取收收益。 ​ 根据项目性质，确定政府组织结构如下： 中央层级： 国家发展和改革委员会（NDRC，国家发改委）： 负责经济和社会发展规划，可能涉及项目的规划和资金安排。 生态环境部（原环境保护部）： 主管全国范围内的环境保护工作，负责污水治理政策的制定和实施。 水利部： 负责水资源管理，可能与污水处理项目中的水质、水量等相关事务有关。 住房和城乡建设部： 在城市污水治理项目中可能参与城市基础设施和规划。 地方层级： 省级生态环境厅/局： 在省级范围内负责环境保护和污水治理工作。 地市级生态环境局： 在地市级别进行具体的环境监管和治理工作，包括污水处理。 水务局： 在地方层级，水务局可能负责水资源管理和水环境保护，与污水处理相关。 城市规划和建设部门： 负责城市基础设施规划和建设，包括城市污水处理设施的规划和建设。 相关协会和研究机构： 中国城市水务协会： 作为一个行业协会，可能参与行业内的交流、合作和标准制定。 中国环境科学研究院等研究机构： 参与环境科学研究，为政府决策提供科学依据。 以上是主要的污水处理方面的组织架构，各级政府机构在负责本级别事务的同时，也执行中央政府的政策和指令。协调各级政府和相关机构之间的合作至关重要，以确保污水治理工作的高效实施。请注意，政府组织架构可能会根据时代和政策的变化而调整。 政府采购流程 政府采购是指政府机关、事业单位、公有制企事业单位以及其他使用财政资金的组织，为了履行职责，通过市场行为获取特定商品和服务的过程。 江苏省财政厅政府采购处日前发布了6张操作流程图，包括公开招标操作流程图、竞争性谈判操作流程图、单一来源操作流程图、邀请招标操作流程图、询价操作流程图、竞争性磋商操作流程图。 这几种招标方式有一些关键区别，主要体现在供应商的选择方式、投标过程以及采购合同的达成方式上。以下是它们的主要区别： 公开招标： 供应商选择： 所有合格的供应商都可以参与，公开竞争。 投标过程： 公开发布招标公告，潜在供应商可以获取招标文件并提交投标文件。 合同达成： 通过公开评标，中标供应商与采购方签订正式合同。 竞争性谈判： 供应商选择： 需要事先确定一些资格供应商，然后邀请其参与谈判。 投标过程： 邀请特定的供应商参与竞争性谈判，谈判过程中商议合同条款。 合同达成： 最终确定中标供应商，签订正式合同。 单一来源： 供应商选择： 仅选择一个供应商，通常因为特殊原因，如技术专业性、专有权等。 投标过程： 直接与选定的供应商进行谈判和洽谈。 合同达成： 签订正式合同。 邀请招标： 供应商选择： 从已有供应商资格名单中邀请特定的供应商参与招标。 投标过程： 邀请特定供应商参与，发放邀请函，供应商提交投标文件。 合同达成： 通过评审确定中标供应商，签订正式合同。 询价： 供应商选择： 向多个供应商发出询价函，通常是小额采购。 投标过程： 供应商提交报价，采购方评审并选择最合适的报价。 合同达成： 签订正式合同。 竞争性磋商： 供应商选择： 事先确定一些资格供应商，然后邀请其参与磋商。 投标过程： 邀请特定的供应商参与，进行竞争性磋商，商议合同条款。 合同达成： 最终确定中标供应商，签订正式合同。 这些方式的选择通常由采购项目的性质、法规规定以及采购方的需求决定。 客户关系 根据做了一年政府部门的项目，我对于B2G的项目有一定的了解，基本逻辑也是按照B2B的方式去做，建立线索，验证线索，线索向机会点转化，客户群管理，投标管理，商务管理，合同管理，与2B最大的差别，2G的项目要求更稳定一些，周期也比2C的项目长，所以项目的稳定性更重要一些。 相比直接硬怼耗精力在“最终客户”上，不如先摸清楚外围生意网络，找到靠谱“中间人”，对于政府资源，总是周围有一圈人的，比如揭阳污水项目，林总在项目中起到的作用就非常大，但是这种模式，基本上销售毛利率不会很高，因为对于你来说始终产生不了关键客户关系。所以总体来说，ToG项目很多时候是在做经销商管理。 对于经销商要建立清晰的合作协议： 制定明确的合作协议，确保协议中包含了双方的权利和责任，包括价格政策、销售目标、付款条款等。合作协议应该能够阐明各方的期望。一旦建立关系，要充分放权，充分沟通，同时制订合理的激励计划和技术支持，形成良性循环。 在建立好完善的经销模式后，商业模式有了正反馈，再考虑去做2G的大项目，即EPC模式：EPC（Engineering Procurement Construction），是指承包方受业主委托，按照合同约定对工程建设项目的设计、采购、施工等实行全过程或若干阶段的总承包。并对其所承包工程的质量、安全、费用和进度进行负责。对于这种模式，交付与付款周期都是大挑战，虽然项目规模大，但是收尾困难，项目初期需要对于招标方的资质，付款能力，领导情况做深入评估，人员高度卷积，客户关系深度管理，该项目虽然盈利水平不高，但是对于公司在行业内的口碑都有正向作用，但是如果不能合理评估项目困难，盲目卷入，可能会造成巨大的灾难性亏损。 ToG客户关系分析 TOG政务市场面对的用户主要是是公务员、事业编人员，这个人群大多是高知人群，从学历、社会地位、经济收入、家庭背景都占有相当的优势。由于在政府工作，习惯政令行事、层级森严、派系林立的环境，工作任务固定、重复性高、失误率低的要求。用户主要可以分为以下4类： 决策人员：树立标杆、体现政绩； 管理人员：做好监管、规避风险； 业务人员：流程规范、操作流畅； 广大群众：减少环节、方便快捷； TOG产品的利益相关方通常比较多，且各自需求不一致。对于乙方公司来讲，决策者的需求当然是最重要的，为了更好表达各干系人的需求，通过下面用户心理需求模型来说明，越往上的需求有优先级别越高。 1. 可靠性 可靠性是政务市场的基本要求，包括：项目能够顺利完成；可靠运维服务；数据安全。另外，政府客户对数据安全可靠特别重视，通常在政务内网，政务外网部署，保障数据安全。如果考虑上云部署，要做好保障数据安全的解决方案。 2. 风险控制 政府工作会对工作进行溯源问责，例如办理过程的记录，系统的操作记录，在发生争议或问题的时候，能够快速定位原因。因此，在产品设计过程要关注风险控制。 3. 体现政绩 驱动决策者来做某个项目，都是基于政策和考评要求。发达地区政府追求标杆项目，其他地区追求地方特色，因此定制化需求就比较多。政府之间经常会有考察学习的活动，经常通过可视化大屏展示政绩成果。大屏展示体现了地方特色，很难做到标准化。 4. 效率提升 效能办会对人员每月进行工作量统计，绩效考核，这个时候如何提升效率就显得尤为重要。 5. 更好的体验 所有的角色都需要更好的体验，但使用系统最多的业务人员和人民群众对体验要求最甚。 不像TOC产品那样，基于收集大量用户数据建立画像，TOG产品更多通过行业分析、客户调研来构建客户画像。通过构建客户画像，有助于精准营销，针对性行业客户特点开展售前营销，也有助于项目需求调研前期的背景分析。 TOG的客户，还具有以下特点： 1. 用户非客户 TOG的客户和某类用户可能之间只存在服务与被服务，监管与被监管的关系。 2. 客户往往是行业专家 客户通常是某个政府行业领域的专家，比如城管局，药监局，交管局等等。这就需要我们去拜访客户之前，对行业有着充分的理解，了解产品需要解决该行业什么痛点，才能够有机会取得客户的信任。 3. 潜在客户难以触达，特别是决策者 因为决策者往往是领导，而除非有特别的关系，或者是客户主动找到我们，领导往往不太容易见到。因此这就更需要我们在关键节点之前，做好充分准备。 4. 客户决策流程较长 政府端通常有一个决策流程，我们能够接触到的，一般是执行者，而执行者往往需要向领导汇报，如果关系到位，可以在关键节点见到决策者，这个时候就需要把握机会，汇报关键内容，争取决策者的信任。预算也是非常关键的因素，弄清楚政府部门在这方面的预算，是至关重要的，预算直接关系着决策的结果。 通过客户画像提供了客户特征信息，了解项目背景。还要了解用户建设该项目的动机和背后存在的痛点的关键环节，基于不同的动机，客户对系统的要求也是很大差别的。 政务用户需求通常是由上而下，上级领导掌握着全部的需求决策权。通过用户心理需求模型，在调研过程要抓住主要核心人物（决策人员）的需求，直接决定着需求调研的成功与否。想尽办法获取最有用的信息，利用现场访谈、观察、查阅资料等方法，可以采用直接了解和曲线了解需求。","categories":[{"name":"经验总结","slug":"经验总结","permalink":"https://blackforest1990.github.io/categories/%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"与虎谋皮","slug":"与虎谋皮","permalink":"https://blackforest1990.github.io/tags/%E4%B8%8E%E8%99%8E%E8%B0%8B%E7%9A%AE/"}]},{"title":"云计算架构设计总结","slug":"云计算架构设计","date":"2024-01-18T02:35:45.000Z","updated":"2024-02-28T05:27:24.843Z","comments":true,"path":"2024/01/18/云计算架构设计/","link":"","permalink":"https://blackforest1990.github.io/2024/01/18/%E4%BA%91%E8%AE%A1%E7%AE%97%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"什么是云计算？美国国家标准与技术协会（NIST）对此有这样一个权威和经典的定义： “所谓云计算，就是这样一种模式，该模式允许用户通过无所不在的、便捷的、按需获得的网络接入到一个可动态配置的共享计算资源池（其中包括了网络设备、服务器、存储、应用以及业务），并且以最小的管理代价或者业务提供者交互复杂度即可实现这些可配置计算资源的快速发放与发布。” 云计算的核心可以用五大基本特征、三种服务模式以及四类部署模式来概括。五大基本特征是：按需获得的自助服务，广泛的网络接入、资源池化、快捷的弹性伸缩以及可计量的服务。三种服务模式为：云基础设施即服务（IaaS），云平台即服务（PaaS），以及云软件即服务（SaaS）。四类部署模式可以划分为：专有云（私有云）、行业云、公有云，以及混合云。 云计算把一个固定CAPEX投入的IT项目变成一个PAYU 的OPEX项目, 因为成本和方案的优势，云计算伴随着企业数字化转型，被越来越看重，如何去做企业云化的架构设计，被讨论的越来越频繁，架构不应该只是考虑技术上的可行性，同时要考虑能否快速迁移，能否进行人员培训提高企业的DevOps能力，能否随着数字化转型成功给企业带来正向收益，这些要素同样需要纳入架构的设计中。无论IT架构如何螺旋式演进，客户价值和驱动力都体现在： 更低的TCO； 更高的业务部署与生命周期管理效率； 更优的业务性能与用户体验。 云计算的商业动力与技术趋势 用户痛点 在传统IT体系架构下，当前企业基础设施建设与运维所面临的核心痛点问题可以总结概括为如下几点。 平均资源利用率及能耗效率低下：各个IT基础设施单部件的选型、数量以及不同部件的组网连接方案均取决于企业IT收集的各业务部门对于IT核心业务处理量需求的预测和规划。同时所有企业IT应用软件、数据库以及中间件软件均采用独占计算、存储和网络资源的烟囱式部署。软件应用与硬件唯一捆绑，不同应用之间无法动态、高效共享相同的计算与存储资源。加之按照摩尔定律不断翻番增长的CPU计算能力已大大超出应用软件对计算资源利用率的同步能力，导致企业IT的平均资源利用率始终处于低于20%的水平。 新业务上线测试周期长，效率低下：企业任何一项新业务上线，从最基础的硬件平台开始，向上逐层延伸至操作系统、中间件、数据库、CRM/ERP/HRM/PDM/Email/UC等各类业务关键软件堆栈，均需要投入IT专业化团队，进行软件安装、调试、功能与性能验证测试、网络配置及修改调整，然后经过若干轮测试、故障及性能稳定性测试定位及重配置和调整之后，才能最终达到期望正式上线运行的成熟度水准。这个过程一般需要长达2至3个月的时间。 资源储备及弹性伸缩能力不足，不具备应对企业IT突发业务高峰处理的能力：针对特定垂直行业短时间内突发性的高流量、高密度业务需求（比如节假日期间对视频网站的突发业务流程冲击），企业内部物理基础设施资源往往无法满足短时间内迅速获取所需资源的需求，以及处置业务高峰过后的资源闲置问题 企业核心信息资产通过个人办公PC/便携外泄的安全风险：部分企业核心信息资产通过员工个人PC电脑或便携设备外泄给竞争对手，对企业竞争力和商业利益带来负面影响。过分严格的信息安全管控措施又导致了工作效率的下降，企业管理层及员工无法便捷地通过无所不在的网络访问企业防火墙内部的信息资产。 中小型企业希望通过宽带网络管道，从运营商托管应用数据中心“按需获取”其所需的企业IT应用能力：数量众多的中小企业，缺少IT领域专业经验，甚至没有财力和精力建设和维持自己专属的IT部门以及IT基础设施平台，普遍希望可以直接从托管运营商那里获取支撑其日常业务运作所需的SaaS服务。 针对解决上述企业IT系统建设和维护过程中遇到的普遍痛点问题，迫切呼唤业界IT软硬件解决方案提供商借助云计算技术，打造TCO、性价比与效率最优的“IT基础设施私有云及公有云”，具体包括： 面向大型企业和行业领域提供全自动化管理、一站式交付、支持与企业ITIL无缝集成融合、TCO最优化的端到端解决方案，实现企业传统IT基础设施及应用的改造、扩容和新建； 面向中小型企业，提供支持多租户安全隔离与动态发放、超大规模资源池调度管理、可最大限度发挥规模经济效益的公有云托管解决方案。 云计算的商业动力：企业ICT转型 互联网企业的核心竞争力 复杂盈利模式 在盈利模式上，相比传统企业，互联网公司最终设计了更为复杂、先进的盈利模式，即我们通常所说的“羊毛出在狗身上，猪来买单”。相比传统企业，这种盈利模式的好处是，用户接受互联网公司的产品和服务几乎没有利益付出的负面障碍。而最终为互联网提供免费服务的付费者也认为其每笔付出均有所值（这些付费者可能包括风险投资商、在互联网上做广告的企业，或者在互联网平台进行产品销售省去了渠道成本的企业）。这种复杂盈利模式让互联网公司的用户数量可以呈爆发式的增长，从而形成对传统企业的一项巨大的竞争优势。如今互联网公司所设计的盈利模式更加复杂，已经不再是简单的羊、狗、猪这种三方的关系了，而是贯穿全产业链、全商业运作的一种生态模式。而传统企业如今还是以简单的商品买卖这种古老的交易模式为主。这种盈利模式的竞争力差异，可能会让传统企业最终落到“把自己卖了，还在替别人点钱”的尴尬境地。 极低成本 互联网公司的这种复杂盈利模式，必须在规模效应（需要时间培育）下才能获得回报，而放大规模，需要更高的经营成本。这就要求互联网公司，为了活到能够盈利，必须再绞尽脑汁考虑如何降低自身的运营成本。构成互联网公司的主要成本主要是经营互联网网站所需的IT设备成本、IT软件成本、机房租赁成本、网络成本、办公场地成本、人员成本、市场广告成本等。其中IT设备、软件机房、网络以及运维人力的成本是互联网公司的最大成本源。对此，互联网公司不能再购买昂贵的商业IT产品，如产自知名IT厂商的小型机、数据库、操作系统等。他们只能寻求最便宜的解决方案，那就是我们现在看到的x86硬件和几乎全部基于开源软件一起构建的云计算平台。这个云计算平台相比传统企业使用的小型机、商业数据库、高端存储、商业应用软件等方式，成本至少下降了80%以上。而通过云计算的自动化运营技术，其大幅降低了运维人力的需求，一个运维人员可以管理数千台乃至上万台的IT设备。同时，基于云计算平台，其对机房基础设施也进行了优化改造，降低机房的能耗，即电力成本与场地成本。在业务上层，互联网公司千方百计地推进业务流程自动化的工作，使得大量传统企业人工流程在互联网平台上实现全自动化的处理，大幅降低了业务处理成本。 而传统企业，在丰厚的业务利润的滋养下，以及IT部门所处的企业非核心地位下，根本没有动力和条件向互联网公司那样拼命地降低IT成本。在大企业病的氛围下，传统企业所谓的降低成本，往往仅仅是为了一个漂亮的财务报表。实现每年10%～20%的成本下降幅度，即可以完美地达成当年业绩。在这种冰火两重天的环境下，让互联网公司在10年左右的时间里，大幅度地拉开了与传统企业的成本领先优势。如今，在传统金融行业每发放一笔贷款的成本竟然是互联网金融企业的1000倍。 极度的敏捷 为了快速推出业务，互联网公司也是无所不用其极。相比传统企业，互联网公司从人员组织架构、企业文化、经营模式、IT基础设施平台等方面都做了大幅改进。在组织架构上，即使是大型互联网企业，也放弃了传统企业那种逐层审批、大小领导签字画押的环节。业务研发团队自行进行业务决策，缩短内部业务研发外的时间。在企业文化上，为了业务快速上线，没日没夜的工作变得稀松平常，上线后再休息。在经营模式上，也完全打破传统企业把产品完美化再推向市场的策略，而是让位于业务上线时间，互联网公司让业务先上线，通过上线后用户反馈，再继续不断优化产品（规避了传统企业普遍存在的那种闭门造车的模式）。为了加快业务研发进度，在IT基础设施平台方面，互联网公司必须考虑用一个自动化的工具平台，利用这个平台，可以在最短的时间，开发出业务应用，并可以灰度发布，上线后还可以不断地继续完善。这就是我们已经熟知的云计算PaaS平台。经过这种为了加快业务上线速度进行的企业工作流程、组织架构、企业文化、IT平台的重构，互联网企业实现了新业务从研发立项到上线周期不会超过2周，最短只需不到2天的敏捷度。 大数据寡头 至今，大型互联网公司拥有几千PB的数据已经稀松平常了，领先的互联网公司已经走向EB乃至ZB的数量级。而大型传统企业所拥有的数据量，也不过几PB到几十PB，拥有几百个PB数据的传统企业已经少之又少了。双方仅在数据量上就已经达到上百倍的差距。这还只是数据的数量，还不算质量，在数据质量方面，互联网公司对消费者（个人）信息的掌握更是拥有巨大的优势，大型互联网公司的用户数量都是以亿为单位。个人的几乎所有活动信息都会呈现在互联网之上，包括但不限于个人的姓名、电话、住址、社会家庭关系、活动轨迹、资金关系、资产数额、知识能力、个人喜好、照片、影像、银行账号、社会交流、商务交流等。除了个人信息，还有大量的企业信息，包括企业（特别是网上开店企业）的所有经营活动、资金活动、客户信息、市场状况、销售活动、广告活动等。当所有的个人信息和企业信息汇聚起来，又形成了整个经济数据。任何经济领域的风吹草动，都不会逃过互联网厂商大数据监测与分析系统的法眼，而且在信息获取时间方向上比传统企业或机构大幅领先（比如某互联网公司公布的大企业景气指数曲线与国家统计局的指数曲线基本相同，但发布时间却比统计局的提前了5个月以上）。互联网企业获取的精准经济数据又可以反过来进行各种金融与市场商业活动。除了数据质量，在大数据处理技术上，互联网厂商也走在了前列。当大部分传统企业还在靠人工进行市场、经营与投资活动的时候，互联网公司已经开始进入了机器智能主导下的信息收集、分析、决策、处理的时代。 传统企业的ICT转型 传统企业应先认清自己 对于传统企业而言，有个重要的疑问需要解决，那就是为何互联网等信息化平台会成为所有企业的业务核心，即提高IT部门的地位，解决这个疑问的最佳答案是德国提出并已经局部实现的工业4.0概念。在工业4.0的场景下，一个制造企业，从产品的需求提出，到产品设计、原型生产、小批量试制、中等规模试制、测试验证，到大规模生产、物流仓储，再到市场销售的全环节、全流程，全部通过IT系统与互联网体系主导完成。人力工作只是在当前计算机设备能力有限的设计阶段和流程的规范性方面进行有限干预而已。 再以政府运营为例，政府未来的运营路径又是如何呢？政府作为公益、监管、执法机构，最高效率的运作就是利用互联网信息化的技术手段，打通与国家公民中所有企业、个人信息连接的壁垒，构建一个密集网状的信息化公共治理平台。比如：企业与个人的纳税可以在公共交易平台的交易与支付瞬间同时完成，税率也可以实现高度的定制化、个性化，可以针对不同企业经营与家庭状况收取不同税负并可调节。在这个公共信息化平台之上，所有的企业销售的商品与服务全程可追溯。而（企业）公民双方争议的调解和裁决大部分也可以在公共信息平台上解决，如此样例还有很多。政府达到这样一个公共信息化平台的信息化治理高度，这种治理模式实际上在一些互联网平台上已经完全或部分成为了现实，只是治理方是互联网公司而非政府而已。 评估自己的防护壁垒与环境允许的转型窗口期 虽然互联网厂商在向各行各业快速渗透，但出于各行业独有的技术壁垒、监管资质壁垒、资源壁垒、垄断市场壁垒等限制，互联网厂商无法一下子在短时间内通吃一切，气愤之余，也因此给这些壁垒冠以“保护既得利益，阻碍改革深入发展”的帽子。无论如何，这些壁垒给各行业的传统企业一个难得的转型窗口期。不同行业的转型窗口期不尽相同，这跟互联网厂商的基础能力相关。当前阶段互联网公司的基础能力聚集在个人消费者与小企业及个人创业者层面。那么以个人和小企业为目标客户的传统企业，转型窗口期就更短。以大型企业或政府机构为目标客户的传统企业转型窗口期则相对较长。因为经济的运转最终要靠个人，所以任何传统企业都不会有太长的转型窗口期。按照IT更新换代的发展周期预计，短的窗口期也就3～5年，长的窗口期也难以超过10年。 企业云计算的发展趋势 里程碑： 阶段 描述 面向数据中心管理员的IT基础设施资源虚拟化阶段 该阶段的关键特征体现为通过计算虚拟化技术的引入，将企业IT应用与底层的基础设施彻底分离解耦，将多个企业IT应用实例及运行环境（客户机操作系统）复用在相同的物理服务器上，并通过虚拟化集群调度软件，将更多的IT应用复用在更少的服务器节点上，从而实现资源利用效率的提升。 面向基础设施云租户和云用户的资源服务化与管理自动化阶段 该阶段的关键特征体现为通过管理平面的基础设施标准化服务与资源调度自动化软件的引入，以及数据平面的软件定义存储和软件定义网络技术，面向内部和外部的租户，将原本需要通过数据中心管理员人工干预的基础设施资源复杂低效的申请、释放与配置过程，转变为在必要的限定条件下（比如资源配额、权限审批等）的一键式全自动化资源发放服务过程。面向云租户的基础设施资源服务供给，可以是虚拟机形式，可以是容器（轻量化虚拟机），也可以是物理机形式。该阶段的企业IT云化演进，暂时还不涉及基础设施层之上的企业IT应用与中间件、数据库软件架构的变化 面向企业IT应用开发者及管理维护者的企业应用架构的分布式微服务化和企业数据架构的互联网化重构及大数据智能化阶段 该阶段的关键特征体现为：企业IT自身的应用架构逐步从纵向扩展应用分层架构体系，走向（依托开源增强的、跨不同业务应用领域高度共享的）数据库、中间件平台服务层以及（功能更加轻量化解耦、数据与应用逻辑彻底分离的）分布式无状态化架构，从而使得企业IT在支撑企业业务敏捷化、智能化以及资源利用效率提升方面迈上一个新的高度和台阶，并为企业创新业务的快速迭代开发铺平了道路。 云计算各阶段间的主要差异： 从IT非关键应用走向电信网络应用和企业关键应用 在云计算的计算虚拟化技术发展初期阶段，Guest OS与Host OS之间的前后端I/O队列在I/O吞吐上的开销较大，而传统的结构化数据由于对I/O性能吞吐和时延要求很高，这两个原因导致很多事务关键型结构化数据在云化的初期阶段并未被纳入虚拟化改造的范畴，从而使得相关结构化数据的基础设施仍处于虚拟化乃至云计算资源池的管理范围之外。然而随着虚拟化XEN/KVM引擎在I/O性能上的不断优化提升（如采用SR-IOV直通、多队列优化技术），使得处于企业核心应用的ERP等关系型关键数据库迁移到虚拟化平台上实现部署和运行已不是问题 从计算虚拟化走向存储虚拟化和网络虚拟化 对于存储来说，由于最基本的硬盘（SATA/SAS）容量有限，而客户、租户对数据容量的需求越来越大，因此必须考虑对数据中心内跨越多个松耦合的分布式服务器单元内的存储资源（服务器内的存储资源、外置SAN/NAS在内的存储资源）进行“小聚大”的整合，组成存储资源池。这个存储资源池，可能是某一厂家提供的存储软硬件组成的同构资源池，也可以是被存储虚拟化层整合成为跨多厂家异构存储的统一资源池。各种存储资源池均能以统一的块存储、对象存储或者文件的数据面格式进行访问。 在多租户虚拟化的环境下，不同租户对于边缘的路由及网关设备的配置管理需求也存在极大的差异化，而物理路由器和防火墙自身的多实例能力也无法满足云环境下租户数量的要求，采用与租户数量等量的路由器与防火墙物理设备，成本上又无法被多数客户所接受。于是人们思考是否可能将网络自身的功能从专用封闭平台迁移到服务器通用x86平台上来。这样至少网络端节点的实例就可以由云操作系统来直接自动化地创建和销毁，并通过一次性建立起来的物理网络连接矩阵，进行任意两个网络端节点之间的虚拟通讯链路建立，以及必要的安全隔离保障，从而里程碑式地实现了业务驱动的网络自动化管理配置，大幅度降低数据中心网络管理的复杂度。 资源池从小规模的资源虚拟化整合走向更大规模的资源池构建，应用范围从企业内部走向多租户的基础设施服务乃至端到端IT服务 通过虚拟化整合之后的资源池的服务对象，不能再仅仅局限于数据中心管理员本身，而是需要扩展到每个云租户。因此云平台必须在基础设施资源运维监控管理Portal的基础上，进一步面向每个内部或者外部的云租户提供按需定制基础设施资源，订购与日常维护管理的Portal或者API界面，并将虚拟化或者物理的基础设施资源的增、删、改、查等权限按照分权分域的原则赋予每个云租户，每个云租户仅被授权访问其自己申请创建的计算、存储以及与相应资源附着绑定的OS和应用软件资源，最终使得这些云租户可以在无须购买任何硬件IT设备的前提下，实现按需快速资源获取，以及高度自动化部署的IT业务敏捷能力的支撑，从而将云资源池的规模经济效益，以及弹性按需的快速资源服务的价值充分发掘出来。 数据规模从小规模走向海量，数据形态从传统结构化走向非结构化和半结构化 对非结构化、半结构化大数据的处理而产生的数据计算和存储量的规模需求，已远远超出传统的Scale-Up硬件系统可以处理的，因此要求必须充分利用云计算提供的Scale-Out架构特征，按需获得大规模资源池来应对大数据的高效高容量分析处理的需求。企业内日常事务交易过程中积累的大数据或者从关联客户社交网络以及网站服务中抓取的大数据，其加工处理往往并不需要实时处理，也不需要系统处于持续化的工作态，因此共享的海量存储平台，以及批量并行计算资源的动态申请与释放能力，将成为未来企业以最高效的方式支撑大数据资源需求的解决方案选择。 企业和消费者应用的人机交互计算模式，也逐步从本地固定计算走向云端计算、移动智能终端及浸入式体验瘦终端接入的模式 为应对云接入管道上不同业务类型对业务体验的不同诉求，业界通用的远程桌面接入协议在满足本地计算体验方面已越来越无法满足当前人机交互模式发展所带来的挑战，需要重点聚焦解决面向IP多媒体音视频的端到端QoS/QoE优化，并针对不同业务类别加以动态识别并区别处理，使其满足如下场景需求。 云资源服务从单一虚拟化，走向异构兼容虚拟化、轻量级容器化以及裸金属物理机服务器 基于共享Linux内核，对应用实例的运行环境以容器为单位进行隔离部署，并将其配置信息与运行环境一同打包封装，并通过容器集群调度技术（如Kubernetes）实现高并发、分布式的多容器实例的快速秒级发放及大规模容动态编排和管理，从而将大规模软件部署与生命周期管理，以及软件DevOps敏捷快速迭代开发与上线效率提升到了一个新的高度。从长远趋势上来看，容器技术终将以其更为轻量化、敏捷化的优势取代虚拟化技术，但在短期内仍很难彻底解决跨租户的安全隔离和多容器共享主机超分配情况下的资源抢占保护问题，因此，容器仍将在可见的未来继续依赖跨虚拟机和物理机的隔离机制来实现不同租户之间的运行环境隔离与服务质量保障。 云平台和云管理软件从闭源、封闭走向开源、开放 随着XEN/KVM虚拟化开源，以及OpenStack、CloudStack、Eucalyptus等云操作系统OS开源软件系统的崛起和快速进步，开源力量迅速发展壮大起来，迎头赶上并逐步成长为可以左右行业发展格局的重要决定性力量。 云计算的架构内涵与关键技术 云计算总体架构 企业数据中心IT架构正在面临一场前所未有的，以“基础设施软件定义与管理自动化”、“数据智能化与价值转换”以及“应用架构开源化及分布式无状态化”为特征的转化。 基础设施资源层融合 面向企业IT基础设施运维者的数据中心计算、存储、网络资源层，不再体现为彼此独立和割裂的服务器、网络、存储设备，以及小规模的虚拟化资源池，而是通过引入云操作系统，在数据中心将多个虚拟化集群资源池统一整合为规格更大的逻辑资源池，甚至进一步将地理上分散、但相互间通过MPLS/VPN专线或公网连接的多个数据中心以及多个异构云中的基础设施资源整合为统一的逻辑资源池，并对外抽象为标准化、面向外部租户（公有云）和内部租户（私有云）的基础设施服务，租户仅需制定其在软件定义的API参数中所需资源的数量、SLA/QoS及安全隔离需求，即可从底层基础设施服务中以全自动模式弹性、按需、敏捷地获取到上层应用所需的资源配备。 数据层融合 面向企业日常业务经营管理者的数据信息资产层，不再体现为散落在各个企业、消费者IT应用中，如多个看似关联不大的结构化事务处理记录（关系型数据库）数据孤岛，非结构化的文档、媒体以及日志数据信息片段，而是通过引入大数据引擎，将这些结构化与非结构化的信息进行统一汇总，汇聚存储和处理，基于多维度的挖掘分析与深度学习，从中迭代训练出对业务发展优化及客户满意度提升有关键价值的信息，从而将经营管理决策从纯粹依赖人员经验积累转变到更多依赖基于大数据信息内部蕴藏的智慧信息，来支撑更科学、更敏捷的商业决策。除大数据之外，数据层融合的另一个驱动力，来自于传统商业数据库在处理高并发在线处理及后分析处理扩展性方面所遭遇的不可逾越的架构与成本的瓶颈，从而驱动传统商业闭源数据库逐步被Scale Out架构的数据库分表分库及水平扩展的开源数据库所替代。 应用平台层融合 企业IT业务开发者和供应者的应用平台层开始积极探索基于云应用开发平台来实现跨应用领域基础公共开发平台与中间件能力去重整合，节省重复投入，同时通过在云开发平台中集成透明的开源中间件来替代封闭的商业中间件平台套件，特别通过引入面向云原生应用的容器化应用安装、监控、弹性伸缩及生命周期版本灰度升级管理的持续集成与部署流水线，来推动企业应用从面向高复杂度、厚重应用服务的瀑布式开发模式，逐步向基于分布式、轻量化微服务的敏捷迭代、持续集成的开发模式演进。 云计算架构上下文 云计算架构应用上下文的相关角色包括：云租户/服务消费者、云应用开发者、云服务运营者/提供者、云设备提供者 从上述云计算的基础上下文描述，我们不难看出云平台和云运营与运维管理系统是介于上层多租户的IT应用、传统数据中心管理软件，以及下层数据中心物理基础设施层之间的一层软件。其中云平台可进一步被分解为面向基础设施整合的云操作系统，面向数据整合的大数据引擎，以及面向应用中间件整合的应用开放平台。而云运营与运维管理系统在云计算引入的初期，与传统数据中心管理系统是并存关系，最终将逐步取代传统数据中心管理。 云平台的南向接口IF4向下屏蔽底层千差万别的物理基础设施层硬件的厂家差异性。针对应用层软件以及管理软件所提出的基础设施资源、数据处理以及应用中间件服务诉求，云平台系统向上层多租户的云应用与传统数据中心管理软件屏蔽如何提供资源调度、数据分析处理，以及中间件实现的细节，并在北向接口IF1、IF2和IF3为上层软件及特定租户提供归一化、标准化的基础设施服务（IaaS）、数据处理及应用平台服务（PaaS）API服务接口。在云平台面向云运营与管理者（拥有全局云资源操作权限）的IF3接口，除了面向租户的基础设施资源生命周期管理API之外，还包括一些面向物理、虚拟设施资源及云服务软件日常OAM运行健康状态监控的操作运维管理API接口。 其中IF1/IF2/IF3接口中关于云租户感知的云平台服务API的典型形态为Web RESTful接口。IF4接口则为业务应用执行平面的x86指令，以及基础设施硬件特有的、运行在物理主机特定类型OS中的管理Agent，或者基于SSL承载的OS命令行管理连接。IF3接口中的OAM API则往往采用传统IT和电信网管中被广泛采用的Web RESTful、SNMP、CORBA等接口。 云计算的典型技术参考架构 物理资源层 所有支撑IaaS层的IT基础设施硬件，其中包括服务器、存储（传统RAID架构垂直扩展的Scale Up存储和基于服务器的分布式水平扩展的Scale Out存储），以及数据中心交换机（柜顶、汇聚以及核心交换）、防火墙、VPN网关、路由器等网络安全设备。 虚拟资源层 （1）计算虚拟化 所有计算应用（含OS）并非直接承载在硬件平台上，而是在上层软件与裸机硬件之间插入了一层弹性计算资源管理及虚拟化软件：弹性计算资源管理软件对外负责提供弹性计算资源服务管理API，对内负责根据用户请求调度分配具体物理机资源；虚拟化软件（Hypervisor）对来自所有的x86指令进行截获，并在不为上层软件（含OS）所知的多道执行环境并行执行“仿真操作”，使得从每个上层软件实例的视角，仍然是在独占底层的CPU、内存以及I/O资源；而从虚拟化软件的视角，则是将裸机硬件在多个客户机（VM）之间进行时间和空间维度的穿插共享（时间片调度、页表划、I/O多队列模拟等）。 虚拟化环境下更高的内存访问效率：应用感知的大内存业务映射技术，通过该技术，可有效提升从虚拟机线性逻辑地址到最终物理地址的映射效率。 虚拟化环境下更高的CPU指令执行效率：通过对机器码指令执行的流程进行优化扫描，通过将相邻执行代码段中的“特权”指令所触发的“VM_Exit”虚拟化仿真操作进行基于等效操作的“合并”，从容达到在短时间内被频繁反复地执行。由于每次VM_Exit上下文进入和退出的过程都需要涉及系统运行队列调度以及运行环境的保存和恢复，即将多次上下文切换合并为一次切换，从而达到提升运行效率的目的。 虚拟化环境下更高的I/O和网络包收发处理效率：由于多个虚拟机在一个物理机内需要共享相同的物理网卡进行网络包收发处理，为有效减少中断处理带来的开销，在网络及I/O发包过程中，通过将小尺寸分组包合并为更大尺寸的分组包，可以减少网络收发接受端的中断次数，从而达到提升虚拟机之间网络吞吐率的目的。 更高的RAS可靠性保障：针对云计算所面临的电信领域网络及业务云化的场景，由于硬件故障被虚拟化层屏蔽了，使得物理硬件的故障无法像在传统物理机运行环境那样直接被传送通知给上层业务软件，从而导致上层业务层无法对故障做出秒级以内的及时响应，比如业务层的倒换控制，从而降低了对整体可靠性水平。如何感知上层的业务要求，快速进行故障检测和故障恢复，保证业务不中断，这给计算虚拟化带来了新的挑战。 单VM及多VM的弹性伸缩技术：单VM及多VM的弹性伸缩技术包括基本资源部件级别、虚拟机级别、云系统级别三个层次的伸缩技术。基本资源部件级别：精细化的Hypervisor资源调度，对指定虚拟机实例的CPU、内存及存储规格进行弹性伸缩，并可对伸缩上下限进行配额限制。虚拟机级别：指虚拟机集群的自动扩展与收缩，基于CloudWatch机制对集群资源忙闲程度的监控，对业务集群进行集群伸缩与扩展的Auto-Scaling控制。云系统级别：在内部私有云资源不足的情况下，自动向外部公有云或其他私有云（计算及存储资源池）“租借”及“释放”资源。 （2）存储虚拟化 通过对所有来自应用软件层的存储数据面的I/O读写操作指令进行“截获”，建立从业务应用视角覆盖不同厂家、不同版本的异构硬件资源的统一的API接口，进行统一的信息建模，使得上层应用软件可以采用规范一致的**、与底层具体硬件内部实现细节解耦的方式访问底层存储资源**。 通过“存储虚拟化”层内对多个对等的分布式资源节点的聚合，实现该资源的“小聚大”。比如，将多个存储/硬盘整合成为一个容量可无限扩展的超大（EB级规模）的共享存储资源池。由此可以看到，存储虚拟化相对计算虚拟化最大的差别在于：其主要定位是进行资源的“小聚大”，而非“大分小”。原因在于，存储资源的 “大分小”在单机存储以及SAN/NAS独立存储系统，乃至文件系统中通过LUN划分及卷配置已经天然实现了，然而随着企业IT与业务数据的爆炸式增长，需要实现高度扁平化、归一化和连续空间，跨越多个厂家服务器及存储设备的数据中心级统一存储，即“小聚大”。存储“小聚大”的整合正在日益凸显出其不可替代的关键价值。 高性能分布式存储引擎：伴随着云计算系统支撑的IT系统越来越大，覆盖范围从不同服务器存储节点，到分布在不同地理区域的数据中心，这就需要有一个分布式存储引擎。这个引擎，能满足高带宽、高I/O等各种场景要求，能很好地进行带宽的扩展。 存储异构能力：如何利旧，将不同厂家原有的独立SAN、NAS设备组合成一个大的存储资源池，也是软件定义存储中需要解决的问题 存储卸载：传统的企业存储系统，在采用各种各样的存储软件，这些软件存储操作对存储I/O和CPU资源均有较大消耗，会影响到用户业务性能的发挥。因此，如何将存储操作标准化，然后将存储操作利用某些标准的硬件动作去代替，这就是存储卸载。 （3）网络虚拟化 Cloud OS管理的资源范畴扩展到了整个数据中心，甚至将跨越多个由广域网物理或者逻辑专线连接起来数据中心。在一个具备一定规模的数据中心内，甚至多个数据中心内，各计算、存储单元之间以完全点对点的方式进行松耦合的网络互联。云数据中心之上承载的业务种类众多，各业务类型对于不同计算单元（物理机、虚拟机）之间，计算单元与存储单元之间，乃至不同安全层次的计算单元与外部开放互联网网络和内部企业网络之间的安全隔离及防护机制要求动态实现不同云租户之间的安全隔离。云数据中心还要满足不同终端用户不同场景的业务组网要求以及他们的安全隔离要求。因此，云操作系统的复杂性将随着云租户及租户内物理机和虚拟机实例的数量增长呈现几何级数的增长，由业务应用驱动的数据中心网络虚拟化和自动化已变得势在必行和不可或缺。为了实现彻底与现有物理硬件网络解耦的网络虚拟化与自动化，唯一的途径与解决方案就是SDN（也即所谓软件定义的网络），即构建出一个与物理网络完全独立的叠加式逻辑网络，其主要部件以及相关技术包括以下几方面。 SDN控制器：这是软件定义网络的集中控制模块。负责云系统中网络资源的自动发现和池化、根据用户需求分配网络资源、控制云系统中网络资源的正常运行。 虚拟交换机：根据SDN控制器，创建出的虚拟交换机实例。可以对这个虚拟交换机进行组网的设计、参数的设置，一如对物理交换机的使用。 虚拟路由器：根据SDN控制器，创建出的虚拟路由器实例。可以对这个虚拟路由器进行组网的设计、参数的设置，一如对物理路由器的使用。 虚拟业务网关：根据用户业务的申请，由SDN控制器创建出虚拟业务网关实例，提供虚拟防火墙的功能。可以对这个虚拟业务网关进行组网的设计、参数的设置，一如对物理业务网关的使用。 虚拟网络建模：面对如此复杂多变的组网，如何保证网络的有效区分和管理，又能保证交换和路由的效率，一个有效的建模方法和评估模型是需要的。虚拟网络建模技术能提前预知一个虚拟网络的运行消耗、效率和安全性。虚拟网络建模可以做成一个独立功能库，在需要的时候启动，以减少对系统资源的占用。 资源服务与调度层 相对虚拟化层在业务执行面和数据面上“资源聚合与分割仿真”，该层次主要体现为管理平面上的“逻辑资源调度”。 由于多个厂家已经投入到云计算的研发和实施中，不可避免地有多种实现方式。而要实现云计算真正的产业化并被广泛使用，各厂家的云计算平台必须要能够互相交互，即进行接口标准化。接口标准化后，主流的虚拟化平台，例如Hyper-V、KVM、UVP、ESX等之间能够互相兼容。各个硬件厂家或者中间件厂家可以自由选择虚拟化内核。 在云计算新的发展阶段中，面向公有云、面对国际化公司的分布式云系统将是重点。这样引发对超大资源的分配和调度。在整个云计算的实现架构上，计算、存储、网络资源的分配和使用将走向专业化。这是因为一个云应用业务，根据性质的不同，它对计算、存储、网络资源的需求可能是不一样的。例如：呼叫中心业务偏向于计算资源使用，而对于网盘业务则偏向于存储资源使用。在这种情况下，为了更有效地利用资源，给业务层提供基本资源调用API是最好的选择，将计算、存储、网络资源都作为基本资源单位，提供统一的资源调用接口，让云业务开发者自己选择如何高效地使用这些资源。这些API包括以下几个方面。 弹性计算资源调用API：计算资源包括CPU和内存，云计算平台根据云运营商的要求，已经将CPU和内存虚拟化和池化。系统提供资源的动态申请、释放、故障检测、隔离和自动切换功能，做到业务不感知。CPU资源又可以分为纯计算型、图像处理型等不同类型。不管是CPU还是内存，都提供瘦分配功能，资源的自动伸缩保证在低业务量时减少资源的消耗，高业务量时开启所有物理资源，确认业务的高效运行。计算资源API还需要提供集群能力。 弹性存储资源调用API：存储资源API提供文件或者卷接口，除了提供常见的资源申请、释放、瘦分配等功能外，还涉及其他几个关键方面。 异构资源的池化：不同的厂家在将存储资源池化后，提供统一的API，一个厂家可以利用这些API，将不同厂家的存储资源池构成一个大的资源池，然后再封装出API供业务调用。 存储资源的分层分级存储：因业务性能要求的不同，分层存储是一个常用的技术，业务系统在申请存储资源的时候，可以选择是否使用这个特性。 内存存储资源的支持：未来的系统，内存一定会成为主存，所有的存储，除非一些特别重要的信息，基本上不再需要存入非易失性介质。而使用内存资源作为主存，可靠性是关键要求。在构造内存存储池的时候，可靠性必须贯彻始终，每个内存存储在其他地方有备份，或者确保内存存储有可靠的UPS保护。 弹性网络资源调用API：网络资源API的基本功能也包括资源的申请、释放、监控、故障隔离和恢复等，也需要考虑异构资源的统一化。 拉通公有云与私有云的混合云架构 我们也不难发现，很多大企业及政府机构在面临云计算的建设使用模式的选择时，不可避免地将安全性问题放在了一个非常重要的位置上，甚至是作为首要考量的因素。目前，仅有在自建数据中心及自己维护管理组织的掌控范围内私有云模式才能保障企业敏感涉密的关键信息资产。这一事实决定了私有云仍将是很多大企业建设云计算首要选择的模式，私有云仍将与公有云在未来相当长一段时间内并存发展。只有拉通公有云和私有云的混合云能够将线上的公有云弹性敏捷优势，与私有云的安全私密保障优势相结合，实现优势互补，才能成为企业的最佳选择。 然而，考虑到大企业、政府机构等的业务负载的多样性，需要向云端迁移的应用并不仅仅包含核心涉密的信息资产，也包括业务突发性强，资源消耗量大，并且具备资源使用完毕之后可以立即释放的特征，比如开发测试应用、大数据分析计算应用、电商渠道的分布式Web前端应用等，均属于此类应用负载。这些应用当然也更适合采用公有云的方式来承载。但对于同一企业租户来说，如果一部分应用负载部署在公有云端，另一部分应用负载部署在私有云端，则仅仅跨云的身份认证、鉴权、拉通的统一发放及API适配是不够的，更重要的是必须实现拉通公有云和私有云的安全可信网络，实现自动化建立网络连接。 为满足上述诉求，需要跨不同的公有云和私有云，构建一层统一的混合云编排调度及API开放层，实现跨不同异构云的统一信息模型，并通过适配层将不同异构私有云、公有云的云服务及API能力集，对齐到混合云的统一信息模型，并通过SDN与各公有云、私有云的网络控制功能相配合，最终完成跨异构云网络互联的自动化。当然这个统一编排调度引擎，以及API开放层的实现架构，存在不同的可选路径。 引入一个全新的编排调度层，逐一识别出跨不同异构云的公共服务能力，并以此公共能力及其信息建模为基础参照，进行到各公有云、私有云的计算，存储原生API能力的逐一适配。该路径下的跨云网络互联方案，需要混合云SDN与各公有云、私有云的VPN网络服务进行紧密协同配合，由于不同异构云之间的网络服务语义及兼容性相比计算和存储服务差别更大，因此也必然给跨云的VPN网络连接适配处理带来了更大的复杂度与挑战。 依托于业界开源事实标准的云服务与调度层（如OpenStack），作为拉通各异构公有云、私有云的信息模型及API能力的基准，通过社区力量推动各异构云主动提供与该事实标准兼容的适配驱动。该路径下的跨云网络互联，采用叠加在所有异构云虚拟化之上的Overlay虚拟网络机制，无须进行跨异构云的网络模型适配转换，即可面向租户实现按需的跨云网络互联，从而大大降低了跨云网络互联处理的难度，为混合云的广泛普及奠定了坚实的基础。 可靠性保障 数据中心内的可靠性保障技术 数据中心内的可靠性保障技术主要包括HA（High Availability）冷备份、FT（Fault Tolerance）热备份、轻量级FT。 HA（High Availability） 冷备份数据中心内基于共享存储的冷迁移，在由于软件或硬件原因引发主用VM/PM故障的情况下，触发应用在备用服务器上启动。其适用于不要求业务零中断或无状态应用的可靠性保障。 FT（Fault Tolerance） 热备份其指指令、内存、所有状态数据同步。该方式的优势是状态完全同步，完全保证一致性，且支持SMP。劣势是性能开销大，会带来40%左右的性能降低。 轻量级FT 其是基于I/O同步的FT热备机制。优势是CPU/网络性能损耗10%以内，支持单核和多核。劣势是适合于网络I/O为主服务的场景。 跨数据中心的可靠性保障技术 跨数据中心的可靠性保障技术，主要是基于存储虚拟化层I/O复制的同步和异步容灾两种。基于存储虚拟化层I/O复制的同步容灾，采用生产和容灾中心同城（＜100KM）部署，时延小于5ms,DC间带宽充裕，并且对RPO（恢复点目标）要求较高，一般RPO接近或者等于0秒。分布式块存储提供更高效的I/O同步复制效率。 基于存储虚拟化层I/O复制的异步容灾采用生产和容灾中心异地（大于100KM）部署，带宽受限，时延大于5ms，同时对RPO有一定的容忍度，如RPO大于5分钟。I/O复制及快照对性能的影响趋近于零。 云计算核心架构竞争力 云计算及大数据开源软件概览 项目 描述 OpenStack 云操作系统框架，基于这个框架，可以集成不同的各类组件，实现满足不同场景需要的云操作系统，并在此基础上，最终构建完整的云计算系统。在计算领域，可以插件化的形式接入KVM、Xen、vCenter、FusionCompute等不同的Hypervisor；在存储领域，可以以插件化的形式实现对不同厂商的存储设备，以及Ceph、FusionStorage、vSAN等不同的软件定义存储的管理；在网络领域，可以实现对不同的网络硬件设备，OVS、Liunx-bridge、HAProxy等开源网络组件，以及多种SDN控制器的接入。 Kubernetes /Mesos / Docker Mesos生态：核心组件包括Mesos容器集群资源管理调度以及不同的应用管理框架。典型的应用管理框架包括Marathon和Chronos，其中Marathon用来管理长期运行服务，如Web服务；Chronos用来管理批量任务。Mesos生态主要由Mesosphere、Twitter等公司主力推动。 Kubernetes生态：Google公司发起的社区项目，涵盖容器集群资源管理调度，以及不同类型应用的应用管理组件。例如副本可靠性管理，服务发现和负载均衡，灰度升级，配置管理等组件。 Docker生态：Docker公司希望向容器生态系统上层发展，推出了Swarm容器资源管理调度组件，以及Compose应用编排组件。 Hadoop/Spark Hadoop来自Apache社区，是一个可水平扩展、高可用、容错的海量数据分布式处理框架，提供了简单分布式编程模型map-reduce。Hadoop设计的假设是底层硬件不可靠，由Hadoop检测和处理底层硬件失效 本文对于云计算的架构设计做了初步总结，后面会细化各个技术和应用场景，分开描述。","categories":[{"name":"经验总结","slug":"经验总结","permalink":"https://blackforest1990.github.io/categories/%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/"}],"tags":[{"name":"云计算","slug":"云计算","permalink":"https://blackforest1990.github.io/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"}]},{"title":"Tcp&ip","slug":"Tcp-ip","date":"2024-01-16T04:52:04.000Z","updated":"2024-01-23T06:28:32.592Z","comments":true,"path":"2024/01/16/Tcp-ip/","link":"","permalink":"https://blackforest1990.github.io/2024/01/16/Tcp-ip/","excerpt":"","text":"本文基于一个TCP&amp;IP项目进行学习，主要目的是来探索网络编程的奇妙。如下为本次学习的一些网络库和知识库。 代码参考：https://github.com/saminiir/level-ip 基础知识参考：https://beej-zhcn.netdpi.net/ TCP&amp;IP 协议层 网络接口层（Network Interface Layer）： 对应于OSI模型的物理层和数据链路层。负责将数据帧封装成比特流，并处理与物理网络设备的交互。 网络层（Internet Layer）： 对应于OSI模型的网络层。主要功能是在网络中路由数据包，为数据包选择最佳路径。IP协议是在这一层工作的关键协议。 传输层（Transport Layer）： 对应于OSI模型的传输层。负责端到端的通信，提供可靠的数据传输。TCP（传输控制协议）和UDP（用户数据报协议）是在这一层工作的协议。 应用层（Application Layer）： 对应于OSI模型的会话层、表示层和应用层。包含了各种应用程序，如HTTP（超文本传输协议）、FTP（文件传输协议）、SMTP（简单邮件传输协议）等。 Ethernet &amp; ARP TAP设备 为了拦截来自 Linux 内核的低级网络流量，我们将使用 Linux TAP 设备。简而言之，网络用户空间应用程序通常使用 TUN/TAP 设备分别操作 L3/L2 流量。在Linux中，TAP代表（Tap Virtual Network Device）。TAP设备是一种虚拟网络设备，通常用于模拟网络连接或实现虚拟专用网络（VPN）等网络功能。由于我们想要从第 2 层开始构建网络堆栈，因此我们需要一个 TAP 设备。我们像这样实例化它： 123456789101112131415161718192021222324252627282930313233static int tun_alloc(char *dev)&#123; struct ifreq ifr; int fd, err; if( (fd = open(&quot;/dev/net/tap&quot;, O_RDWR)) &lt; 0 ) &#123; perror(&quot;Cannot open TUN/TAP dev\\n&quot; &quot;Make sure one exists with &quot; &quot;&#x27;$ mknod /dev/net/tap c 10 200&#x27;&quot;); exit(1); &#125; CLEAR(ifr); /* Flags: IFF_TUN - TUN device (no Ethernet headers) * IFF_TAP - TAP device * * IFF_NO_PI - Do not provide packet information */ ifr.ifr_flags = IFF_TAP | IFF_NO_PI; if( *dev ) &#123; strncpy(ifr.ifr_name, dev, IFNAMSIZ); &#125; if( (err = ioctl(fd, TUNSETIFF, (void *) &amp;ifr)) &lt; 0 )&#123; perror(&quot;ERR: Could not ioctl tun&quot;); close(fd); return err; &#125; strcpy(dev, ifr.ifr_name); return fd;&#125; 在这之后，返回的文件描述符fd可以用于读取和写入数据到虚拟设备的以太网缓冲区。IFF_NO_PI标志在这里非常关键，否则我们将得到不必要的数据包信息附加到以太网帧之前。 以太网帧格式 多种不同的以太网技术是连接局域网(LAN) 中计算机的支柱。 以太网标准：https://en.wikipedia.org/wiki/IEEE_802.3 接下来，我们将看一下以太网帧头。可以将其声明为 C 结构体，如下所示： 1234567struct eth_hdr &#123; uint8_t dmac[6]; uint8_t smac[6]; uint16_t ethertype; uint8_t payload[];&#125; __attribute__((packed)); dmac smac: 它们包含通信双方的 MAC 地址（分别是目标和源）。 重载字段ethertype是一个 2 个八位字节的字段，根据其值，指示有效负载的长度或类型。具体来说，如果该字段的值大于或等于1536，则该字段包含有效负载的类型（例如IPv4、ARP）。如果该值小于该值，则它包含有效负载的长度。 在类型字段之后，以太网帧可能有几个不同的标签。这些标签可用于描述帧的虚拟 LAN (VLAN) 或服务质量(QoS) 类型。以太网帧标签被排除在我们的实现之外，因此相应的字段也不会出现在我们的协议声明中。 payload包含指向以太网帧有效负载的指针。在我们的例子中，这将包含 ARP 或 IPv4 数据包。如果有效负载长度小于所需的最小48字节（不含标签），则将填充字节附加到有效负载的末尾以满足要求。 我们还包含if_ether.hLinux 标头来提供以太类型及其十六进制值之间的映射。 最后，以太网帧格式末尾还包括帧校验序列字段，该字段与循环冗余校验（CRC）一起用于检查帧的完整性。我们将在实现中省略对该字段的处理。 __attribute__((packed))：这是一个GCC特有的属性，用于告诉编译器以最小的字节对齐方式来布局结构体，确保没有额外的填充字节。这对于网络协议帧头等需要严格字节对齐的结构体来说是重要的。 以太网帧解析 解析和处理传入以太网帧的总体场景非常简单： 1234567if (tun_read(buf, BUFLEN) &lt; 0) &#123; print_error(&quot;ERR: Read from tun_fd: %s\\n&quot;, strerror(errno));&#125;struct eth_hdr *hdr = init_eth_hdr(buf);handle_frame(&amp;netdev, hdr); 地址解析协议 地址解析协议（ARP）用于将48位以太网地址（MAC地址）动态映射到协议地址（例如IPv4地址）。这里的关键是，通过 ARP，可以使用多种不同的 L3 协议：不仅是 IPv4，还有其他协议。通常的情况是知道 LAN 中某些服务的 IP 地址，但要建立实际通信，还需要知道硬件地址 (MAC)。因此，ARP用于广播和查询网络，要求IP地址的所有者报告其硬件地址。 ARP数据包格式比较简单： 123456789struct arp_hdr&#123; uint16_t hwtype; uint16_t protype; uint8_t hwsize; uint8_t prosize; uint16_t opcode; unsigned char data[];&#125; __attribute__((packed)); ARP 标头 ( arp_hdr) 包含 2 个八位字节hwtype，它确定所使用的链路层类型。在我们的例子中，这是以太网，实际值为0x0001。 2 个八位字节protype字段指示协议类型。在我们的例子中，这是 IPv4，通过值 进行通信0x0800。 hwsize（硬件地址长度）： 一个8位的整数，表示硬件地址的长度，以字节为单位 prosize（协议地址长度）：一个8位的整数，表示协议地址的长度，以字节为单位。 2 个八位字节字段opcode声明 ARP 消息的类型。它可以是 ARP 请求 (1)、ARP 应答 (2)、RARP 请求 (3) 或 RARP 应答 (4)。 该data字段包含 ARP 消息的实际负载，在我们的例子中，它将包含 IPv4 特定信息： 1234567struct arp_ipv4&#123; unsigned char smac[6]; uint32_t sip; unsigned char dmac[6]; uint32_t dip;&#125; __attribute__((packed)); 这些字段非常不言自明。smac dmac分别包含发送方和接收方的 6 字节 MAC 地址。sip和dip分别包含发送者和接收者的 IP 地址。 地址解析算法 检查硬件类型（ar$hrd）： 如果硬件类型存在（几乎肯定存在），继续。 可选地检查硬件长度（ar$hln）： 检查协议类型（ar$pro）： 如果协议类型存在，继续。 可选地检查协议长度（ar$pln）： 初始化Merge_flag为false： 检查转换表中是否存在 &lt;协议类型，发送者协议地址&gt; 这一对： 如果已存在： 使用数据包中的新信息更新该条目的发送者硬件地址字段。 将 Merge_flag 设置为 true。 检查当前设备是否是目标协议地址： 如果是： 如果 Merge_flag 为false，则将 &lt;协议类型，发送者协议地址，发送者硬件地址&gt; 添加到转换表中。 检查操作码是否是ARP请求 (ares_op$REQUEST)： 如果是： 交换硬件和协议字段，将本地硬件和协议地址放入发送者字段。 将 ar$op 字段设置为 ares_op$REPLY。 将数据包发送到在同一硬件上收到请求时的新目标硬件地址。 这个算法描述了在接收到ARP请求时的处理流程，包括更新转换表、响应ARP请求和发送ARP回复。 translation table用于存储 ARP 结果，以便主机只需查找其缓存中是否已有该条目即可。这可以避免向网络发送冗余 ARP 请求的垃圾邮件。 IPv4 and ICMPv4 IPv4 我们的实现中的下一层 (L3)（在以太网帧之后）处理将数据传送到目的地的情况。也就是说，互联网协议(IP) 的发明是为了为 TCP 和 UDP 等传输协议提供基础。它是无连接的，这意味着与 TCP 不同，所有数据报在网络堆栈中都是相互独立处理的。这也意味着 IP 数据报可能会无序到达。 此外，IP 并不能保证成功传输。这是协议设计者有意识的选择，因为 IP 旨在为同样不保证传输的协议提供基础。UDP 就是这样一种协议。如果通信双方之间需要可靠性，则可以在 IP 之上使用 TCP 等协议。在这种情况下，更高级别的协议负责检测丢失的数据并确保所有数据均已传输。 Header IPv4 标头的长度通常为 20 个八位位组。标头可以包含尾随选项，但我们的实现中省略了它们。字段的含义相对简单，可以用 C 结构体来描述： 123456789101112131415struct iphdr &#123; uint8_t ihl : 4; /* TODO: Support Big Endian hosts */ uint8_t version : 4; uint8_t tos; uint16_t len; uint16_t id; uint16_t frag_offset; uint8_t ttl; uint8_t proto; uint16_t csum; uint32_t saddr; uint32_t daddr; uint8_t [];&#125; __attribute__((packed)); 4 位字段version指示 Internet 标头的格式。在我们的例子中，IPv4 的值为 4。 互联网报头长度字段ihl的长度同样为 4 位，由于该字段的大小为 4 位，因此它最多只能容纳 15。因此，IP 标头的最大长度为 60 个八位字节（15 乘以 32 除以 8）。 服务类型字段源自tos为IP 数据报的服务质量。 总长度字段len 传达整个 IP数据报的长度。由于它是 16 位字段，因此最大长度为 65535 字节。大型 IP 数据报会被分割成更小的数据报，以满足不同通信接口的最大传输单元(MTU)。 id字段用于索引数据报，最终用于重组分片的IP数据报。该字段的值只是一个由发送方递增的计数器。反过来，接收方知道如何对传入的片段进行排序。 flags字段定义了数据报的各种控制标志。具体来说，发送方可以指定数据报是否允许分片，是否是最后一个分片，或者是否还有更多分片传入。 片段偏移字段frag_offset指示片段在数据报中的位置。当然，第一个数据报的索引设置为 0。 ttl是一个常见属性，数据报的生命周期。它通常由原始发送方设置为 64，每个接收方都会将该计数器减 1。当它达到零时，数据报将被丢弃，并且可能会回复一条 ICMP 消息以指示错误。 该proto字段为数据报提供了在其有效负载中携带其他协议的固有能力。该字段通常包含 16 (UDP) 或 6 (TCP) 等值，仅用于向接收方传达实际数据的类型。 报头校验和字段csum，用于验证 IP 报头的完整性。 最后，saddr和daddr字段分别指示数据报的源地址和目标地址。 Internet Checksum 互联网校验和字段用于检查 IP 数据报的完整性。算法的实际代码如下： 12345678910111213141516171819202122232425262728293031323334uint32_t sum_every_16bits(void *addr, int count)&#123; register uint32_t sum = 0; uint16_t * ptr = addr; while( count &gt; 1 ) &#123; /* This is the inner loop */ sum += * ptr++; count -= 2; &#125; /* Add left-over byte, if any */ if( count &gt; 0 ) sum += * (uint8_t *) ptr; return sum;&#125;uint16_t checksum(void *addr, int count, int start_sum)&#123; /* Compute Internet Checksum for &quot;count&quot; bytes * beginning at location &quot;addr&quot;. * Taken from https://tools.ietf.org/html/rfc1071 */ uint32_t sum = start_sum; sum += sum_every_16bits(addr, count); /* Fold 32-bit sum to 16 bits */ while (sum&gt;&gt;16) sum = (sum &amp; 0xffff) + (sum &gt;&gt; 16); return ~sum;&#125; sum_every_16bits 函数： 参数 void *addr 是指向内存地址的指针，表示数据的起始地址。 参数 int count 是要计算校验和的数据字节数。 函数使用指针 ptr 迭代访问数据，每次累加两个字节的值到 sum 中，直到处理完所有的字节。 如果数据字节数是奇数，最后一个字节单独累加。 返回一个 32 位整数，表示所有 16 位字的和。 checksum 函数： 参数 void *addr 是数据的起始地址。 参数 int count 是要计算校验和的数据字节数。 参数 int start_sum 是初始的校验和值。 函数调用 sum_every_16bits 函数计算数据的 16 位字的和，然后将其加到初始校验和值 start_sum 中。 然后，使用一个循环将 32 位的和折叠为 16 位，直到和不再超过 16 位。 最后，返回计算得到的校验和的一位补码。 这些函数的目的是按照 RFC1071 中描述的方式计算 Internet 校验和。计算校验和的过程涉及将所有 16 位字相加，然后将 32 位和折叠为 16 位。最终，返回的值是校验和的一位补码。 Internet Control Message Protocol version 4 由于互联网协议缺乏可靠性机制，因此需要某种方式来通知通信方可能的错误情况。因此，互联网控制消息协议(ICMP) 用于网络中的诊断措施。 Header ICMP 标头驻留在相应 IP 数据包的有效负载中。ICMPv4报头的结构如下： 123456struct icmp_v4 &#123; uint8_t type; uint8_t code; uint16_t csum; uint8_t data[];&#125; __attribute__((packed)); type字段传达消息的目的。类型字段保留了42个不同的值，但常用的只有大约8个。在我们的实现中，使用类型 0（Echo Reply）、3（Destination Unreachable）和 8（Echo request）。 code字段进一步描述了消息的含义。例如，当类型为 3（目的地不可达）时，代码字段暗示原因。一个常见错误是当数据包无法路由到网络时：始发主机很可能会收到类型为 3 且代码为 0（网络不可达）的 ICMP 消息。 csum字段与IPv4报头中的校验和字段相同，并且可以使用相同的算法来计算它。在 ICMPv4 中，校验和是端到端的，这意味着计算校验和时还包括有效负载。 消息及其处理 实际的 ICMP 负载由查询/信息消息和错误消息组成。首先，我们来看看回显请求/回复消息，在网络中通常称为“ping”： 12345struct icmp_v4_echo &#123; uint16_t id; uint16_t seq; uint8_t data[];&#125; __attribute__((packed)); 消息格式紧凑。该字段id由发送主机设置，以确定回显应答要发送给哪个进程。例如，可以在此字段中设置进程 ID。 该字段seq是回显的序列号，它只是一个从零开始的数字，每当形成新的回显请求时就加一。这用于检测回显消息在传输过程中是否消失或重新排序。 该data字段是可选的，但通常包含回显时间戳等信息。然后可以使用它来估计主机之间的往返时间。 ICMPv4 错误消息Destination Unreachable具有以下格式： 123456struct icmp_v4_dst_unreachable &#123; uint8_t unused; uint8_t len; uint16_t var; uint8_t data[];&#125; __attribute__((packed)); 首先，第一个八位字节未使用。然后，长度字段（len field）表示原始数据报的长度，以IPv4的4字节单位计算。2字节字段var的值取决于ICMP代码。最后，导致目标不可达状态的原始IP数据包的尽可能多的部分被放置到数据字段中。 TCP 基础知识和握手 可靠性机制 可靠发送数据的问题看似表面，但涉及到其实际的实现。主要是，在数据报式网络中的错误修复方面出现了几个问题： 发送方应等待接收方确认多长时间？ 如果接收方处理数据的速度无法赶上发送数据的速度怎么办？ 如果中间的网络（例如路由器）无法像发送数据一样快速处理数据怎么办？ 在所有情况下，数据包交换网络的潜在危险都存在——来自接收方的确认可能在传输过程中被损坏甚至丢失，这使发送方陷入困境。 为了解决这些问题，可以使用多种机制。也许最常见的是滑动窗口技术，双方都对传输的数据进行记录。窗口数据被认为是连续的（就像数组的切片），并且当双方处理（并确认）数据时，窗口向前“滑动”： 123456789101112Left window edge Right window edge | | | | --------------------------------------------------------- ...| 3 | 4 | 5 | 6 | 7 |... --------------------------------------------------------- ^ ^ ^ ^ | \\ / | | \\ / | Sent and Window size: 3 Cannot be ACKed sent yet 使用这种滑动窗口的便利特性是它还减轻了流量控制的问题。当接收方处理数据的速度不能达到发送数据的速度时，就需要进行流量控制。在这种情况下，滑动窗口的大小将协商得较小，从而导致发送方的输出受到限制。 另一方面，拥塞控制有助于发送方和接收方之间的网络堆栈不发生拥塞。有两种通用方法：在显式版本中，协议有一个字段用于专门通知发送方有关拥塞状态的信息。在隐式版本中，发送方尝试猜测网络何时拥塞并应限制其输出。总体而言，拥塞控制是一个复杂的、反复出现的网络问题。 TCP 基础知识 TCP 中的底层机制比 UDP 和 IP 等其他协议涉及更多。TCP是面向连接的协议，这意味着首先在正好两端之间建立单播通信通道。这个连接是由双方主动处理的：建立连接（握手），告知对方数据的状态和可能出现的问题。 TCP 的另一个重要属性是它是一种流协议。与 UDP 不同，TCP 不保证应用程序在发送和接收数据时保持稳定的数据“块”。相反，TCP 实现必须缓冲数据，当数据包丢失、重新排序或损坏时，TCP 必须等待并组织缓冲区中的数据。只有当数据被认为是完整的时，TCP才可以将数据交给应用程序的套接字。 由于 TCP 将数据作为流进行操作，因此流中的“块”必须转换为 IP 可以承载的数据包。这称为打包，其中 TCP 标头包含流中当前索引的序列号。这还有一个方便的特性，即流可以分成许多可变大小的段，然后 TCP 知道如何重新打包它们。 与 IP 类似，TCP 也检查消息的完整性。这是通过与 IP 中相同的校验和算法实现的，但增加了细节。主要是，校验和是端到端的，这意味着标头和数据都包含在校验和中。此外，还包括根据 IP 标头构建的伪标头。 如果 TCP 实现接收到损坏的段，它会丢弃它们并且不会通知发送方。这个错误可以通过发送方设置的定时器来纠正，如果接收方从未确认过该报文段，则可以使用该定时器来重新传输该报文段。 TCP 也是一个全双工系统，这意味着流量可以同时在两个方向上流动。这意味着通信双方必须在内存中保持双向数据的排序。更深入地说，TCP 通过在其发送的段中包含对相反流量的确认来保留其流量足迹。 从本质上讲，数据流的排序是 TCP 的主要原理。然而，保持同步的问题并不是一个简单的问题。 TCP Header 接下来，我们将定义消息标头并描述其字段。TCP头看似简单，但是包含了很多关于通信状态的信息。 TCP 标头为 20 个八位位组，大小为： 123456789101112 0 15 31-----------------------------------------------------------------| source port | destination port |-----------------------------------------------------------------| sequence number |-----------------------------------------------------------------| acknowledgment number |-----------------------------------------------------------------| HL | rsvd |C|E|U|A|P|R|S|F| window size |-----------------------------------------------------------------| TCP checksum | urgent pointer |----------------------------------------------------------------- 源端口和目标端口字段用于建立来自和到主机的多个连接。也就是说，Berkeley 套接字是应用程序绑定到 TCP 网络堆栈的流行接口。通过端口，网络堆栈知道将流量定向到哪里。由于字段大小为 16 位，因此端口值范围为 0 到 65535。 由于流中的每个字节都有编号，因此序列号代表 TCP 段的窗口索引。握手时，它包含初始序列号(ISN)。 确认号包含发送方期望接收的下一个字节的窗口索引。握手后，必须始终填充 ACK 字段。 报头长度(HL) 字段以 32 位字表示报头的长度。 接下来，展示了几个标志。前 4 位 ( rsvd ) 未使用。 拥塞窗口降低©用于通知发送方降低了其发送速率。 ECN Echo (E) 通知发送方收到拥塞通知。 Urgent Pointer（U）指示该段包含优先级数据。 ACK (A) 字段用于传达 TCP 握手的状态。它在连接的剩余时间内保持开启状态。 PSH（P）用于指示接收方应尽快将数据“推送”到应用程序。 RST ® 重置 TCP 连接。 SYN (S)用于在初始握手时同步序列号。 FIN (F)表示发送方已完成数据发送。 window size字段用于通告窗口大小。换句话说，这是接收方愿意接受的字节数。由于它是 16 位字段，因此最大窗口大小为 65,535 字节。 TCP checksum字段用于验证 TCP 段的完整性。该算法与 Internet 协议相同，但输入段还包含 TCP 数据以及来自 IP 数据报的伪标头。 当设置 U 标志时，使用紧急指针。该指针指示紧急数据在流中的位置。 在可能的选项之后，接下来是实际数据。然而，该数据不是必需的。例如，握手仅通过 TCP 标头完成。 TCP握手 TCP连接通常经历以下阶段：连接建立（握手）、数据传输和连接关闭。下图描述了 TCP 通常的握手例程： 1234567891011TCP A TCP B 1. CLOSED LISTEN 2. SYN-SENT --&gt; &lt;SEQ=100&gt;&lt;CTL=SYN&gt; --&gt; SYN-RECEIVED 3. ESTABLISHED &lt;-- &lt;SEQ=300&gt;&lt;ACK=101&gt;&lt;CTL=SYN,ACK&gt; &lt;-- SYN-RECEIVED 4. ESTABLISHED --&gt; &lt;SEQ=101&gt;&lt;ACK=301&gt;&lt;CTL=ACK&gt; --&gt; ESTABLISHED 5. ESTABLISHED --&gt; &lt;SEQ=101&gt;&lt;ACK=301&gt;&lt;CTL=ACK&gt;&lt;DATA&gt; --&gt; ESTABLISHED 主机 A 的套接字处于关闭状态，这意味着它不接受连接。相反，主机 B 绑定到特定端口的套接字正在侦听新连接。 主机 A 打算发起与主机 B 的连接。因此，A 制作了一个 TCP 段，该段设置了 SYN 标志，并且序列字段填充了值 (100)。 主机 B 使用设置了 SYN 和 ACK 字段的 TCP 段进行响应，并通过向其加 1 来确认 A 的序列号 (ACK=101)。同样，B 生成序列号（300）。 3 次握手由连接请求发起者 (A) 的 ACK 完成。确认字段反映了主机接下来期望从另一端接收到的序列号。 数据开始流动，主要是双方都确认了对方的段号。 这是建立TCP连接的常见场景。然而，出现了几个问题： 初始序列号是如何选择的？ 如果双方同时请求彼此连接怎么办？ 如果路段延迟一段时间或无限期怎么办？ 初始序列号(ISN) 由通信双方在第一次联系时独立选择。由于它是识别连接的关键部分，因此必须选择它，使其最有可能是唯一的且不易被猜测。事实上，在TCP 序列号攻击中，攻击者可以复制 TCP 连接并有效地将数据传送给目标，冒充受信任的主机。 最初的规范建议 ISN 由每 4 微秒递增的计数器选择。然而，攻击者可以猜测到这一点。实际上，现代网络堆栈通过更复杂的方法生成 ISN。 两个端点收到对方的连接请求（SYN）的情况称为同时打开。这是通过 TCP 握手中的额外消息交换来解决的：双方都发送 ACK（不知道另一方也已完成），并且双方对请求进行 SYN-ACK。此后，数据传输开始。 最后，TCP 实现必须有一个计时器来知道何时放弃建立连接。尝试重新建立连接，通常采用指数退避，但一旦达到最大重试次数或时间阈值，连接将被视为不存在。 TCP 选项 TCP 标头段中的最后一个字段是为可能的 TCP 选项保留的。最初的规范提供了三个选项，但后来的规范添加了更多选项。接下来，我们将看看最常见的选项。 最大段大小(MSS) 选项告知 TCP 实现愿意接收的最大 TCP 段大小。IPv4 中的典型值为 1460 字节。 选择性确认(SACK) 选项优化了许多数据包在传输过程中丢失且接收器的数据窗口充满“漏洞”的情况。为了弥补由此造成的吞吐量下降，TCP 实现可以通过 SACK 通知发送方它未收到的特定数据包。因此，发送方以比累积确认方案更直接的方式接收有关数据状态的信息。 窗口缩放选项增加了有限的 16 位窗口大小。也就是说，如果双方在握手段中都包含此选项，则窗口大小将乘以此比例。拥有更大的窗口大小对于批量数据传输非常重要。 时间戳选项允许发送方将时间戳放入 TCP 分段中，然后可用于计算每个 ACK 分段的 RTT。然后可以使用该信息来计算 TCP 重传超时。 TCP Data Flow &amp; Socket API Transmission Control Block 通过定义记录数据流状态的变量来开始讨论 TCP 数据管理是有益的。 简而言之，TCP 必须跟踪它已发送和接收确认的数据序列。为了实现这一点，为每个打开的连接初始化一个称为传输控制块（TCB）的数据结构。 传出（发送）端的变量是： 123456789Send Sequence Variables SND.UNA - send unacknowledged SND.NXT - send next SND.WND - send window SND.UP - send urgent pointer SND.WL1 - segment sequence number used for last window update SND.WL2 - segment acknowledgment number used for last window update ISS - initial send sequence number 依次，为接收方记录以下数据： 123456Receive Sequence Variables RCV.NXT - receive next RCV.WND - receive window RCV.UP - receive urgent pointer IRS - initial receive sequence number 此外，当前正在处理的段的辅助变量定义如下： 12345678Current Segment Variables SEG.SEQ - segment sequence number SEG.ACK - segment acknowledgment number SEG.LEN - segment length SEG.WND - segment window SEG.UP - segment urgent pointer SEG.PRC - segment precedence value 这些变量共同构成了给定连接的大部分 TCP 控制逻辑。 TCP数据通讯 一旦建立连接，就会开始显式处理数据流。TCB 中的三个变量对于状态的基本跟踪非常重要： SND.NXT- 发件人将跟踪要在SND.NXT中使用的下一个序列号。 RCV.NXT- 接收方记录下一个期望的序列号RCV.NXT。 SND.UNA- 发送方将在SND.UNA 中记录最早的未确认序列号。 在足够的时间段内，当TCP管理数据通信且没有传输发生时，这三个变量将相等。 例如，当 A 决定向 B 发送带有数据的段时，以下事件发生： TCP A发送一个段并在其自己的记录（TCB）中推进SND.NXT。 TCB B接收该段并通过推进RCV.NXT进行确认，并发送一个ACK。 TCB A接收ACK并推进SND.UNA。 这些变量推进的数量是段中数据的长度。这是TCP在传输数据上的控制逻辑基础。 TCP 连接终止 关闭 TCP 连接同样是一个复杂的操作，可以强制终止（RST）或通过双方协议（FIN）完成。 基本场景如下： 主动关闭者发送FIN 报文段。 被动关闭者通过发送 ACK 段来确认这一点。 被动关闭器者开始自己的关闭操作（当它没有更多数据要发送时）并有效地成为主动关闭者。 一旦双方都向对方发送了 FIN 并且向两个方向都确认了它们，连接就会关闭。 显然，TCP 连接的关闭需要四个段，而 TCP 连接建立（三次握手）则需要三个段。 此外，TCP 是一种双向协议，因此可以让另一端宣布它没有更多数据要发送，但仍保持在线状态以接收传入数据。这称为TCP 半关闭。 数据包交换网络的不可靠特性给连接终止带来了额外的复杂性 - FIN 段可能会消失或永远不会被有意发送，从而使连接处于尴尬的状态。例如，在 Linux 中，内核参数tcp_fin_timeout控制 TCP 在强制关闭连接之前等待最终 FIN 数据包的秒数。这违反了规范，但却是预防拒绝服务 (DoS) 所必需的。 中止连接涉及设置了 RST 标志的段。发生重置的原因有很多，但常见的原因有： 对不存在的端口或接口的连接请求 另一个 TCP 已崩溃并最终处于不同步连接状态 尝试干扰现有连接 因此，TCP 数据传输的最佳路径永远不会涉及 RST 段。 套接字API 为了能够利用网络堆栈，必须为应用程序提供某种接口。BSD Socket API是最著名的一种，它起源于 1983 年的 4.2BSD UNIX 版本。Linux 中的 Socket API 与 BSD Socket API 兼容。 socket(2)通过调用并将套接字类型和协议作为参数传递，可以从网络堆栈中保留套接字。通用值为AF_INET和SOCK_STREAM。这将默认为 TCP-over-IPv4 套接字。 成功从网络堆栈保留 TCP 套接字后，它将连接到远程端点。这是connect(2)使用的地方，调用它将启动 TCP 握手。 从那时起，我们就可以从套接字write(2)和read(2)获取数据了。 网络堆栈将处理 TCP 流中数据的排队、重传、错误检查和重组。对于应用程序来说，TCP的内部行为大多是不透明的。应用程序唯一可以依赖的是 TCP 已确认发送和接收数据流的责任，并且它将通过套接字 API 通知应用程序意外行为。 socket()： 创建一个套接字，返回一个套接字描述符。 1int socket(int domain, int type, int protocol); bind()： 将套接字与特定地址（IP地址和端口号）绑定。 1int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); listen()： 启动服务端等待客户端连接请求的过程。 1int listen(int sockfd, int backlog); accept()： 接受客户端的连接请求，返回一个新的套接字用于与客户端通信。 1int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); connect()： 发起与远程服务器的连接。 1int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); send() 和 recv()： 用于发送和接收数据。 12size_t send(int sockfd, const void *buf, size_t len, int flags);size_t recv(int sockfd, void *buf, size_t len, int flags); TCP 重传 自动重复请求 许多可靠协议的基础是自动重复请求 (ARQ)的概念。 在 ARQ 中，接收方发送其已接收数据的确认，而发送方则重新传输其从未收到确认的数据。 正如我们所讨论的，TCP 将传输数据的序列号保存在内存中并以确认进行响应。传输的数据被放入重传队列中，并且启动与数据相关的定时器。如果在定时器超时之前没有收到数据序列的确认，则会发生重传。 TCP重传 当TCP传输包含数据的报文段时，它会将副本放入重传队列中并启动计时器；当收到该数据的确认时，该段将从队列中删除。如果在定时器超时之前没有收到确认，则重新传输该段。 然而，原来的重传超时计算公式被认为不适用于不同的网络环境,最新的规范化规范可以从 RFC6298中找到。 基本算法相对简单。对于给定的 TCP 发送方，定义状态变量来计算超时： srtt是平滑的往返时间，用于平均分段的往返时间 (RTT) rttvar保存往返时间变化 rto最终保存重传超时，例如以毫秒为单位 简而言之，srtt 充当连续 RTT 的低通滤波器。由于 RTT 可能存在较大的变化，rttvar 用于检测这些变化并防止它们影响平均函数。此外，假设时钟的粒度为 G 秒。 如RFC6298中所述，计算步骤如下： 在第一次 RTT 测量之前： 1rto = 1000ms 在第一个 RTT 测量R上： 123srtt = Rrttvar = R/2rto = srtt + max(G, 4*rttvar) 关于后续测量： 12345alpha = 0.125beta = 0.25rttvar = (1 - beta) * rttvar + beta * abs(srtt - r)srtt = (1 - alpha) * srtt + alpha * rrto = srtt + max(g, 4*rttvar) 计算后rto，如果小于1秒，则四舍五入为1秒。可以提供最大数量，但必须至少为 60 秒 TCP 实现的时钟粒度传统上被估计为相当高，范围从 500 毫秒到 1 秒。然而，像 Linux 这样的现代系统使用的时钟粒度为 1 毫秒。 需要注意的一件事是， 建议 RTO 始终至少为 1 秒。这是为了防止虚假重传，即当某个数据段重传过快时，会导致网络拥塞。在实践中，许多实现选择亚秒级的四舍五入：Linux 使用 200 毫秒。 Karn’s Algorithm Karn 算法是一种防止 RTT 测量给出错误结果的强制算法。它只是指出不应为重传的数据包获取 RTT 样本。 换句话说，TCP 发送方会跟踪其发送的分段是否为重传，并跳过这些确认的 RTT 例程。这是有道理的，因为否则发送方无法区分原始段和重传段之间的确认。 然而，当使用时间戳 TCP 选项时，可以测量每个 ACK 段的 RTT。 管理 RTO 定时器 管理重传定时器相对简单。RFC6298推荐以下算法： 当发送数据段且 RTO 定时器未运行时，将其激活，超时值为rto 当所有未完成的数据段均被确认后，关闭 RTO 定时器 当收到新数据的 ACK 时，用以下值重新启动 RTO 定时器：rto 当 RTO 定时器到期时： 重传最早的未确认段 将 RTO 定时器退后 2 倍，即 ( rto = rto * 2) 启动RTO定时器 此外，当 RTO 值出现回退并且成功进行后续测量时，RTO 值可能会急剧缩小。在进行退避并等待确认时，TCP 实现可能会清除 srtt 和 rttvar。 请求重传 TCP 通常不仅仅依靠 TCP 发送方的计时器来修复丢失的数据包。接收方还可以通知发送方需要重传分段。 重复确认是一种对无序段进行确认的算法，但按最新有序段的序列号进行确认。在三个重复确认之后，TCP 发送方应该意识到它需要重新传输由重复确认通告的段。 此外，选择性确认（SACK）是重复确认的更复杂版本。它是一个 TCP 选项，接收器能够将接收到的序列编码到其确认中。然后发送者立即注意到任何丢失的数据段并重新发送它们。 代码走读 代码结构如下 先看下makefile文件，看看程序是怎么编译出来的？ 123456789101112131415161718192021222324252627282930313233343536CPPFLAGS = -I include -Wall -Werror -pthreadsrc = $(wildcard src/*.c)obj = $(patsubst src/%.c, build/%.o, $(src))headers = $(wildcard include/*.h)apps = apps/curl/curllvl-ip: $(obj) $(CC) $(CFLAGS) $(CPPFLAGS) $(obj) -o lvl-ip @echo @echo &quot;lvl-ip needs CAP_NET_ADMIN:&quot; sudo setcap cap_setpcap,cap_net_admin=ep lvl-ipbuild/%.o: src/%.c $&#123;headers&#125; $(CC) $(CFLAGS) $(CPPFLAGS) -c $&lt; -o $@debug: CFLAGS+= -DDEBUG_SOCKET -DDEBUG_TCP -g -fsanitize=threaddebug: lvl-ipapps: $(apps) $(MAKE) -C tools $(MAKE) -C apps/curl $(MAKE) -C apps/curl-pollall: lvl-ip appstest: debug apps @echo @echo &quot;Networking capabilites are required for test dependencies:&quot; which arping | sudo xargs setcap cap_net_raw=ep which tc | sudo xargs setcap cap_net_admin=ep @echo cd tests &amp;&amp; ./test-run-allclean: rm build/*.o lvl-ip CPPFLAGS 定义了一些编译选项，包括头文件目录、警告标志等。 src 使用wildcard函数列举了src目录下所有的.c文件。 obj 使用patsubst函数将src中的.c文件路径转换为build中的.o文件路径。 headers 列举了include目录下所有的头文件。 apps 定义了一个变量，包含了一个名为curl的应用程序。 lvl-ip 是默认目标规则，依赖于$(obj)。它编译了所有的.o文件并生成可执行文件lvl-ip，然后使用setcap命令赋予了特定的权限。 build/%.o 规则定义了如何将.c文件编译成.o文件。 debug 目标规则用于构建带有调试信息和线程检测的lvl-ip。 apps 目标规则用于构建额外的应用程序。 all 是一个依赖于lvl-ip和apps的目标规则。 test 目标规则用于运行测试，要求一些网络权限。 clean 规则用于清理生成的.o文件和可执行文件。 函数从main函数入口， 在链接阶段，链接器将编译生成的目标文件（例如，.o文件）合并成一个可执行文件。在这个过程中，链接器会解析main函数的地址，将其设置为程序的入口点。 123456789101112131415int main(int argc, char** argv)&#123; /*1. argc（Argument Count）： 这是一个整数，表示命令行参数的数量（argument count）。它表示在运行程序时通过命令行 输入的参数的个数。`argc` 至少为 1，因为程序的名称通常被认为是一个参数。 2. argv（Argument Vector）：这是一个字符指针数组，其中每个指针指向一个字符串，表示实际的命令行参数（argument ` vector）。`argv[0]` 是程序的名称，`argv[1]` 到 `argv[argc-1]` 是通过命令行输入的其他参数。每个参数都以字符串的形式表 示。*/ parse_cli(argc, argv);//该函数可能用于解析命令行参数 argc 和 argv，以便你的程序可以接受和处理命令行输入 init_signals();//该函数可能用于初始化信号处理程序 init_stack();//该函数可能用于初始化程序的堆栈 init_security();//该函数可能用于执行一些与程序安全性相关的初始化操作 run_threads();//启动线程 wait_for_threads();//该函数可能用于等待所有线程执行完毕或达到某种状态 free_stack();//该函数可能用于释放之前初始化的堆栈或相关资源&#125; 12345678static void init_stack()&#123; tun_init(); netdev_init(); route_init(); arp_init(); tcp_init();&#125; tun_init(): 这个函数用于初始化TUN（网络隧道）设备。TUN设备是一种虚拟网络设备，用于在用户空间和内核空间之间传递网络数据包。 netdev_init(): 这个函数用于初始化网络设备。网络设备是计算机网络中的硬件设备或虚拟设备，用于进行数据包的输入和输出。 route_init(): 这个函数用于初始化路由表。路由表用于确定数据包从源地址到目标地址的传输路径。 arp_init(): 这个函数用于初始化ARP（地址解析协议）。ARP协议用于将IP地址映射到物理硬件地址（如MAC地址）。 tcp_init(): 这个函数用于初始化TCP协议。TCP是一种可靠的、面向连接的协议，用于在计算机网络中进行可靠的数据传输。 1234567static void run_threads()&#123; create_thread(THREAD_CORE, netdev_rx_loop);// 创建并启动网络设备接收循环的线程 create_thread(THREAD_TIMERS, timers_start); // 创建并启动定时器的线程 create_thread(THREAD_IPC, start_ipc_listener); // 创建并启动 IPC 监听器的线程 create_thread(THREAD_SIGNAL, stop_stack_handler);// 创建并启动处理停止事件的线程&#125; 这段代码定义了一个名为 create_thread 的函数，用于创建线程并启动执行指定的函数。以下是对代码的主要解释： 1234567static void create_thread(pthread_t id, void *(*func) (void *))&#123; // 使用 pthread_create 函数创建线程 if (pthread_create(&amp;threads[id], NULL, func, NULL) != 0) &#123; // 如果创建线程失败，输出错误信息 print_err(&quot;Could not create core thread\\n&quot;); &#125; } pthread_create 函数： 这是 POSIX 线程库中用于创建线程的函数。它接受四个参数： &amp;threads[id]：指向 pthread_t 类型的变量，用于存储新创建线程的标识符。 NULL：线程的属性，这里设置为默认属性。 func：指向线程执行的函数的指针。 NULL：传递给线程执行函数的参数，这里设置为 NULL。 print_err 函数： 如果创建线程失败，调用 print_err 函数输出错误信息。 这个函数的作用是通过调用 pthread_create 创建线程，并将线程的标识符存储在全局数组 threads 的指定位置。如果创建线程失败，输出错误信息。这样的设计通常用于并发执行多个任务，提高程序的性能和响应性。","categories":[{"name":"编程","slug":"编程","permalink":"https://blackforest1990.github.io/categories/%E7%BC%96%E7%A8%8B/"}],"tags":[{"name":"how to make","slug":"how-to-make","permalink":"https://blackforest1990.github.io/tags/how-to-make/"}]},{"title":"万历十五年读书笔记","slug":"万历十五年读书笔记","date":"2024-01-09T09:42:32.000Z","updated":"2024-01-10T04:15:14.998Z","comments":true,"path":"2024/01/09/万历十五年读书笔记/","link":"","permalink":"https://blackforest1990.github.io/2024/01/09/%E4%B8%87%E5%8E%86%E5%8D%81%E4%BA%94%E5%B9%B4%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","excerpt":"","text":"​ 万历十五年，黄公仁宇之大作，英文名为“1587, A year of No Significance”, 在历史上1587实在为寡淡的一年，但是通过这一年万历皇帝，申时行，张居正，海瑞，戚继光等人的遭遇，阐述出明帝国在结构系统上的硬伤，无论如何的天纵奇才都不可能避免走向衰落。 ​ 明朝的衰败，实为制度的衰败，名为帝国，在本质上无非是数不清的农村合并成的一个集合体，礼仪和道德代替了法律，对于违法的行为作掩饰则被认为忠厚识大体。各个机构之间的联系，从来没有可资遵守的成文条例，所以造成行政效率低下，整个国家不能做到如臂指使的运转。当一个人口众多的国家，各人行动全凭儒家简单粗浅而又无法固定的原则所限制，而法律又缺乏创造性，则其社会发展的程度，必然受到限制。即便是宗旨善良，也不能补助技术之不及。 万历皇帝 ​ 万历皇帝朱翊（yì）钧（jūn）为国家的最高元首，本朝在开国之初曾经设立过丞相的职位，经过一个时期，内阁大学士在某种程度上就行使了丞相的职权。这种以阁臣代行相职的制度，来源于开国之君为了巩固政权而做出的苦心设计，目的是使皇权不被分割，也不致为旁人取代。大学士原来属于文学侍从之臣。由于殿试时文理出众，名列前茅，就可以进入翰林院。翰林几经升转，其中最突出的人物就可以被任命为大学士，供职于文渊阁。由于文渊阁是皇帝的文书机构，和皇帝最为接近，在不设丞相的情况下，这个机构的职权就由于处理政事的需要而越来越大，大学士一职也变成了皇帝的秘书而兼顾问，张居正名为首辅，或称元辅，其他大学士的任命则出于他的推荐。大学士之中有了主次之分，造成了今后朝臣之间的更加复杂的纠纷局面。内阁制度，破坏了皇帝-群臣-相的体系（皇帝负责天命和军事，宰相负责政务和官员任命），造成了文官体系的无比强大。万历皇帝在励精图治以后，发现了文官体系的不可战胜，从此不在做反抗，让帝国慢慢腐烂下去。 张居正 ​ 洪武皇帝两百年以前创建本朝，并确立了整套的政治和经济制度，其主要的着眼点在于保存一个农业社会的俭朴风气。当时全国的文官仅有八千人。所有办理文牍和事务的技术人员称之为“吏”，和文官属于两个不同的阶层，如泾渭之分明。官可以罚降为吏，吏却很少能上升为官。这些吏的薪给极为微薄，仅足以供一家糊。农村的组织方式是以每一乡村为单位，构成一个近于自治的集团，按照中央政府的规定订立自己的乡约。一村内设“申明亭”和“旌善亭”各一座，前者为村中耆老仲裁产业、婚姻、争斗等纠纷的场所，后者则用以表扬村民中为人所钦佩的善行。洪武皇帝所推行的农村政策及一整套的措施，对本朝今后的历史，影响至为深远。其最显著的后果是，在全国的广大农村中遏止了法制的成长发育，而以抽象的道德取代了法律。上自官僚下至村民，其判断是非的标准是“善”和“恶”，而不是“合法”或“非法”。在财政制度上，政府规定了按面积征收田赋，除浙西（当时的浙西包括今日的苏南）而外，其他地区的税率都比较低。征收不分贫富，其限制富户的办法即上述的服役。征收不分贫富，其限制富户的办法为服役。这种服役名目繁多，而且按累进税的原则分派，即家室愈是殷富，其负担也愈是繁重。这种以赢补亏而不由上级机关总揽收支以节约交通、通讯、簿记、仓库管理等各项后勤支出的财政制度贯彻于始终。全国满布着无数的短途运输线，缺乏统一的组织和管理。到后来税收已由实物折为现银。这种原始的方式也由于积重难返，而且中级机构又缺乏组织，而无法完全改变。显而易见，这种财政制度的弊病在于缺乏弹性，不能适应环境而调整。各府县的税率、税额长期凝固，即使耕地的收获量增加，其利益也为业主和高利贷者分润，于国库则无所裨益。 ​ 当张居正出任首辅的时候，本朝已经有了两百年的历史。开国时的理想和所提倡的风气与今天的实际距离已经愈来愈远了。很多问题，按理说应该运用组织上的原则予以解决，但事实上无法办到，只能代之以局部的人事调整。这种积弊的根源在于财政的安排。在开国之初，政府厘定各种制度，其依据的原则是“四书”上的教条，认为官员们应当过简单朴素的生活是万古不磨的真理。从这种观念出发而组成的文官集团，是一个庞大无比的组织，在中央控制下既没有重点，也没有弹性，更谈不上具有随着形势发展而作调整的能力。各种技术力量，诸如交通通讯、分析统计、调查研究、控制金融、发展生产等等则更为缺乏。一个必然的后果，即政府对民间的经济发展或衰退，往往感到隔膜，因之税收和预算不能随之而增加或减缩。财政上死板、混乱与缺乏控制，给予官员的俸禄又微薄到不合实际，官员们要求取得额外收入也就是不可避免的了。以张居正的精明干练，他没有能解决这个问题。他的十年首辅生涯，仅仅刚把问题看清楚。他的一套改革办法使文官们感受到极大的压力而不能成功，而且招致了死后的被清算。 申时行 ​ 申时行为皇帝的老师，张居正死后，申时行担任首辅，接替他的位置，他胸中富有积蓄，但是不近悬崖，不树异帜，在张居正死后，他承认张居正的过错，但并不借此夸大前任的过失，作为自己执政的资本。施政的要诀，仍不外以抽象的方针为主，以道德为一切事业的根基。朝廷最大的任务是促进文官之间的互相信赖与和谐。除非把全部文官罢免，而代之以不同的组织和不同的原则，身为首辅的人只能和文官合作，按照他们的共同意志办事。申时行没有忽略文官的双重性格：即虽称公仆，实系主人；有阳则有阴。他必须恰如其分地处理此中矛盾。时势要求申时行充当和事佬，他就担任这样角色。他不得不把目标降低。他所说的“使不肖者犹知忌惮，而贤者有所依归”，就表现了他调和这阴阳两极的方针。他无意于鼓励不法，但也不能对操守过于认真。他欣赏自己“从中调剂，就事匡维”这一处世和执政的原则，对待皇帝的办法则是“显谏者不若潜移为妙”，因为这种办法既对皇帝的权威无损，而臣下的目的又可以达到。 海瑞 ​ 和很多同僚不同，海瑞不能相信治国的根本大计是在上层悬挂一个抽象的、至美至善的道德标准，而责成下面的人在可能范围内照办，行不通就打折扣。而他的尊重法律，乃是按照规定的最高限度执行。 海瑞充分重视法律的作用并且执法不阿，但是作为一个在圣经贤传培养下成长的文官，他又始终重视伦理道德的指导作用： 凡讼之可疑者，与其屈兄，宁屈其弟；与其屈叔伯，宁屈其侄。与其屈贫民，宁屈富民；与其屈愚直，宁屈刁顽。事在争产业，与其屈小民，宁屈乡宦，以救弊也。事在争言貌，与其屈乡宦，宁屈小民，以存体也。 用这样的精神来执行法律，确实与“四书”的训示相符合。可是他出任文官并在公庭判案，上距“四书”的写作已经两千年，距本朝的开国也已近两百年。这一段有关司法的建议恰恰暴露了这个帝国在制度上长期存在的困难：以熟读诗书的文人治理农民，他们不可能改进这个司法制度，更谈不上保障人权。法律的解释和执行离不开传统的伦理，组织上也没有对付复杂的因素和多元关系的能力。 戚继光 ​ 武将领兵作战，和文官集团的施政原则在根本上是不能相容的。当社会和经济的发展不能平衡，冲突激化，以政治手段调剂无效，通常就会导致战争。有时候严重的天灾造成大面积的饥荒，百姓面对死亡的威胁，也会铤而走险，诉诸武力。但是我们帝国的文官，则一贯以保持各方面的平衡作为施政的前提，如果事情弄到动用武力，对他们来说就是失败的象征。他们具有一种牢不可破的观念，即上自国家，下至个人，不能把力量作为权威。如果一个地区有什么特殊的经济利益，那么就应当加以压抑，而不是提倡。至于天灾足以引起战争，则尤为无知妄说，因为从道德观念来说，天下的事物无不可以共同分配，灾民的暴动乃是小人犯上作乱的劣根性使然。 ​ 在维持军队给养的问题上，同样表现了帝国政府重文轻武的风气。让军人自己组织和管理后方勤务，根本不能考虑；即使是在文官管辖之下，把仓库的地点按照战略需要来作适当的配置，也被看作有背于平衡施政的原则。述种风气还使军人退伍以后不能得到正常的社会地位。本朝治理农民的根本方针是保持他们的淳朴无知，一个士兵退伍还乡，就等于增加一个无业游民，因为他在军队里所学到的技术和养成的起居习惯，已经难于再度适应农村的生活，事情的复杂性就会因之而增加。军官退伍以后所引起的问题更为严重。在别的国家里，一个退伍军官通常都受到应有的尊敬，如果担任民政职务，他的管理经验也能保证他胜任愉快。然而事情适得其反，我们的军官在长期训练中所培养的严格和精确，退伍以后竟毫无用武之地。他会发现在军队以外，人们所重视的是安详的仪表、华丽的文辞、口若悬河的辩才以及圆通无碍的机智。 ​ 也许是有鉴于唐朝藩镇的跋扈，本朝从洪武开始，就具有这重文轻武的趋向。大约经过了一百年，文官集团进入了成熟的阶段，他们的社会地位上升到历史上的最高点；换句话说，也就是武官的社会地位下降到历史上的最低点。这种畸形的出现，原因在于本朝的政治组织为一元化，一元化的思想基础则是两千年来的孔孟之道。如果让军队保持独立的、严格的组织，和文官集团分庭抗礼，这一元化的统治就不可能如所预期地成长、发展，以至于登峰造极。这种制度既经固定，将领们即使出生入死，屡建奇功，其社会影响，也未必抵得上一篇精彩的大块文章。这种制度和风气所造成的严重后果早已被事实所证明。 ​ 面对这样令人焦虑的局面，戚继光的任务决不仅止于单纯地击败倭寇。他首先要组织一支新型的军队，从他的军事著作《纪效新书》中可以看到如何有条不紊地实施他的建军方案：宣布招兵的办法，规定月饷的数字，拟订分配列兵职务的原则，明确官兵的职责，设计队、哨、局的组织，统一武器的规格，颁发旗帜金鼓这一类通讯器材，等等。他所制定的赏罚原则并不完全决定于战斗的胜负。即使大败，有功者仍然要给予奖赏；相反，即使大胜，作战不力和临阵脱逃者仍然要受到处罚。 ​ 在戚继光以前，在军队中受到重视的是个人的武艺，等到他们被有组织的倭寇屡屡击溃以后，当局者才觉悟到一次战斗的成败并非完全决定于个人武艺。戚继光对一个步兵班作了如下的配置：队长一名，火伕一名，战士十名。这这种配置由于左右对称而名为“鸳鸯阵”。右边持方形藤牌的士兵，其主要的任务在于保持既得的位置，稳定本队的阵脚。左边持圆形藤牌的士兵，则要匍匐前进，并在牌后掷出标枪，引诱敌兵离开有利的防御的位置。引诱如果成功，后面的两个士兵则以狼筅把敌人扫倒于地，然后让手持长枪的伙伴一跃而上把敌人刺死戳伤。最后两个手持镋钯的士兵则负责保护本队的后方，警戒侧翼，必要时还可以支援前面的伙伴，构成第二线的攻击力量。可以明显地看出，这一个十二人的步兵班乃是一个有机的集体。预定的战术取得成功，全靠各个士兵分工合作，很少有个人突出的机会。正由于如此，主将戚继光才不惮其烦地再三申明全队人员密切配合的重要性，并以一体赏罚来作纪律上的保证。 ​ 戚继光的方案比较现实。他没有去触动整个的国家体制，而只是脚踏实地，做他职责范围内力所能及的事。他的部队从来没有一个后勤司令，也没有一个固定的军需处和兵工署。在整个国家机构之中，也没有委派过向他的部队作后勤供应的专职人员。他部队中的装备和武器，来源于各府县的分散供应。这种情况自然不能保持武器的质量。戚继光的募兵原则是只收农民，而不收城市居民。他认为来自市井的人都属于狡猾无赖之徒。这种观点，虽然有它的片面性，但揆诸实际，在城市中有固定职业的人是极少自愿从军的。士兵为社会所普遍轻视，其军饷也相当微薄，城市中的应募者绝大多数只是把兵营当作解决食宿的救济所，一有机会就想另谋高就。戚继光的求实精神还表现于使革新不与传统距离过远，更不大事声张。他的部队保留了古老而朴素的农村作风，有时也和卫所内来自军户的部队并肩作战。他们日常的军饷，大体和在农村中充当短工的收入相等，但另设重赏以鼓励士气，一个敌军的头颅，赏额高达白银三十两。在作战中，总兵戚继光不惜初期接战的损失。经验告诉他，战斗无非是击破敌方的军事组织。如果以雷霆万钧之力，加于对方组织重点之上，则其配转运活的枢纽既被消灭，其全局必迅速瓦解。 ​ 在抗倭战争中功绩最为卓著的戚继光不是在理想上把事情做得至善至美的将领，而是最能适应环境以发挥他的天才的将领。他所以获得成功的要点，在于他清醒的现实感。他看清并适应了当时的政治，而把军事技术作为必要的辅助，这是在当时的环境里惟一可以被允许的方案。至于在一个以文人治国的农业国家之内，谁想要极端强调军事效率，提倡技术的发展，而导致军人和文官的并驾齐驱，哪怕他能举出无数动听的理由，在事实上也是绝对办不到的。 ​ 本书清晰透彻，明朝有如submarine sandwich，上面是一块长面包，大而无当，此乃文官集团；下面也是一块长面包，也没有有效的组织，此乃成千上万的农民。其中三个基本的组织原则，此即尊卑男女老幼，没有一个涉及经济及法治和人权，也没有一个可以改造利用。中国以道德代替法律，作者批评得很透彻。但西方的法律，也非道德的根源。比如西方所谓“自由”及“民主”，都是抽象的观念，务必透过每一个国家的地理及历史上的因素，才行得通。英国之民主，即不可能与日本之民主相同，而法国的自由也和美国的自由有差别。大历史的观点，亦即是从“技术上的角度看历史”(technical interpretation of history)。中国的革命，好像一个长隧道，须要一百零一年才可以通过。我们的生命纵长也难过九十九岁。以短衡长，只是我们个人对历史的反应，不足为大历史。将历史的基点推后三五百年才能摄入大历史的轮廓。","categories":[{"name":"历史","slug":"历史","permalink":"https://blackforest1990.github.io/categories/%E5%8E%86%E5%8F%B2/"}],"tags":[{"name":"黄仁宇","slug":"黄仁宇","permalink":"https://blackforest1990.github.io/tags/%E9%BB%84%E4%BB%81%E5%AE%87/"}]},{"title":"CPU调度","slug":"CPU调度","date":"2024-01-03T05:03:58.000Z","updated":"2024-01-19T07:03:37.319Z","comments":true,"path":"2024/01/03/CPU调度/","link":"","permalink":"https://blackforest1990.github.io/2024/01/03/CPU%E8%B0%83%E5%BA%A6/","excerpt":"","text":"基本概念 ​ 多道程序设计的目标是始终有一些进程在运行，以最大限度地提高CPU利用率。在一次性保持内存中有多个进程。当一个进程必须等待时，操作系统将CPU从该进程中取走，并将CPU交给另一个进程。这种类型的调度是操作系统功能的基本部分。几乎所有计算机资源在使用之前都会进行调度。当然，CPU是主要的计算机资源之一。因此，它的调度对操作系统设计至关重要。 CPU-I/O Burst Cycle 进程的执行包括CPU执行和I/O等待的循环。进程在这两种状态之间交替。进程执行始于一个CPU脉冲。接着是一个I/O脉冲，然后是另一个CPU脉冲，再接着是另一个I/O脉冲，如此往复。最终，最后一个CPU脉冲以系统请求终止执行而结束。 CPU脉冲的持续时间已经得到广泛测量。尽管它们在进程之间和计算机之间变化很大，但它们倾向于具有类似于下图所示的频率曲线。该曲线通常被描述为指数或超指数，其中有大量短的CPU脉冲和少量长的CPU脉冲。 I/O密集型程序通常有许多短的CPU脉冲。而CPU密集型程序可能有一些长的CPU脉冲。这种分布在选择适当的CPU调度算法时可能很重要。 CPU调度器 ​ 每当CPU变为空闲状态，操作系统必须选择就绪队列中的一个进程来执行。选择过程由短期调度器，或称为CPU调度器，执行。调度器从内存中准备执行的进程中选择一个，并分配CPU给该进程。 ​ 需要注意的是，就绪队列不一定是先进先出（FIFO）队列。当我们考虑各种调度算法时，就绪队列可以被实现为FIFO队列、优先级队列、树状结构，或者仅仅是一个无序的链表。就绪队列中的所有进程都排队等待在CPU上运行的机会。队列中的记录通常是进程的PCB。 抢占式调度 CPU调度决策可能发生在以下四种情况下： 当一个进程从运行状态切换到等待状态时（例如，由于I/O请求或对子进程终止的wait()调用导致） 当一个进程从运行状态切换到就绪状态时（例如，发生中断时） 当一个进程从等待状态切换到就绪状态时（例如，I/O完成时） 当一个进程终止时 ​ 对于情况1和4，从调度的角度来看没有选择。必须选择一个新的进程（如果在就绪队列中存在的话）来执行。然而，对于情况2和3，有选择的余地。 当调度仅在情况1和4下发生时，我们称调度方案为非抢占式。否则，它是抢占式的。在非抢占式调度下，一旦CPU被分配给一个进程，该进程将保持CPU，直到它通过终止或切换到等待状态释放CPU。Windows 95引入了抢占式调度，之后的所有Windows操作系统版本都使用了抢占式调度。Macintosh的Mac OS X操作系统也使用抢占式调度；Macintosh操作系统的早期版本依赖于合作式调度。合作式调度是某些硬件平台上唯一可用的方法，因为它不需要抢占式调度所需的特殊硬件（例如计时器）。 不幸的是，抢占式调度可能导致多个进程共享数据时出现竞态条件。考虑两个共享数据的进程的情况。在一个进程正在更新数据时，它被抢占以便第二个进程可以运行。然后，第二个进程试图读取数据，这时数据处于不一致的状态。这 抢占还影响操作系统内核的设计。在处理系统调用时，内核可能正忙于代表一个进程进行活动。这些活动可能涉及更改重要的内核数据（例如I/O队列）。如果进程在这些更改的过程中被抢占，并且内核（或设备驱动程序）需要读取或修改相同的结构，会发生混乱。包括大多数UNIX版本在内的某些操作系统通过等待系统调用完成或I/O块发生之前进行上下文切换来处理这个问题。这种方案确保内核结构简单，因为内核不会在内核数据结构处于不一致状态时抢占一个进程。不幸的是，这种内核执行模型对支持必须在给定时间范围内完成执行的实时计算的情况不利。 ​ 由于中断可以在任何时候发生（根据定义），并且因为内核不能总是忽略它们，受中断影响的代码段必须在同时使用时受到保护。操作系统需要几乎在任何时候都能接受中断。否则，可能会丢失输入或覆盖输出。为了确保这些代码段不会被多个进程同时访问，它们在进入时禁用中断，而在退出时重新启用中断。需要注意的是，禁用中断的代码段并不经常发生，通常包含很少的指令。 Dispatcher 参与CPU调度功能的另一个组件是调度程序（dispatcher）。调度程序是一个模块，它将CPU的控制权交给短期调度器选择的进程。这个功能涉及以下内容： • 切换上下文 • 切换到用户模式 • 跳转到用户程序中重新启动该程序的正确位置 调度程序应尽可能快，因为它在每次进程切换时被调用。调度程序停止一个进程并启动另一个进程运行所需的时间被称为调度延迟。 调度标准 不同的CPU调度算法具有不同的特性，选择特定算法可能会偏向某一类进程。在选择在特定情况下使用哪种算法时，我们必须考虑各种算法的特性。 有许多用于比较CPU调度算法的标准。用于比较的特性在判断哪个算法最好时可能会有很大的差异。这些标准包括： CPU利用率CPU utilization。我们希望保持CPU尽可能繁忙。在概念上，CPU利用率可以从0到100％。在实际系统中，它应该在40％（对于轻载系统）到90％（对于重载系统）之间。 吞吐量Throughput 。如果CPU正在执行进程，那么工作正在进行。工作的一个度量是每个时间单位完成的进程数量，称为吞吐量。对于长时间进程，这个速率可能是每小时一个进程；对于短交易，它可能是每秒十个进程。 周转时间Turnaround time。从某个进程的角度来看，重要的标准是执行该进程需要多长时间。从提交进程到完成的时间间隔是周转时间。周转时间是在等待进入内存、在就绪队列中等待、在CPU上执行以及进行I/O的时间段的总和。 等待时间Waiting time。CPU调度算法不会影响进程执行或进行I/O的时间。它只影响进程在就绪队列中等待的时间。等待时间是在就绪队列中等待的时间段的总和。 响应时间Response time。在交互式系统中，周转时间可能不是最佳标准。通常，进程可以在相当早的时候产生一些输出，并且在将先前的结果输出给用户的同时可以继续计算新的结果。因此，另一种度量是从提交请求到产生第一个响应的时间。这个度量称为响应时间，是启动响应所需的时间，而不是输出响应所需的时间。周转时间通常受输出设备速度的限制。 调度算法 First-Come, First-Served Scheduling ​ 最简单的算法就是FCFS算法，采用这种方案，先请求CPU的进程先分配到CPU。FCFS策略可以用FIFO队列实现。当一个进程进入到就绪队列，其PCB链接到队列的尾部。当CPU空闲的时候，CPU分配给位于队列头的进程，接着该运行进程就从队列里删除。 会产生护航效应（convoy effect）：短进程在长进程后面排队（I/O密集型进程等待CPU密集型进程） Shortest-Job-First Scheduling ​ 这一算法将每个进程与其下一个 CPU 区间段相关联。当 CPU 为空闲时，它会赋给具有最短 CPU 区间的进程。如果两个进程具有同样长度，那么可以使用FCFS 调度来处理。有两种方案，抢占与非抢占： ●非抢占：一旦CPU给了进程，它就不能被抢占，直到完成它的CPU burst ●抢占：如果一个新进程到达时的CPU burst长度小于当前执行进程的剩余时间，则抢占。这个方案被称为最短剩余时间优先(Shortest-Remaining-Time-First SRTF) SJF 调度算法可证明为最佳的，这是因为对于给定的一组进程， SJF 算法的平均等待时间最小。 虽然 SJF 算法最佳，但是它不能在短期CPU 调度层次上加以实现。因为没有办法知道下一个 CPU 区间的长度。→种方法是近似SJF 调度。虽然不知道下一个CPU 区间的长度，但是可以预测它。 Priority Scheduling ■ 每个进程都关联有一个优先级数（整数） ■ CPU分配给具有最高优先级的进程（最小整数表示最高优先级） ​ ● 抢占式 ​ ● 非抢占式 ■ SJF是一种优先级调度，其中优先级是预测的下一个CPU执行时间 优先级调度算法的一个主要问题是无穷阻塞(indefinite blocking) 或饥饿 (starvation) 。可以运行但缺乏 CPU 的进程可认为是阻塞的，它在等待CPU。优先级调度算法会使某个低优先级进程无穷等待 CPU。 低优先级进程无穷等待问题的解决之一是老化(aging) 。老化是一种技术，以逐渐增加在系统中等待很长时间的进程的优先级。 Round-Robin Scheduling 为了实现 RR 调度，将就绪队列保存为进程的FIFO 队列。新进程增加到就绪队列的尾部。 CPU 调度程序从就绪队列中选择第一个进程，设置定时器在个时间片之后中断，再分派该进程。 每个进程得到一个小单位的CPU时间（time quantum or time slice），通常是10-100毫秒。经过此时间后，该进程将被抢占并添加到准备队列的末尾。 如果准备队列中有n个进程，time quantum为q，那么每个进程一次获得1/n的CPU时间，最多为q时间单位。没有进程等待的时间超过（n-1）q时间单位。 算法的性能很大程度上依赖于时间片的大小。在极端情况下，如果时间片非常大，那么RR算法与 FCFS 算法一样。如果时间片很小(如 1 ms) 时，那么 RR 算法称为处理器共享， (从理论上来说 )n 个进程对于用户都有它自己的处理器，速度为真正处理器速度的 1/n 。这种方法用在 Control Data Corporation (CDC) 的硬件上，可以用1组硬件和10 组寄存器实现 10 个外设处理器。硬件为一组寄存器执行一个指令，然后为下一组执行。这种循环不断进行，形成了10 个慢处理器而不是1个快处理器。(实际上，由于处理器比内存快很多，而每个指令都要使用内存，所以这些处理器并不比10 个真正处理器慢很多。时间片较小的时候同样要考虑上下文切换问题。 ​ Multilevel Queue Scheduling 在进程可容易地分成不同组的情况下，可以建立另一类调度算法。例如，一个常用的划分方法是前台(交互）进程和后台(批处理）进程。 多级队列调度算法 (multilevel queue scheduling algorithm) 将就绪队列分成多个独立队列。根据进程的属性，如内存大小、进程优先级、进程类型，一个进程被永久地分配到一个队列。每个队列有自己的调度算法。例如，前台进程和后台进程可处于不同队列。前台队列可能采用 RR 算法调度，而后台队列可能采用 FCFS 算法调度。 调度方式： ​ ● 固定优先级调度；（即，先为前台服务，然后为后台服务）。可能导致饥饿。 ​ ● 时间片 – 每个队列都获得一定量的CPU时间，可以在其进程之间进行调度；即，循环轮询中的80%分配给前台，FCFS中的20%分配给后台。 Multilevel Feedback Queue Scheduling ​ 通常在使用多级队列调度算法时，进程进入系统时被永久地分配到一个队列。例如，如果前台进程和后台进程分别有独立队列，进程并不从一个队列转移到另一个队列，这是因为进程并不改变前台或后台性质。这种设置的优点是低调度开销，缺点是不够灵活。与之相反，多级反馈队列调度算法 (multilevel feedback queue scheduling algorithm) 允许进程在队列之间移动。主要思想是根据不同CPU 区间的特点以区分进程。如果进程使用过多 CPU 时间，那么它会被转移到更低优先级队列。这种方案将I/O约束和交互进程留在更高优先级队列。此外，在较低优先级队列中等待时间过长的进程会被转移到更高优先级队列。这种形式的老化阻止饥饿的发生。 例如，考虑一个多级反馈队列调度程序，它有三个队列，从0~2。调度程序首先执行队列0内的所有进程。只有当队列0为空时，它才能执行队列1内的进程。类似地，只有队列0和1都为空时，队列2的进程才能执行。到达队列1的进程会抢占队列2的进程。同样，到达队列0的进程会抢占队列1的进程。进入就绪队列的进程被放入队列0内。队列0中的每个进程都有 8ms 的时间片。如果一个进程不能在这一时间内完成，那么它就被移到队列1的尾部。如果队列0为空，队列1的头部进程会得到1个 16 ms 的时间片。如果它不能完成，那么将被抢占，并被放到队列2 中。只有当队列0和1为全时，队列2内的进程才可根据 FCFS 来运行。、 这种调度算法将给那些 CPU 区间不超过 8 ms 的进程最高优先级。这种进程可以很快地得到 CPU ，完成其 CPU 区间，并处理下一个 I/O 区间。所需超过 8 ms 但不超过 24 ms的进程也会很快被服务，但是它们的优先级比最短进程要低一点。长进程会自动沉入到队列2，在队列0和队列1不用的 CPU 周期可按FCFS顺序来服务。 通常，多级反馈队列调度程序可由下列参数来定义: 队列数量。 每个队列的调度算法。 用以确定何时升级到更高优先级队列的方法。 用以确定何时降级到更低优先级队列的方法。 用以确定进程在需要服务时应进入哪个队列的方法。 线程调度 为了能在CPU上运行，用户线程必须映射到相应的内核级线程，尽管这种映射可能是间接的，可能使用轻量级进程（LWP）。 竞争范围 ​ 用户线程与内核线程的区别之一在于它们是如何被调度的。在执行多对一模型和多对多模型的系统上，线程库调度用户级线程到一个有效的LWP上运行，这被称为进程竞争范围 (process-contention scope, PCS) 方法，因为 CPU竞争发生在属于相同进程的线程之间。当提及线程库调度用户线程到有效的LWP时，并不意味着线程实际上就在 CPU 上运行，这需要操作系统将内核线程调度到物理 CPU 上。为了决定调度哪个内核线程到 CPU ，内核采用系统竞争范围 (system-contention scope, SCS)方法来进行。采用SCS 调度方法，竞争 CPU 发生在系统的所有线程中，采用一对一的模型(如 WindowsXP 、Solaris 9 、Linux)的系统，调度仅使用 SCS 方法。 ​ 典型地，PCS 是根据优先级完成的一一调度程序选择具有最高优先级的可运行的线程来运行。用户级线程优先级由程序员给定，并且不被线程库调节，尽管有些线程库允许程序员改变线程的优先级。值得注意的是，PCS 通常抢占当前具有较高优先级的正在运行的线程，但在具有相同优先级的线程间并没有时间分割的保证。 Pthread 调度 现在，我们重点介绍了允许在线程创建期间指定PCS或SCS的POSIX Pthread API。 • PTHREAD SCOPE PROCESS 使用PCS调度线程。 • PTHREAD SCOPE SYSTEM 使用SCS调度线程。 在实现多对多模型的系统上，PTHREAD SCOPE PROCESS策略将用户级线程调度到可用的LWPs上。LWPs的数量由线程库维护，可能使用调度器激活的方式。对于多对多系统，PTHREAD SCOPE SYSTEM调度策略将为每个用户级线程创建并绑定一个LWP，有效地使用一对一策略映射线程。 Pthread IPC提供了两个函数来获取和设置争用范围策略： • pthread_attr_setscope(pthread_attr_t *attr, int scope) • pthread_attr_getscope(pthread_attr_t *attr, int *scope) 这两个函数的第一个参数都包含指向线程的属性集的指针。pthread_attr_setscope()函数的第二个参数传递PTHREAD SCOPE SYSTEM或PTHREAD SCOPE PROCESS值，指示如何设置争用范围。对于pthread_attr_getscope()，第二个参数包含一个指向int值的指针，该值设置为争用范围的当前值。如果发生错误，这些函数中的每一个都返回非零值。 如下，我们展示了一个Pthread调度API。程序首先确定了现有的争用范围，并将其设置为PTHREAD SCOPE SYSTEM。然后，它创建了五个单独的线程，这些线程将使用SCS调度策略运行。请注意，在某些系统上，只允许特定的争用范围值。例如，Linux和Mac OS X系统仅允许PTHREAD SCOPE SYSTEM。 123456789101112131415161718192021222324252627282930313233343536#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#define NUM_THREADS 5int main(int argc, char *argv[])&#123; int i, scope; pthread_t_tid[NUM_THREADS]; pthread_attr_t attr; /* get the default attributes */ pthread_attr_init(&amp;attr); /* first inquire on the current scope */ if (pthread_attr_getscope(&amp;attr, &amp;scope) != 0) fprintf(stderr, &quot;Unable to get scheduling scope\\n&quot;); else &#123; if (scope == PTHREAD_SCOPE_PROCESS) printf(&quot;PTHREAD_SCOPE_PROCESS&quot;); else if (scope == PTHREAD_SCOPE_SYSTEM) printf(&quot;PTHREAD_SCOPE_SYSTEM&quot;); else fprintf(stderr, &quot;Illegal scope value.\\n&quot;); &#125; /* set the scheduling algorithm to PCS or SCS */ pthread_attr_setscope(&amp;attr, PTHREAD_SCOPE_SYSTEM); /* create the threads */ for (i = 0; i &lt; NUM_THREADS; i++) pthread_create(&amp;tid[i],&amp;attr,runner,NULL); /* now join on each thread */ for (i = 0; i &lt; NUM_THREADS; i++) pthread_join(tid[i], NULL);&#125;/* Each thread will begin control in this function */void *runner(void *param)&#123; /* do some work ... */ pthread exit(0);&#125; 多处理器调度 ​ 迄今为止，主要集中讨论了单处理器系统内的CPU调度问题。如果有多个CPU ，则负载均衡(load sharing) 成为可能，但调度问题也相应地变得更为复杂。己试验过许多可能的方法，与单处理器中的CPU调度算法一样，没有最好的解决方案。下面简要讨论多处理器调度的相关问题。其中主要讨论处理器功能相同(或同构)的系统，可以将任何处理器用于运行队列内的任何进程(但请注意，即使对同构多处理器，也有一些调度限制。考虑一个系统，有一个I/O设备与一个处理器通过私有总线相连，希望使用该设备的进程必须调度到该处理器上运行)。 多处理器调度的方法 ​ 在一个多处理器中，CPU 调度的一种方法是让一个处理器(主服务器)处理所有的调度决定、I/O 处理以及其他系统活动，其他的处理器只执行用户代码。这种非对称多处理(asymmetric multiprocessing) 方法更为简单，因为只有一个处理器访问系统数据结构，减轻了数据共享的需要。另一种方法是使用对称多处理 (symmetric multiprocessing, SMP) 方法，即每个处理器自我调度。所有进程可能处于一个共同的就绪队列中，或每个处理器都有它自己的私有就绪进程队列。无论如何，调度通过每个处理器检查共同就绪队列并选择一个进程来执行。如果多个处理器试图访问和更新一个共同数据结构，那么每个处理器必须仔细编程:必须确保两个处理器不能选择同一进程，且进程不会从队列中丢失。现代操作系统多采用 SMP方法。 处理器亲和性 ​ 考虑一个进程在特定处理器上运行时对缓存内存的影响。进程最近访问的数据填充了该处理器的缓存。因此，进程的连续内存访问往往可以在缓存内存中得到满足。现在考虑一下如果进程迁移到另一个处理器会发生什么。必须使第一个处理器的缓存内存无效，并重新填充第二个处理器的缓存。由于使缓存无效和重新填充的成本很高，大多数SMP系统试图避免将进程从一个处理器迁移到另一个处理器，而是尝试让进程继续在同一处理器上运行。这被称为处理器亲和性，即进程对其当前运行的处理器有亲和性。 ​ 处理器亲和性有多种形式。当操作系统有一个策略，尝试使进程继续在同一处理器上运行（但不能保证这样做）时，我们有一个称为软亲和性的情况。在这里，操作系统将尝试将进程保持在单个处理器上，但进程可能在处理器之间迁移。相反，一些系统提供支持硬亲和性的系统调用，从而允许进程指定其可以运行的处理器子集。许多系统同时提供软亲和性和硬亲和性。例如，Linux实现了软亲和性，但它也提供了sched_setaffinity()系统调用，支持硬亲和性。 系统的主存体系结构可能会影响处理器亲和性问题。下图演示了一种特征非均匀存储访问（NUMA）的体系结构，在这种体系结构中，CPU对主存储器的某些部分的访问速度比对其他部分的速度更快。通常，这发生在包含组合CPU和内存板的系统中。板上的CPU可以更快地访问该板上的内存，而不是系统中其他板上的内存。如果操作系统的CPU调度器和内存放置算法能够协同工作，那么被分配到特定CPU的进程可以在该CPU所在的板上分配内存。这个例子还表明，操作系统通常并不像操作系统教科书中描述的那样清晰定义和实现。相反，操作系统各部分之间的“实线”通常只是“虚线”，算法以旨在优化性能和可靠性的方式创建连接。 负载均衡 ​ 在SMP系统中，保持所有处理器的工作负载均衡，以完全利用多处理器的优点，这是很重要的。否则，将会产生一个或多个处理器空闲，而其他处理器处于高工作负载状态，并有一系列进程在等待 CPU 。负载均衡(load balancing) 设法将工作负载平均地分配到SMP系统中的所有处理器上。值得注意的是，负载均衡通常只是对那些拥有自己私有的可执行进程的处理器而言是必要的。在具有共同队列的系统中，通常不需要负载均衡，因为一旦处理器空闲，它立刻从共同队列中取走一个可执行进程。但同样值得注意的是，在绝大多数支持 SMP的当代操作系统中，每个处理器都具有一个可执行进程的私有队列。 ​ 负载平衡通常有两种方法:push migration和 pull migration。对于 push migration，一个特定的任务周期性地检查每个处理器上的负载，如果发现不平衡，即通过将进程从超载处理器移到(或推送)空闲或不太忙的处理器，从而平均地分配负载。当空闲处理器从一个忙的处理器上推送 (pull)一个等待任务时，发生pull migration. push migration 和 pull migration 不能相互排斥，事实上，在负载平衡系统中它们常被并行地实现。例如，Linux 每过 200 ms (push migration) 或每当一个处理器的运行队列为空时(pull migration) ,运行其负载平衡算法。 有趣的是,负载平衡常会抵消处理器亲和性的优点。即保持一个进程在同一处理器上运行的优点在于，进程可以利用它在处理器缓存中的数据。无论是从一个处理器向另一处理器 push 或 pull 进程，都使此优点失效。事实上，在系统工程中，关于何种方式是最好的，没有绝对的规则。因此，在某些系统中，空闲的处理器常会从非空闲的处理器中 pull 进程，而在另一些系统中，只有当不平衡达到一定额度后才会移动进程。 多核处理器 ​ 传统上，SMP系统通过提供多个物理处理器来允许多个线程同时运行。然而，计算机硬件的一种最新做法是在同一物理芯片上放置多个处理器核心，从而形成多核处理器。每个核心维护其体系结构状态，因此在操作系统看来，它就像是一个独立的物理处理器。 使用多核处理器的SMP系统比每个处理器都有自己的物理芯片的系统更快且消耗更少的电力。 多核处理器可能会复杂化调度问题。让我们考虑一下可能发生的情况。研究人员发现，当处理器访问内存时，它会花费大量时间等待数据变得可用。这种情况被称为内存停顿，可能由于各种原因引起，例如缓存未命中（访问不在缓存内存中的数据）。下图说明了内存停顿。在这种情况下，处理器可能会花费高达50％的时间等待从内存获取数据。 为了解决这种情况，许多最近的硬件设计在多线程处理器核心中实现了两个（或更多）硬件线程分配给每个核心。这样，如果一个线程在等待内存时停滞，核心可以切换到另一个线程。下图说明了一个双线程处理器核心，其中线程0的执行和线程1的执行交错进行。从操作系统的角度看，每个硬件线程都表现为一个逻辑处理器，可用于运行软件线程。因此，在双线程，双核系统上，向操作系统呈现了四个逻辑处理器。UltraSPARC T3 CPU每个芯片有16个核心和每个核心8个硬件线程。从操作系统的角度看，似乎有128个逻辑处理器。 总的来说，有两种方法可以使处理核心多线程：粗粒度和细粒度多线程。对于粗粒度多线程，线程在处理器上执行，直到发生长延迟事件，例如内存停顿。由于长延迟事件引起的延迟，处理器必须切换到另一个线程开始执行。然而，由于在其他线程可以在处理器核心上开始执行之前，必须刷新指令流水线，因此在线程之间切换的成本很高。一旦新线程开始执行，它就开始用其指令填充流水线。细粒度（或交错）多线程在更细的粒度上（通常在指令周期的边界处）在线程之间进行切换。然而，细粒度系统的体系结构设计包括用于线程切换的逻辑。因此，在线程之间切换的成本很小。 注意，多线程多核处理器实际上需要两个不同级别的调度。在一个级别上是操作系统在选择在每个硬件线程（逻辑处理器）上运行哪个软件线程时必须做出的调度决策。对于这个调度级别，操作系统可以选择任何调度算法。第二个调度级别指定每个核心如何决定运行哪个硬件线程。在这种情况下有几种策略可供采用。前面提到的UltraSPARC T3使用简单的循环调度算法将8个硬件线程调度到每个核心。另一个例子是Intel Itanium，它是一个双核处理器，每个核心有两个硬件管理的线程。分配给每个硬件线程的是一个动态紧急值，范围从0到7，其中0表示最低的紧急值。 实时调度（Real-Time Scheduling） 实时操作系统的CPU调度涉及到一些特殊的问题。一般来说，我们可以区分软实时系统和硬实时系统。软实时系统不能保证关键实时进程何时被调度。它们只能保证该进程会优先于非关键进程。硬实时系统有更严格的要求。任务必须在其截止日期之前得到服务；在截止日期过期后提供的服务与没有服务是一样的。 最小化延迟 考虑实时系统的事件驱动特性。系统通常在实时等待事件发生。事件可能在软件中发生，比如定时器到期，也可能在硬件中发生，比如远程控制的车辆检测到它正在接近障碍物。当事件发生时，系统必须尽快响应并对其进行服务。我们将事件延迟定义为事件发生到服务完成经过的时间。 通常，不同的事件有不同的延迟要求。例如，防抱死刹车系统的延迟要求可能是3到5毫秒。也就是说，从车轮首次检测到打滑的时刻起，防抱死刹车系统有3到5毫秒的时间来响应并控制情况。任何需要更长时间的响应都可能导致汽车失控。相反，控制飞机上雷达的嵌入式系统可能容忍几秒钟的延迟周期。 有两种延迟影响实时系统性能： 中断延迟 调度延迟 中断延迟是指从中断到达CPU到开始服务中断的例行程序的时间段。当发生中断时，操作系统必须首先完成正在执行的指令并确定发生的中断类型。然后，在使用特定的中断服务例行程序（ISR）服务中断之前，它必须保存当前进程的状态。执行这些任务所需的总时间就是中断延迟。显然，对于实时操作系统来说，最小化中断延迟至关重要，以确保实时任务得到及时关注。事实上，对于硬实时系统，中断延迟不仅需要最小化，还必须受到约束，以满足这些系统的严格要求。 影响中断延迟的一个重要因素是中断在内核数据结构更新期间被禁用的时间。实时操作系统要求只在很短的时间内禁用中断。 调度调度程序停止一个进程并启动另一个进程所需的时间被称为调度延迟。为实时任务提供对CPU的即时访问要求实时操作系统最小化这种延迟。保持调度延迟低的最有效技术是提供具有抢占性内核。调度延迟的冲突阶段有两个组成部分： 抢占内核中正在运行的任何进程 低优先级进程释放高优先级进程所需的资源 例如，在Solaris中，禁用抢占的调度延迟超过100毫秒。启用抢占后，它减少到小于1毫秒。 Priority-Based Scheduling 实时操作系统最重要的特性之一是在实时进程需要CPU时立即做出响应。因此，实时操作系统的调度器必须支持基于优先级的抢占式算法。回顾一下，基于优先级的调度算法根据进程的重要性为每个进程分配一个优先级；更重要的任务被分配比被视为不太重要的任务更高的优先级。如果调度器还支持抢占，那么如果一个更高优先级的进程可用于运行，当前在CPU上运行的进程将被抢占。 请注意，提供一个抢占性的、基于优先级的调度器仅保证软实时功能。硬实时系统必须进一步保证实时任务将按照其截止日期要求进行服务，而要实现这样的保证需要额外的调度特性。 然而，在我们继续讨论各个调度器的详细信息之前，我们必须定义要进行调度的进程的某些特征。首先，这些进程被视为周期性的。也就是说，它们需要在固定的时间间隔（周期）内使用CPU。一旦周期性进程获得了CPU，它有一个固定的处理时间t，一个截止日期d，必须在此截止日期之前由CPU服务，并且有一个周期p。处理时间、截止日期和周期之间的关系可以表示为0 ≤ t ≤ d ≤ p。周期性任务的速率为1/p。下图说明了周期性进程随时间的执行情况。调度程序可以利用这些特性，根据进程的截止日期或速率要求分配优先级。 这种调度形式的不寻常之处在于，一个进程可能必须向调度器宣告其截止日期要求。然后，使用一种称为准入控制算法的技术，调度器执行以下两种操作之一。如果能够保证任务将按时完成，则接受该进程，并保证该进程将按时完成，否则拒绝请求，因为无法保证该任务将按照其截止日期得到服务。 速率单调调度 速率单调调度算法（Rate-Monotonic Scheduling）使用静态优先级策略和抢占来调度周期性任务。如果正在运行一个优先级较低的进程，并且有一个优先级更高的进程可用于运行，那么它将抢占较低优先级的进程。进入系统时，每个周期性任务被分配一个与其周期成反比的优先级。周期越短，优先级越高；周期越长，优先级越低。这个策略背后的理念是将更频繁需要CPU的任务分配更高的优先级。此外，假设周期性进程的处理时间对于每个CPU突发都是相同的。也就是说，每次进程获取CPU时，其CPU突发的持续时间是相同的。 让我们考虑一个例子。我们有两个进程P1和P2。P1和P2的周期分别为50和100，即p1 = 50和p2 = 100。P1的处理时间为t1 = 20，P2的处理时间为t2 = 35。每个进程的截止日期要求在其下一个周期的开始之前完成其CPU突发。我们首先要问自己是否可能安排这些任务，使每个任务都满足其截止日期。如果我们将进程Pi的CPU利用率定义为其突发到其周期的比值——t1/p1——则P1的CPU利用率为20/50 = 0.40，P2的CPU利用率为35/100 = 0.35，总CPU利用率为75％。因此，似乎我们可以以这样的方式安排这些任务，使它们都满足其截止日期，同时仍然保留CPU可用周期。 假设我们为P2分配一个比P1更高的优先级。在这种情况下，P1和P2的执行如下图所示。正如我们所见，P2首先开始执行，并在时间35完成。此时，P1开始运行；它在时间55完成其CPU突发。然而，P1的第一个截止日期是在时间50，因此调度器导致P1错过了其截止日期。 现在假设我们使用速率单调调度，其中我们为P1分配比P2更高的优先级，因为P1的周期比P2短。在这种情况下，这些进程的执行如下图所示。P1首先启动并在时间20完成其CPU突发，从而满足其第一个截止日期。P2在这时开始运行，并运行到时间50。此时，它被P1抢占，尽管它的CPU突发仍有5毫秒未完成。P1在时间70完成其CPU突发，此时调度器恢复P2。P2在时间75完成其CPU突发，也满足其第一个截止日期。系统在时间100之前处于空闲状态，然后再次调度P1。 速率单调调度被认为是最优的，因为如果一组进程无法通过这种算法进行调度，那么任何分配静态优先级的其他算法都不能进行调度。接下来，让我们看一组不能使用速率单调算法进行调度的进程。假设进程P1的周期为p1 = 50，CPU突发为t1 = 25。对于P2，相应的值为p2 = 80和t2 = 35。速率单调调度会为进程P1分配更高的优先级，因为它的周期较短。这两个进程的总CPU利用率为(25/50)+(35/80) = 0.94，因此似乎这两个进程可以被调度，并仍然使CPU有6％的可用时间。下图显示了进程P1和P2的调度。最初，P1运行直到在时间25完成其CPU突发。然后，P2开始运行，并一直运行到时间50，然后被P1抢占。此时，P2的CPU突发仍有10毫秒未完成。进程P1运行直到时间75；因此，P2错过了在时间80完成其CPU突发的截止日期。 因此，尽管速率单调调度是最优的，但它有一个限制：CPU利用率是有界的，而且并不总是能够充分最大化CPU资源。调度N个进程的最坏情况CPU利用率是。对于系统中的一个进程，CPU利用率为100％，但随着进程数量接近无穷大，它会下降到约69％。对于两个进程，CPU利用率约为83％。 最早截止期优先调度 最早截止期优先调度（Earliest-Deadline-First Scheduling，简称EDF）根据截止期动态分配任务的优先级。截止期越早，优先级越高；截止期越晚，优先级越低。在EDF策略下，当一个进程变为可运行状态时，它必须向系统宣告其截止期要求。优先级可能需要根据新可运行进程的截止期进行调整。请注意，这与速率单调调度不同，速率单调调度中优先级是固定的。 p1 = 50和t1 = 25，p2 = 80和t2 = 35。这些进程的EDF调度显示在下图中。进程P1具有最早的截止期，因此其初始优先级高于进程P2。进程P2在P1的CPU执行结束时开始运行。然而，与速率单调调度允许P1在其下一个周期开始时抢占P2不同，EDF调度允许进程P2继续运行。P2现在比P1具有更高的优先级，因为其下一个截止期（在时间80）比P1的（在时间100）更早。因此，P1和P2都满足了第一个截止期。进程P1在时间60再次开始运行，并在时间85完成其第二个CPU执行，也在时间100满足其第二个截止期。P2在此时开始运行，只是在P1在时间100的下一个周期开始时被抢占。P2被抢占是因为P1的截止期（时间150）比P2的（时间160）更早。在时间125，P1完成其CPU执行，P2恢复执行，于时间145完成，并满足其截止期。系统在时间150直到P1再次被调度时为空闲。 与速率单调算法不同，EDF调度不要求进程是周期性的，也不要求进程每个执行周期需要固定的CPU时间。唯一的要求是当进程变为可运行状态时，它必须向调度程序宣告其截止期。EDF调度的吸引力在于它在理论上是最优的，理论上它可以调度进程，使每个进程都能满足其截止期要求，而CPU利用率将达到100％。然而，在实践中，由于进程间切换的成本和中断处理的开销，不可能达到这种CPU利用率水平。 比例份额调度 比例份额调度器通过在所有应用程序之间分配 T 份额来运行。每个应用程序可以获得 N 份额的时间，从而确保该应用程序将获得总处理器时间的 N/T。例如，假设要在三个进程 A、B 和 C 之间分配 T = 100 份额的总时间。A 被分配了 50 份额，B 被分配了 15 份额，C 被分配了 20 份额。这个方案确保了 A 将拥有总处理器时间的 50%，B 将拥有 15%，C 将拥有 20%。 比例份额调度器必须与一个入场控制策略配合工作，以确保应用程序获得其分配的时间份额。入场控制策略将仅在有足够份额可用时才接受请求特定数量份额的客户端。在我们当前的例子中，我们已经分配了 50 + 15 + 20 = 85 份额的总共 100 份额。如果一个新的进程 D 请求 30 份额，入场控制器将拒绝 D 进入系统。 POSIX Real-Time Scheduling POSIX标准还为实时计算提供了扩展—POSIX.1b。在这里，我们介绍了一些与调度实时线程相关的POSIX API。POSIX定义了两个用于实时线程的调度类别： SCHED_FIFO SCHED_RR SCHED_FIFO根据先到先服务的原则使用FIFO队列调度线程。然而，在相同优先级的线程之间没有时间切片。因此，FIFO队列前面的最高优先级实时线程将获得CPU，直到它终止或阻塞。SCHED_RR使用循环轮询策略。它类似于SCHED_FIFO，只是它在相同优先级的线程之间提供时间切片。POSIX提供了另一个调度类别—SCHED_OTHER—但其实现是未定义的，并且特定于系统；它在不同系统上的行为可能不同。 POSIX API指定了以下两个用于获取和设置调度策略的函数： pthread_attr_getschedpolicy(pthread_attr_t *attr, int *policy) pthread_attr_setschedpolicy(pthread_attr_t *attr, int policy) 这两个函数的第一个参数是指向线程属性集的指针。第二个参数是（1）一个指向整数的指针，该整数被设置为当前调度策略（对于pthread_attr_getschedpolicy()），或者是（2）一个整数值（SCHED_FIFO、SCHED_RR或SCHED_OTHER）用于pthread_attr_setschedpolicy()函数。如果发生错误，这两个函数都返回非零值。 12345678910111213141516171819202122232425262728293031323334353637#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#define NUM_THREADS 5int main(int argc, char *argv[])&#123; int i, policy; pthread_t_tid[NUM_THREADS]; pthread_attr_t attr; /* get the default attributes */ pthread_attr_init(&amp;attr); /* get the current scheduling policy */ if (pthread_attr_getschedpolicy(&amp;attr, &amp;policy) != 0) fprintf(stderr, &quot;Unable to get policy.\\n&quot;); else &#123; if (policy == SCHED_OTHER) printf(&quot;SCHED_OTHER\\n&quot;); else if (policy == SCHED_RR) printf(&quot;SCHED_RR\\n&quot;); else if (policy == SCHED_FIFO) printf(&quot;SCHED_FIFO\\n&quot;); &#125; /* set the scheduling policy - FIFO, RR, or OTHER */ if (pthread_attr_setschedpolicy(&amp;attr, SCHED_FIFO) != 0) fprintf(stderr, &quot;Unable to set policy.\\n&quot;); /* create the threads */ for (i = 0; i &lt; NUM_THREADS; i++) pthread_create(&amp;tid[i],&amp;attr,runner,NULL); /* now join on each thread */ for (i = 0; i &lt; NUM_THREADS; i++) pthread_join(tid[i], NULL);&#125;/* Each thread will begin control in this function */void *runner(void *param)&#123; /* do some work ... */ pthread exit(0);&#125; Linux Scheduling Linux中的进程调度经历了有趣的历史。在版本2.5之前，Linux内核运行的是传统UNIX调度算法的变体。然而，由于这个算法并非设计用于SMP系统，它不能很好地支持具有多个处理器的系统。此外，对于具有大量可运行进程的系统，它导致性能不佳。随着内核版本2.5的推出，调度器进行了彻底的改革，引入了一种称为O(1)的调度算法，该算法在系统中的任务数量不同的情况下都可以在恒定时间内运行。O(1)调度器还增加了对SMP系统的支持，包括处理器亲和性和处理器之间的负载平衡。然而，在实际应用中，尽管O(1)调度器在SMP系统上表现出色，但对许多桌面计算机系统上常见的交互性进程导致了较差的响应时间。在2.6内核的开发过程中，调度器再次进行了修订；在内核2.6.23版本中，完全公平调度器（CFS）成为默认的Linux调度算法。 Linux系统中的调度基于调度类。每个类别都被分配一个特定的优先级。通过使用不同的调度类，内核可以根据系统和进程的需求容纳不同的调度算法。例如，Linux服务器的调度标准可能与运行Linux的移动设备的标准不同。为了决定下一个要运行的任务，调度器选择属于最高优先级调度类的最高优先级任务。标准Linux内核实现了两个调度类别：（1）使用CFS调度算法的默认调度类，和（2）实时调度类。我们在这里讨论每个类别。当然，可以添加新的调度类别。 CFS调度器不是使用将相对优先级值与时间量的长度关联的严格规则，而是为每个任务分配CPU处理时间的一部分。这个比例是根据分配给每个任务的nice value计算的。nice value的范围是-20到+19，其中数值较低的nice value表示较高的相对优先级。具有较低nice value的任务接收CPU处理时间的比例比具有较高nice value的任务多。默认的nice value为0。 （好的这个术语来自这样的思想，即如果一个任务将其nice value从0增加到+10，它对系统中的其他任务很好，因为它降低了其相对优先级。）CFS不使用时间片的离散值，而是确定一个目标延迟，即每个可运行任务应在该时间间隔内至少运行一次的时间间隔。 CPU时间的份额是从目标延迟的值中分配的。除了具有默认值和最小值之外，如果系统中的活动任务数量增加到某个阈值以上，目标延迟的值还可以增加。 CFS调度器不直接分配优先级。相反，它通过使用每个任务的虚拟运行时间来维护虚拟运行时间来记录每个任务运行了多长时间，使用每个任务的变量vruntime。虚拟运行时间与基于任务优先级的衰减因子相关联：较低优先级的任务比较高优先级的任务具有更高的衰减率。对于正常优先级的任务（nice value为0），虚拟运行时间与实际物理运行时间相同。因此，如果一个默认优先级的任务运行了200毫秒，它的vruntime也将是200毫秒。但是，如果一个较低优先级的任务运行了200毫秒，其vruntime将高于200毫秒。同样，如果一个较高优先级的任务运行了200毫秒，其vruntime将小于200毫秒。为了决定下一个要运行的任务，调度器只需选择具有最小vruntime值的任务。此外，变得可运行的较高优先级任务可以抢占较低优先级任务。 CFS PERFORMANCE Linux CFS调度器提供了一个有效的算法来选择下一个要运行的任务。每个可运行的任务都放在一个红黑树中，这是一棵平衡的二叉搜索树，其关键字基于vruntime的值。该树如下所示： 当一个任务变为可运行时，它被添加到树中。如果树上的一个任务不可运行（例如，如果它被阻塞等待I/O），则它被移除。一般来说，已分配较少处理时间（较小的vruntime值）的任务位于树的左侧，而已分配更多处理时间的任务位于右侧。根据二叉搜索树的属性，最左边的节点具有最小的关键值，对于CFS调度器而言，这意味着它是具有最高优先级的任务。由于红黑树是平衡的，发现最左边的节点将需要O(lgN)的操作（其中N是树中的节点数）。但是，出于效率原因，Linux调度器将此值缓存在变量rb_leftmost中，因此确定下一个要运行的任务只需要检索缓存的值。 让我们看看CFS调度器的实际运行：假设两个任务具有相同的nice value。一个任务是I/O绑定的，另一个是CPU绑定的。通常，I/O绑定的任务在阻塞等待额外I/O之前只运行短时间，而CPU绑定的任务在有机会在处理器上运行时会耗尽其时间周期。因此，I/O绑定任务的vruntime值最终将低于CPU绑定任务的vruntime值，从而给I/O绑定任务比CPU绑定任务更高的优先级。此时，如果当I/O绑定任务有资格运行时（例如，当它等待的I/O变得可用时），CPU绑定任务正在执行，则I/O绑定任务将抢占CPU绑定任务。 Linux还使用POSIX标准描述的方法实现了实时调度，使用SCHED_FIFO或SCHED_RR实时策略调度的任何任务都比普通（非实时）任务具有更高的优先级。Linux使用两个单独的优先级范围，一个用于实时任务，另一个用于正常任务。实时任务在0到99的范围内分配静态优先级，并且正常（即非实时）任务在100到139之间分配优先级。这两个范围映射到全局优先级方案，其中数值较低的值表示较高的相对优先级。普通任务根据其nice value分配优先级，其中值-20映射到优先级100，值+19映射到139。 算法评估 我们如何为特定系统选择CPU调度算法呢？ 第一个问题是定义在选择算法时要使用的标准。标准通常以CPU利用率、响应时间或吞吐量的形式定义。为了选择一种算法，我们必须首先定义这些元素的相对重要性。我们的标准可能包括多个度量，例如： 在最大响应时间为1秒的约束下，最大化CPU利用率 通过确保周转时间（平均而言）与总执行时间成线性比例，最大化吞吐量 一旦选择标准被定义，我们希望评估考虑中的算法。接下来，我们将描述可以使用的各种评估方法。 确定模型 接受一个特定的预定工作负载，并定义该工作负载的每个算法的性能 排队模型 在许多系统上，运行的进程每天都会变化，因此没有静态的一组进程（或时间）可用于确定性建模。然而，可以确定的是CPU和I/O突发的分布。这些分布可以进行测量，然后进行逼近或简单估算。结果是描述特定CPU突发概率的数学公式。通常，这个分布是指数分布，并由其均值描述。同样，我们可以描述进程到达系统的时间的分布（到达时间分布）。通过这两个分布，可以计算大多数算法的平均吞吐量、利用率、等待时间等。 计算机系统被描述为一组服务器的网络。每个服务器都有一个等待进程的队列。CPU是一个具有就绪队列的服务器，I/O系统是一个具有设备队列的服务器。通过了解到达率和服务率，我们可以计算利用率、平均队列长度、平均等待时间等。这个研究领域被称为排队网络分析。 例如，n是平均队列长度（不包括正在服务的进程），W是队列中的平均等待时间，λ是新进程的平均到达速率（例如每秒三个进程）。我们期望在等待时间W内，将有 λ × W 个新进程到达队列。如果系统处于稳定状态，那么离开队列的进程数量必须等于到达的进程数量。因此n=λ×W. 这个等式被称为Little’s定理，特别有用，因为它对于任何调度算法和到达分布都是有效的。 我们可以使用Little’s定理来计算其中一个变量，如果我们知道其他两个变量。例如，如果我们知道每秒平均有7个进程到达，而队列中通常有14个进程，那么我们可以计算每个进程的平均等待时间为2秒。 排队分析可以帮助比较调度算法，但它也有局限性。目前，可以处理的算法和分布类别相当有限。复杂算法和分布的数学运算可能很难处理。因此，到达和服务分布通常以数学上可处理但不切实际的方式定义。通常还需要进行许多独立的假设，这可能不准确。由于这些困难，排队模型通常只是实际系统的近似，并且计算结果的准确性可能值得怀疑。 模拟 为了更准确地评估调度算法，我们可以使用模拟。运行模拟涉及编写计算机系统模型的程序。软件数据结构表示系统的主要组件。模拟器具有一个表示时钟的变量。随着此变量的值的增加，模拟器修改系统状态以反映设备、进程和调度程序的活动。在执行模拟时，收集和打印指示算法性能的统计数据。 驱动模拟的数据可以通过多种方式生成。最常见的方法是使用编程为根据概率分布生成进程、CPU突发时间、到达、离开等的随机数生成器。这些分布可以在数学上定义（均匀、指数、泊松）或经验性地定义。如果要经验性地定义分布，就需要对正在研究的实际系统进行测量。结果定义了实际系统中事件的分布；然后可以使用这个分布来驱动模拟。 然而，由于实际系统中连续事件之间的关系，基于分布的模拟可能不准确。频率分布仅指示每个事件发生的实例数量；它不指示它们发生的顺序。为了解决这个问题，我们可以使用跟踪磁带。我们通过监视实际系统并记录实际事件的序列来创建跟踪磁带。然后我们使用这个序列来驱动模拟。跟踪磁带为在完全相同的一组真实输入上比较两个算法提供了一种优秀的方式。这种方法可以为其输入产生准确的结果。 模拟可能很昂贵，通常需要几小时的计算机时间。更详细的模拟提供更准确的结果，但也需要更多的计算机时间。此外，跟踪磁带可能需要大量的存储空间。最后，模拟器的设计、编码和调试可能是一项重大任务。 实现 即使是模拟的准确性也是有限的。评估调度算法的唯一完全准确的方法是将其编码、放入操作系统中，并查看其运行情况。这种方法将实际的算法放入实际操作条件下进行评估。 这种方法的主要困难在于成本较高。费用不仅包括编写算法和修改操作系统以支持它（以及其所需的数据结构），还包括用户对不断变化的操作系统的反应。大多数用户对构建更好的操作系统不感兴趣；他们只是想执行他们的进程并使用它们的结果。不断变化的操作系统无助于用户完成工作。 另一个困难是算法使用的环境将发生变化。环境将不仅以通常的方式变化，即编写新程序和问题类型变化，还将因调度程序的性能而变化。如果短进程被赋予优先级，那么用户可能会将较大的进程分成一组较小的进程。如果交互进程优先于非交互进程，那么用户可能会切换到交互使用。 例如，研究人员设计了一个系统，通过查看终端I/O的数量自动分类交互和非交互进程。如果一个进程在1秒的时间间隔内没有与终端进行输入或输出，则将该进程分类为非交互，并将其移动到较低优先级的队列。作为对此策略的响应，一个程序员修改了他的程序，以在少于1秒的定期间隔内向终端写入一个任意字符。尽管终端输出完全没有意义，系统仍然为他的程序分配了较高的优先级。 最灵活的调度算法是那些可以由系统管理员或用户更改以便调整为特定应用程序或应用程序集的算法。例如，执行高端图形应用程序的工作站可能具有与Web服务器或文件服务器不同的调度需求。一些操作系统——特别是UNIX的几个版本——允许系统管理员为特定的系统配置微调调度参数。 另一种方法是使用可以修改进程或线程优先级的API。Java、POSIX和Windows API提供了这样的功能。这种方法的缺点在于调节一个系统或应用并不能在更通用的情况下改进性能。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blackforest1990.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"进程管理","slug":"进程管理","permalink":"https://blackforest1990.github.io/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"进程同步","slug":"进程同步","date":"2023-12-11T02:27:52.000Z","updated":"2023-12-29T06:50:54.577Z","comments":true,"path":"2023/12/11/进程同步/","link":"","permalink":"https://blackforest1990.github.io/2023/12/11/%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5/","excerpt":"","text":"合作进程是指可以影响或受其他在系统中执行的进程影响的进程。合作进程可以直接共享逻辑地址空间（即代码和数据），也可以通过文件或消息允许仅共享数据。前一种情况通过使用线程来实现。然而，并发访问共享数据可能导致数据不一致。在本文中，我们讨论确保共享逻辑地址空间的合作进程有序执行的各种机制，以维护数据一致性。 背景 我们将解释并发或并行执行如何导致涉及由多个进程共享的数据完整性的问题。现在我们回到有界缓冲区的问题上。我们最初的解决方案在缓冲区中最多允许 BUFFER SIZE - 1 个项同时存在。假设我们想修改算法来解决这个问题。一种可能性是添加一个整数变量 counter，初始化为 0。每次向缓冲区添加一个新项时，counter 增加，并且每次从缓冲区移除一个项时，counter 减少。生产者进程的代码可以修改如下： 12345678while (true) &#123; /* 在 next produced 中生成一个项 */ while (counter == BUFFER SIZE) ; /* 什么也不做 */ buffer[in] = next produced; in = (in + 1) % BUFFER SIZE; counter++;&#125; 消费者进程的代码可以修改如下： 12345678while (true) &#123; while (counter == 0) ; /* 什么也不做 */ next consumed = buffer[out]; out = (out + 1) % BUFFER SIZE; counter--; /* 在 next consumed 中消费一个项 */&#125; 尽管上述的生产者和消费者例程在单独执行时是正确的，但在并发执行时可能无法正常工作。举例说明，假设变量 counter 的值当前为 5，并且生产者和消费者进程同时执行语句 “counter++” 和 “counter–”。在执行这两个语句之后，变量 counter 的值可能是 4、5 或 6！然而，唯一的正确结果是 counter == 5，只有在生产者和消费者分别执行时才能正确生成。 我们可以通过以下方式说明 counter 的值可能不正确。注意语句 “counter++” 在机器语言中可以如下实现： 123register1 = counterregister1 = register1 + 1counter = register1 同样，语句 “counter–” 可以如下实现： 123register2 = counterregister2 = register2 - 1counter = register2 即使 register1 和 register2 可能是相同的物理寄存器（比如累加器），该寄存器的内容将由中断处理程序保存和恢复。“counter++” 和 “counter–” 的并发执行相当于以某种任意顺序交错执行先前介绍的低级语句的顺序执行（但在每个高级语句内部的顺序被保留）。这样的交错执行可能是以下的其中一种： T0: producer execute register1 = counter {register1 = 5} T1: producer execute register1 = register1 + 1 {register1 = 6} T2: consumer execute register2 = counter {register2 = 5} T3: consumer execute register2 = register2 − 1 {register2 = 4} T4: producer execute counter = register1 {counter = 6} T5: consumer execute counter = register2 {counter = 4} 我们将达到这种不正确的状态是因为我们允许两个进程同时操作变量 counter。这种情况，其中多个进程同时访问和操作相同的数据，并且执行的结果取决于访问发生的具体顺序，被称为竞态条件。为了防范上述竞态条件，我们需要确保一次只有一个进程能够操作变量 counter。为了做出这样的保证，我们需要以某种方式同步这些进程。 临界区问题 首先讨论所谓的临界区问题。考虑一个由 n 个进程 {P0，P1，…，Pn−1} 组成的系统。每个进程都有一段代码，称为临界区，其中进程可能正在更改共享变量、更新表、写文件等。系统的重要特性是，当一个进程正在执行其临界区时，不允许其他进程在其临界区中执行。也就是说，没有两个进程可以同时在其临界区中执行。临界区问题是设计一个协议，进程可以使用该协议进行合作。每个进程必须请求进入其临界区的权限。执行此请求的代码部分是入口部分。临界区可能后面跟着一个退出部分。其余代码是剩余部分。 解决临界区问题的解决方案必须满足以下三个要求： 互斥性。如果进程 Pi 正在执行其临界区，则其他进程不能在其临界区中执行。 进展性。如果没有进程在其临界区中执行，并且有些进程希望进入其临界区，则只有那些不在其剩余部分中执行的进程可以参与决定下一个将进入其临界区的进程，而且此选择不能无限期地推迟。 有限等待。在进程发出请求进入其临界区后，以及在该请求被授予之前，允许其他进程进入其临界区的次数存在一个限制或界限。 我们假设每个进程以非零速度执行。然而，我们不能对 n 个进程的相对速度做任何假设。 在某一时刻，操作系统中可能有许多内核模式进程处于活动状态。因此，实现操作系统的内核代码可能存在几种可能的竞争条件。以维护系统中所有打开文件列表的内核数据结构为例。如果两个进程同时打开文件，对此列表的单独更新可能导致竞争条件。其他可能存在竞争条件的内核数据结构包括用于维护内存分配的结构、用于维护进程列表的结构以及用于中断处理的结构。内核开发人员需要确保操作系统没有这样的竞争条件。 在操作系统中处理临界区的两种一般方法是：抢占式内核和非抢占式内核。抢占式内核允许在内核模式下运行的进程在运行时被抢占。非抢占式内核不允许在内核模式下运行的进程被抢占；内核模式进程将一直运行，直到退出内核模式、阻塞或自愿放弃对CPU的控制。 显然，非抢占式内核基本上不会在内核数据结构上产生竞争条件，因为一次只有一个进程在内核中活动。我们不能说抢占式内核也是如此，因此必须仔细设计以确保共享内核数据不受竞争条件的影响。对于多处理器架构来说，抢占式内核尤其难以设计，因为在这些环境中，两个内核模式进程可能同时在不同的处理器上运行。 那么，为什么有人会选择抢占式内核呢？抢占式内核可能更具响应性，因为在内核模式下运行的进程在放弃处理器给等待中的进程之前有较小的风险在任意长的时间内运行。当然，通过设计不会以这种方式行为的内核代码，也可以将此风险最小化。此外，抢占式内核更适用于实时编程，因为它允许实时进程抢占当前在内核中运行的进程。 彼得森解法 由于现代计算机架构执行基本的机器语言指令（如加载和存储）的方式，Peterson解法在这些架构上不能保证正确运行。然而，我们还是介绍这个解决方案，因为它提供了解决关键区问题的良好算法描述，并展示了设计满足互斥、进展和有限等待要求的软件所涉及的一些复杂性。 Peterson解法仅适用于两个进程，它们在它们的关键区和剩余区之间交替执行。这两个进程分别编号为P0和P1。为了方便起见，在表示Pi时，我们使用Pj来表示另一个进程，即j = 1−i。 Peterson解法要求这两个进程共享两个数据项： 12int turn;boolean flag[2]; 变量turn表示轮到谁进入关键区。也就是说，如果turn == i，则允许进程Pi在其关键区执行。数组flag用于指示一个进程是否准备好进入其关键区。例如，如果flag[i]为true，则表示Pi准备好进入其关键区。 为了进入关键区，进程Pi首先将flag[i]设置为true，然后将turn设置为j的值，从而断言如果另一个进程希望进入关键区，它可以这样做。如果两个进程同时尝试进入，turn将大致同时设置为i和j。只有一个赋值将持续；另一个将发生但将立即被覆盖。turn的最终值确定了这两个进程中哪一个被允许首先进入其关键区。 需要满足以下几个前提条件： ● 进程必须能够独立地执行，并且它们之间可以相互干扰。 ● 进程必须可以共享一些公共变量。 ● 进程之间的速度可以不同，但不能有任何假设。 这个算法的一个限制是它只适用于两个进程之间的情况。在有多个进程需要互斥访问共享资源的情况下，需要采用其他算法或技术来解决。 同步硬件 我们刚刚描述了解决临界区问题的一种基于软件的方法。然而，正如前面提到的，像Peterson这样的基于软件的解决方案在现代计算机体系结构上不能保证正常工作。在接下来的讨论中，我们将探讨解决临界区问题的几种更多方法，涉及从硬件到软件的 API 技术，这些技术对内核开发人员和应用程序员都是可用的。所有这些解决方案都基于锁的概念——即通过使用锁来保护关键区域。正如我们将看到的，这些锁的设计可能非常复杂。 我们首先介绍一些简单的硬件指令，这些指令在许多系统上都可用，并展示它们如何有效地解决临界区问题。硬件特性可以使任何编程任务变得更加容易，并提高系统效率。如果我们能够在修改共享变量时阻止中断，那么在单处理器环境中就可以简单地解决临界区问题。这样，我们可以确保当前的指令序列将被允许按顺序执行而不会被抢占。不会运行其他指令，因此不会对共享变量进行意外的修改。这通常是非抢占内核采用的方法。不幸的是，在多处理器环境中，禁用中断可能会很耗时，因为消息会传递到所有处理器。这种消息传递延迟了进入每个关键区的时间，降低了系统效率。还要考虑系统时钟如果通过中断保持更新的影响。 因此，许多现代计算机系统提供了特殊的硬件指令，允许我们测试和修改一个字的内容，或原子地交换两个字的内容——即作为一个不可中断的单元。我们可以使用这些特殊指令以相对简单的方式解决临界区问题。我们通过描述测试与设置（test and set()）和比较与交换（compare and swap()）指令来抽象这些指令背后的主要概念，而不是讨论某个具体机器的某个具体指令。 互斥锁 基于硬件的解决方案对于应用程序员来说通常很复杂且难以访问。相反，操作系统设计者构建软件工具来解决临界区问题。其中最简单的工具之一是互斥锁（mutex lock）。实际上，“mutex”一词是“mutual exclusion”的缩写。我们使用互斥锁来保护临界区，从而防止竞态条件。也就是说，进程必须在进入临界区之前获取锁；当退出临界区时释放锁。acquire()函数用于获取锁，release()函数用于释放锁。 互斥锁有一个布尔变量available，其值指示锁是否可用。如果锁可用，对acquire()的调用成功，并且然后将锁视为不可用。试图获取不可用锁的进程将被阻塞，直到锁被释放。 acquire()的定义如下： 12345acquire() &#123; while (!available) ; /* 忙等待 */ available = false;&#125; release()的定义如下： 123release() &#123; available = true;&#125; 对acquire()或release()的调用必须以原子方式执行。主要缺点是它需要忙等待。当一个进程处于其临界区时，任何尝试进入其临界区的其他进程必须在调用acquire()时不断循环。事实上，这种类型的互斥锁也称为自旋锁，因为进程在等待锁变得可用时会“旋转”。这种持续循环在真正的多编程系统中显然是个问题，其中一个单独的 CPU 在许多进程之间共享。忙等待浪费了 CPU 周期，其他一些进程可能能够有效地使用。 然而，自旋锁也有一个优点，即在进程必须等待锁时不需要进行上下文切换，而上下文切换可能需要很长时间。因此，当预计锁将被持有的时间很短时，自旋锁是有用的。它们通常用于多处理器系统，其中一个线程可以在一个处理器上“旋转”，而另一个线程在另一个处理器上执行其临界区。 信号量 互斥锁，正如我们之前提到的，通常被认为是最简单的同步工具之一。我们将研究一个更健壮的工具，它可以表现得类似于互斥锁，但也可以提供更复杂的方式来使进程同步它们的活动。信号量（Semaphore）S 是一个整数变量，除了初始化之外，只能通过两个标准的原子操作进行访问：wait() 和 signal()。wait() 操作最初被称为 P；signal() 最初被称为 V。wait() 的定义如下： 1234wait(S) &#123; while (S &lt;= 0) S--;; // 忙等待&#125; signal() 的定义如下： 123signal(S) &#123; S++;&#125; 在 wait() 和 signal() 操作中对信号量的整数值的所有修改都必须是不可分割的。也就是说，当一个进程修改信号量值时，没有其他进程可以同时修改相同的信号量值。此外，在 wait(S) 的情况下，对 S 的整数值的测试（S ≤ 0）以及可能的修改（S–）必须在没有中断的情况下执行。 信号量的使用 操作系统通常区分计数信号量和二进制信号量。计数信号量的值可以在无限的域内变化。二进制信号量的值只能在0和1之间变化。因此，二进制信号量的行为类似于互斥锁。实际上，在不提供互斥锁的系统上，可以使用二进制信号量来提供互斥。 计数信号量可以用于控制对由有限数量实例组成的特定资源的访问。信号量被初始化为可用资源的数量。每个想要使用资源的进程都执行对信号量的 wait() 操作（从而减少计数）。当进程释放资源时，它执行 signal() 操作（增加计数）。当信号量的计数变为0时，所有资源都被使用。在此之后，想要使用资源的进程将被阻塞，直到计数变得大于0。 我们还可以使用信号量来解决各种同步问题。例如，考虑两个并发运行的进程：P1 具有语句 S1，P2 具有语句 S2。假设我们要求只有在 S1 完成后才能执行 S2。我们可以通过让 P1 和 P2 共享一个初始值为0的信号量 synch 来轻松实现这个方案。在进程 P1 中，我们插入以下语句： 12S1;signal(synch); 在进程 P2 中，我们插入以下语句： 12wait(synch);S2; 因为 synch 被初始化为0，所以只有在 P1 调用 signal(synch) 之后（也就是在语句 S1 执行后），P2 才会执行 S2。 信号量的实现 为了克服忙等待的需要，我们可以修改 wait() 和 signal() 操作的定义如下：当一个进程执行 wait() 操作并发现信号量值不是正数时，它必须等待。然而，与其忙等待，该进程可以自我阻塞。阻塞操作将一个进程放入与信号量关联的等待队列中，并将进程的状态切换到等待状态。然后控制被传递给 CPU 调度程序，该程序选择另一个进程执行。 一个被阻塞在等待信号量 S 上的进程应该在另一个进程执行 signal() 操作时重新启动。进程通过 wakeup() 操作重新启动，该操作将进程从等待状态更改为就绪状态。然后，将进程放入就绪队列中。（根据 CPU 调度算法，可能或可能不会从运行中的进程切换到新的就绪进程。） 为了在这个定义下实现信号量，我们将信号量定义为： 1234typedef struct &#123; int value; struct process *list;&#125; semaphore; 每个信号量都有一个整数值和一个进程列表。当一个进程必须等待信号量时，它被添加到进程列表中。signal() 操作从等待进程列表中删除一个进程并唤醒该进程。 现在，wait() 信号量操作可以定义为： 1234567wait(semaphore *S) &#123; S-&gt;value--; if (S-&gt;value &lt; 0) &#123; add this process to S-&gt;list; block(); &#125;&#125; signal() 信号量操作可以定义为： 1234567signal(semaphore *S) &#123; S-&gt;value++; if (S-&gt;value &lt;= 0) &#123; remove a process P from S-&gt;list; wakeup(P); &#125;&#125; 阻塞操作挂起调用它的进程。唤醒操作恢复一个被阻塞的进程 P。这两个操作由操作系统作为基本系统调用提供。请注意，在这个实现中，信号量的值可能是负数，而在具有忙等待的信号量的经典定义下，信号量的值永远不会是负数。如果信号量的值是负数，那么它的大小是等待该信号量的进程数。这是由于在 wait() 操作的实现中切换了减法和测试的顺序。 等待进程列表可以通过每个进程控制块（PCB）中的链接字段轻松实现。每个信号量包含一个整数值和指向 PCB 列表的指针。为了确保有界等待，可以使用 FIFO 队列的方式添加和删除进程，其中信号量包含队列的头指针和尾指针。然而，通常情况下，列表可以使用任何排队策略。信号量列表的正确使用不依赖于信号量列表的特定排队策略。 信号量操作必须以原子方式执行是至关重要的。我们必须确保没有两个进程可以同时在同一个信号量上执行 wait() 和 signal() 操作。这是一个关键部分问题；在单处理器环境中，我们可以通过在执行 wait() 和 signal() 操作时简单地禁用中断来解决它。这个方案在单处理器环境中有效，因为一旦中断被禁用，不同进程的指令就不能交错执行。只有当前运行的进程执行，直到重新启用中断，调度程序才能重新获得控制。 在多处理器环境中，必须在每个处理器上禁用中断。否则，来自不同处理器的进程（在不同处理器上运行）的指令可能以任意的方式交错。在每个处理器上禁用中断可能是一项困难的任务，并且可能严重降低性能。因此，SMP 系统必须提供替代的锁定技术——例如 compare and swap() 或自旋锁（spinlocks）——以确保 wait() 和 signal() 的原子执行。 重要的是要承认，通过这种对 wait() 和 signal() 操作的定义，我们并没有完全消除忙等待。相反，我们将忙等待从进程应用程序的入口部分移到了关键部分。此外，我们将忙等待限制在 wait() 和 signal() 操作的关键部分，而这些部分是短暂的（如果编写正确，它们应该不超过大约十条指令）。 死锁和饥饿 使用等待队列实现的信号量可能导致两个或更多进程无限期等待仅由等待进程之一引起的事件。所涉及的事件是执行 signal() 操作。当达到这种状态时，这些进程被称为死锁。为了说明这一点，考虑一个由两个进程 P0 和 P1 组成的系统，每个进程都访问两个信号量 S 和 Q，它们的初始值均为 1： 12345678P0 P1wait(S); wait(Q);wait(Q); wait(S);. .. .. .signal(S); signal(Q);signal(Q); signal(S); 假设 P0 执行 wait(S)，然后 P1 执行 wait(Q)。当 P0 执行 wait(Q) 时，它必须等待 P1 执行 signal(Q)。同样，当 P1 执行 wait(S) 时，它必须等待 P0 执行 signal(S)。由于这些 signal() 操作无法执行，P0 和 P1 陷入了死锁。 当一个进程集合中的每个进程都在等待只能由该集合中的另一个进程引起的事件时，我们说该进程集合处于死锁状态。这里我们主要关注的事件是资源的获取和释放。与死锁相关的另一个问题是无限阻塞或饥饿，即进程在信号量中无限期等待的情况。如果我们以后进先出（LIFO，last-in, first-out）的顺序从与信号量关联的列表中移除进程，那么可能会发生无限阻塞。 优先级反转 当一个更高优先级的进程需要读取或修改当前由一个低优先级进程（或一系列低优先级进程）访问的内核数据时，就会出现调度的挑战。由于内核数据通常受到锁的保护，更高优先级的进程将不得不等待低优先级进程完成对资源的使用。如果低优先级进程被抢占，让步给优先级更高的进程，情况就变得更加复杂。 例如，假设我们有三个进程L、M和H，它们的优先级按照 L &lt; M &lt; H 的顺序。假设进程H需要资源R，而该资源当前正在被进程L访问。通常情况下，进程H会等待L完成对资源R的使用。但是，现在假设进程M变为可运行状态，从而抢占了进程L。间接地，一个具有较低优先级的进程（进程M）影响了进程H等待L放弃资源R的时间。 这个问题被称为优先级反转。它只会在具有两个以上优先级的系统中发生，因此一种解决方案是只有两个优先级。然而，对于大多数通用操作系统来说，这是不够的。通常，这些系统通过实现优先级继承协议来解决这个问题。根据该协议，所有正在访问由更高优先级进程需要的资源的进程都会继承更高的优先级，直到它们完成对这些资源的使用。当它们完成后，它们的优先级将恢复到原始值。在上面的例子中，优先级继承协议将允许进程L暂时继承进程H的优先级，从而防止进程M抢占其执行。当进程L完成对资源R的使用后，它将放弃从H继承的优先级并恢复为其原始优先级。由于资源R现在可用，接下来运行的将是进程H，而不是M。 经典的同步问题 有界缓冲问题（Bounded-Buffer Problem） 在生产者-消费者模型中，有一个有界的缓冲区，生产者将数据放入缓冲区，而消费者从中取出数据。问题在于要保证在缓冲区满或空的情况下，生产者和消费者能够正确地进行同步，避免溢出或下溢。 在有界缓冲问题中，我们有N个缓冲区，每个缓冲区可以容纳一个项。 为了解决这个问题，我们需要以下信号量： mutex：用于保护对缓冲区的访问，防止多个进程同时访问。初始值为1，表示最初是可用的。 full：用于记录当前有多少个缓冲区已经被占用（即已经放入了项）。初始值为0。 empty：用于记录当前还有多少个缓冲区是空的（即可以放入项）。初始值为N，表示所有缓冲区都是空的。 这样，通过合理地使用这三个信号量，我们可以实现多个生产者和消费者正确、安全地访问缓冲区。 生产者进程结构： 123456789101112do &#123; . . . /* produce an item in next produced */ . . . wait(empty); wait(mutex); . . . /* add next produced to the buffer */ . . . signal(mutex); signal(full);&#125; while (true); 消费者进程结构： 123456789101112do &#123; wait(full); wait(mutex); . . . /* remove an item from buffer to next consumed */ . . . signal(mutex); signal(empty); . . . /* consume the item in next consumed */ . . .&#125; while (true); 读者-写者问题（Readers and Writers Problem） 假设一个数据库需要被多个并发进程共享。其中一些进程可能只想读取数据库，而其他一些可能想要更新数据库。我们通过将前者称为读者，将后者称为写者来区分这两种类型的进程。显然，如果两个读者同时访问共享数据，不会产生不良影响。然而，如果一个写者和另一个进程（无论是读者还是写者）同时访问数据库，可能会导致混乱。 为了确保这些困扰不会出现，我们要求写者在写入数据库时具有对共享数据库的独占访问权。这个同步问题被称为读者-写者问题。自从最初提出以来，它一直被用来测试几乎每个新的同步原语。读者-写者问题有几个变种，都涉及到优先级。最简单的一个，被称为第一个读者-写者问题，要求在写者已经获得使用共享对象的许可之前，不应使读者等待。换句话说，没有读者应该因为有写者在等待而等待其他读者完成。第二个读者-写者问题要求一旦写者准备好，就应该尽快执行其写操作。换句话说，如果一个写者正在等待访问对象，那么新的读者就不能开始读取。在第一种情况下，写者可能会饿死；在第二种情况下，读者可能会饿死。 在解决第一个读者-写者问题的方案中，读者进程共享以下数据结构： 123semaphore rw_mutex = 1;semaphore mutex = 1;int read_count = 0; 信号量 rw_mutex 和 mutex 被初始化为 1；read_count 被初始化为 0。rw_mutex 信号量对读者和写者进程都是共享的。mutex 信号量用于在更新变量 read_count 时确保互斥。变量 read_count 用于跟踪当前正在读取对象的进程数量。rw_mutex 信号量用作写者的互斥信号量。它还由第一个或最后一个进入或退出关键部分的读者使用。它不被在其他读者处于其关键部分时进入或退出的读者使用。 请注意，如果一个写者在关键部分中，有 n 个读者在等待，那么一个读者排队在 rw_mutex 上，而 n - 1 个读者排队在 mutex 上。还请注意，当一个写者执行 signal(rw_mutex) 时，我们可能会恢复等待的读者或一个等待的写者的执行。选择由调度程序做出。 12345678910111213141516171819202122232425writer:do &#123; wait(rw_mutex); . . . /* writing is performed */ . . . signal(rw_mutex);&#125; while (true);Reader:do &#123; wait(mutex); read count++; if (read_count == 1) wait(rw_mutex); signal(mutex); . . . /* reading is performed */ . . . wait(mutex); read_count--; if (read_count == 0) signal(rw_mutex); signal(mutex);&#125; while (true); 读者-写者问题及其解决方案已经推广为在某些系统上提供读者-写者锁。获取读者-写者锁需要指定锁的模式：读取或写入访问。当一个进程只想读取共享数据时，它以读取模式请求读者-写者锁。希望修改共享数据的进程必须以写入模式请求锁。多个进程可以同时以读取模式获取读者-写者锁，但只有一个进程可以以写入模式获取锁，因为写者需要独占访问权限。 读者-写者锁在以下情况下最为有用： 在应用程序中很容易确定哪些进程仅读取共享数据，哪些进程仅写入共享数据。 在具有比写者或互斥锁更多读者的应用程序中。这是因为读者-写者锁通常需要更多的开销来建立，比信号量或互斥锁多。允许多个读者同时进行提高了允许并发的能力，以弥补设置读者-写者锁的开销。 哲学家就餐问题（Dining-Philosophers Problem） 在这个问题中，有五位哲学家坐在圆桌前，每位哲学家之间有一根筷子，共有五根筷子。哲学家可以进行思考或就餐，但只有同时拿到左右两根筷子时才能吃饭。 数据结构: 一个装有米饭的碗（数据集） 五根筷子的信号量数组 chopstick[5]，初始化为1，表示每根筷子最初可用。 哲学家的行为规则如下： 当一个哲学家想要进餐时，他必须先拿起他左边的筷子，然后拿起他右边的筷子，才能开始进餐。 进餐完毕后，他会先放下右边的筷子，再放下左边的筷子，然后继续思考。 为了解决哲学家就餐问题，可以使用信号量来控制筷子的访问。当一个哲学家想要拿起筷子时，他会先等待两根筷子都可用，然后将它们标记为不可用，以防止其他哲学家同时取用同一根筷子。 这个问题的解决方案需要巧妙地使用信号量来保证哲学家们可以安全地就餐，同时避免死锁等问题。 12345678910111213semaphore chopstick[5];do &#123; wait(chopstick[i]); wait(chopstick[(i+1) % 5]); . . . /* eat for awhile */ . . . signal(chopstick[i]); signal(chopstick[(i+1) % 5]); . . . /* think for awhile */ . . .&#125; while (true); 同步案例 Linux 在 Linux 的 Version 2.6 之前，Linux 内核是非抢占式的，这意味着在内核模式下运行的进程即使有更高优先级的进程可运行也不能被抢占。然而，现在的 Linux 内核是完全抢占式的，因此当一个任务在内核中运行时可以被抢占。 Linux 提供了内核中的多种不同的同步机制。由于大多数计算机体系结构都提供了原子版本的简单数学操作的指令，因此在 Linux 内核中最简单的同步技术是原子整数，它使用不透明的数据类型 atomic_t 表示。正如其名称所示，使用原子整数的所有数学操作都是无中断的。以下代码演示了声明一个原子整数计数器并执行各种原子操作： 1234567atomic_t counter;int value;atomic_set(&amp;counter, 5); /* counter = 5 */atomic_add(10, &amp;counter); /* counter = counter + 10 */atomic_sub(4, &amp;counter); /* counter = counter - 4 */atomic_inc(&amp;counter); /* counter = counter + 1 */value = atomic_read(&amp;counter); /* value = 12 */ 原子整数在需要更新整数变量（如计数器）的情况下特别高效，因为原子操作不需要锁定机制的开销。然而，它们的使用仅限于这些场景。在存在多个变量可能导致竞态条件的情况下，必须使用更复杂的锁定工具。 在 Linux 中，提供了用于保护内核中关键部分的互斥锁。在这里，任务在进入关键部分之前必须调用 mutex_lock() 函数，而在退出关键部分后必须调用 mutex_unlock() 函数。如果互斥锁不可用，调用 mutex_lock() 的任务将进入睡眠状态，并在锁的所有者调用 mutex_unlock() 时被唤醒。 Linux 还为内核提供自旋锁和信号量（以及这两种锁的读写版本）用于内核中的锁定。在 SMP（对称多处理）机器上，基本的锁定机制是自旋锁，并且内核被设计成仅在短时间内保持自旋锁。在单处理器机器上，例如仅有一个处理核心的嵌入式系统，自旋锁不适用并被启用和禁用内核抢占来替代。换句话说，在单处理器系统上，内核禁用内核抢占而不是持有自旋锁，然后启用内核抢占而不是释放自旋锁。总结如下： Linux 采用了一种有趣的方法来禁用和启用内核抢占。它提供了两个简单的系统调用——preempt_disable() 和 preempt_enable()——用于禁用和启用内核抢占。但是，如果运行在内核中的任务持有锁，则内核是不可抢占的。为了强制执行这一规则，系统中的每个任务都有一个包含计数器 preempt_count 的线程信息结构，用于指示任务持有的锁的数量。当获取锁时，preempt_count 递增，释放锁时递减。如果当前在内核中运行的任务的 preempt_count 值大于 0，则不能安全地抢占内核，因为此任务当前持有锁。如果计数为 0，则内核可以安全地被中断（假设没有未完成的对 preempt_disable() 的调用）。自旋锁以及启用和禁用内核抢占仅在必须短时间内保持锁时在内核中使用。当需要长时间持有锁时，信号量或互斥锁适合使用。 Pthreads同步 尽管Solaris中使用的锁定机制对用户级线程和内核线程都可用，但基本上讨论的同步方法涉及内核内的同步。相比之下，Pthreads API可用于用户级别的程序员，不属于任何特定的内核。该API为线程同步提供了互斥锁、条件变量和读-写锁。互斥锁代表了Pthreads中使用的基本同步技术。互斥锁用于保护代码的临界部分，即线程在进入临界部分之前获取锁，在退出临界部分时释放锁。Pthreads使用pthread_mutex_t数据类型表示互斥锁。可以使用pthread_mutex_init()函数创建互斥锁。第一个参数是指向互斥锁的指针。通过将第二个参数设置为NULL，我们将互斥锁初始化为其默认属性。下面是一个示例： 1234#include &lt;pthread.h&gt;pthread_mutex_t mutex;/* 创建互斥锁 */pthread_mutex_init(&amp;mutex, NULL); 互斥锁通过pthread_mutex_lock()和pthread_mutex_unlock()函数获取和释放。如果在调用pthread_mutex_lock()时互斥锁不可用，调用线程将被阻塞，直到所有者调用pthread_mutex_unlock()。以下代码示例说明了使用互斥锁保护临界部分： 12345/* 获取互斥锁 */pthread_mutex_lock(&amp;mutex);/* 临界部分 *//* 释放互斥锁 */pthread_mutex_unlock(&amp;mutex); 所有互斥锁函数在正确操作时返回0；如果发生错误，则这些函数返回非零错误代码。 许多实现Pthreads的系统也提供信号量，尽管信号量不是Pthreads标准的一部分，而是属于POSIX SEM扩展。POSIX规定了两种类型的信号量 - 命名和未命名。两者之间的基本区别在于，命名信号量在文件系统中有一个实际的名称，并且可以被多个无关的进程共享。未命名信号量只能由属于同一进程的线程使用。在本节中，我们描述未命名信号量。 下面的代码示例演示了用于创建和初始化未命名信号量的sem_init()函数： 1234#include &lt;semaphore.h&gt;sem_t sem;/* 创建信号量并将其初始化为1 */sem_init(&amp;sem, 0, 1); sem_init()函数传递了三个参数： 信号量的指针 表示共享级别的标志 信号量的初始值 在此示例中，通过传递标志0，我们表示该信号量只能由创建信号量的进程的线程共享。非零值将允许其他进程也访问该信号量。此外，我们将信号量初始化为值1。 我们描述了经典的wait()和signal()信号量操作。Pthreads将这些操作命名为sem_wait()和sem_post()。以下代码示例说明了使用上述创建的信号量保护临界部分： 12345/* 获取信号量 */sem_wait(&amp;sem);/* 临界部分 *//* 释放信号量 */sem_post(&amp;sem); 与互斥锁一样，所有信号量函数在成功时返回0，在发生错误条件时返回非零值。 Pthreads API还有其他扩展，包括自旋锁，但重要的是要注意，并非所有扩展都被认为在一个实现中可以从另一个实现中移植。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blackforest1990.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"进程管理","slug":"进程管理","permalink":"https://blackforest1990.github.io/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"线程","slug":"线程","date":"2023-12-05T07:40:18.000Z","updated":"2024-03-19T03:39:53.774Z","comments":true,"path":"2023/12/05/线程/","link":"","permalink":"https://blackforest1990.github.io/2023/12/05/%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"线程 几乎所有现代操作系统都提供了使进程能够包含多个控制线程的功能。我们引入了与多线程计算机系统相关的许多概念，包括对Pthreads和Java线程库的API的讨论。我们探讨了与多线程编程及其对操作系统设计的影响相关的许多问题。最后，我们探讨了Linux操作系统如何在内核级别支持线程。 概述 线程是CPU利用的基本单位；它包括线程ID、程序计数器、寄存器集和堆栈。它与属于同一进程的其他线程共享代码段、数据段和其他操作系统资源，如打开的文件和信号。传统（或重量级）进程具有单一的控制线程。如果一个进程具有多个控制线程，它可以同时执行多个任务。下图说明了传统的单线程进程和多线程进程之间的区别。 动机 一个应用程序通常被实现为一个独立的进程，拥有多个控制线程。例如，一个网络浏览器可能有一个线程显示图像或文本，一个线程从网络检索数据。一个文字处理软件可能有一个用于显示图形的线程，一个用于响应用户按键的线程，还有一个用于在后台执行拼写和语法检查的线程。应用程序还可以被设计为利用多核系统上的处理能力。这样的应用程序可以在多个计算核心上并行执行多个计算密集型任务。 在某些情况下，一个单一的应用程序可能需要执行多个类似的任务。例如，一个网络服务器接受客户端请求，请求可能包括网页、图像、声音等。一个繁忙的网络服务器可能同时有多个（可能是数千个）客户端访问它。如果网络服务器作为一个传统的单线程进程运行，它只能同时为一个客户端提供服务，客户端可能需要等待很长时间才能得到响应。 一种解决方法是让服务器作为一个单一进程接受请求。当服务器收到一个请求时，它创建一个单独的进程来处理该请求。事实上，在线程变得流行之前，这种进程创建的方法很常见。然而，进程创建是耗时且资源密集的。如果新进程将执行与现有进程相同的任务，为什么要承担这么大的开销呢？通常更有效的方法是使用一个包含多个线程的进程。如果网络服务器进程是多线程的，服务器将创建一个单独的线程来监听客户端请求。当请求到达时，服务器不是创建另一个进程，而是创建一个新的线程来处理该请求，并继续监听其他请求。 线程还在远程过程调用（RPC）系统中发挥着重要作用。通常，RPC服务器是多线程的。当服务器接收到一条消息时，它使用一个单独的线程来处理该消息。这使服务器能够同时处理多个并发请求。 最后，大多数操作系统内核现在也是多线程的。在内核中运行多个线程，每个线程执行特定的任务，如设备管理、内存管理或中断处理。例如，Solaris内核中有一组专门用于处理中断的线程；Linux使用一个内核线程来管理系统中的空闲内存量。 优点 响应性： 将交互式应用程序多线程化可能使程序在其部分被阻塞或执行长时间操作时继续运行，从而提高对用户的响应性。这一特性在设计用户界面时特别有用。例如，考虑当用户点击导致执行耗时操作的按钮时会发生什么情况。单线程应用程序在操作完成之前对用户不响应。相比之下，如果耗时操作在单独的线程中执行，应用程序将保持对用户的响应。 资源共享： 进程只能通过共享内存和消息传递等技术来共享资源。这些技术必须由程序员明确安排。然而，线程默认共享它们所属进程的内存和资源。共享代码和数据的好处是允许应用程序在同一地址空间内具有多个不同的活动线程。 经济性： 为进程创建分配内存和资源的成本很高。由于线程共享它们所属进程的资源，创建和切换线程更经济。在经验上评估开销的差异可能很困难，但总体上创建和管理进程比线程耗时得多。例如，在Solaris中，创建一个进程约比创建一个线程慢30倍，而上下文切换则慢5倍。 可伸缩性： 在多处理器架构中，多线程的好处可能更大，因为线程可以并行在不同的处理核心上运行。单线程的进程只能在一个处理器上运行，而不管有多少可用。 进程和线程有什么区别 进程是运行程序的抽象：二进制映像、虚拟化内存、各种内核资源、关联的安全上下文等。线程是进程中的执行单元：虚拟处理器、堆栈和程序状态。换句话说，进程是运行的二进制文件，线程是操作系统进程调度程序可调度的最小执行单元。 一个进程包含一个或多个线程。在单线程进程中，进程包含一个线程。你可以说线程就是进程——正在发生一件事。在多线程进程中，进程包含多个线程，即发生不止一件事。 现代操作系统中两个主要的虚拟化抽象是虚拟化内存和虚拟化处理器。两者都给正在运行的进程提供了一种错觉，认为它们单独消耗了机器的资源。虚拟化内存为进程提供了独特的内存视图，可以无缝映射回物理 RAM 或磁盘存储（交换空间）。虚拟化处理器让进程就像单独在处理器上运行一样，而实际上多个进程跨多个处理器执行多任务。 虚拟化内存与进程相关联，而不是与线程相关联。因此，线程共享一个内存地址空间。相反，不同的虚拟化处理器与每个线程相关联。每个线程都是一个独立的可调度实体。 多核编程 在计算机设计的早期阶段，为了提高计算性能，单CPU系统逐渐演变成多CPU系统。在系统设计的更近期的趋势是将多个计算核心集成到一个芯片上。每个核心对操作系统来说都表现为一个独立的处理器。无论这些核心是跨CPU芯片还是在CPU芯片内部，我们称这些系统为多核或多处理器系统。 多线程编程为更有效地利用这些多个计算核心和提高并发性提供了一种机制。考虑一个具有四个线程的应用程序。在一个具有单个计算核心的系统上，并发仅意味着线程的执行将随时间交错进行，因为处理核心一次只能执行一个线程。然而，在具有多个核心的系统中，并发意味着线程可以并行运行，因为系统可以为每个核心分配一个单独的线程。 在这个讨论中，请注意并行性和并发性之间的区别。如果系统能够同时执行多个任务，则系统是并行的。相反，一个并发的系统通过允许所有任务取得进展来支持多个任务。因此，有并发而没有并行是可能的。在SMP和多核架构出现之前，大多数计算机系统只有一个处理器。CPU调度器被设计为通过在系统中迅速切换进程，从而使每个进程取得进展，从而提供并行性的假象。这样的进程是同时运行的，但不是并行的。 随着系统从几十个线程增长到数千个线程，CPU设计者通过添加硬件来改善线程性能，从而提高了系统性能。现代的Intel CPU通常支持每个核心两个线程，而Oracle T4 CPU支持每个核心八个线程。这种支持意味着可以将多个线程加载到核心中进行快速切换。多核计算机毫无疑问将继续增加核心数和硬件线程支持。 阿姆达尔定律是一个公式，用于确定将额外的计算核心添加到既有串行（非并行）组件又有并行组件的应用程序中可能获得的性能增益。如果S是在具有N个处理核心的系统上必须串行执行的应用程序的部分，该公式如下所示： $$ speedup ≤ 1/(S+(1-S)/N) $$ 例如，假设我们有一个应用程序，其中75%是并行的，25%是串行的。如果我们在一个具有两个处理核心的系统上运行此应用程序，我们可以获得1.6倍的加速。如果我们添加两个额外的核心（总共四个），加速比为2.28倍。 随着N趋近于无穷大，加速比趋近于1/S。例如，如果应用程序的40%是串行执行的，最大加速比为2.5倍，无论我们添加多少个处理核心。这是阿姆达尔定律的基本原则：应用程序的串行部分可以对通过添加额外计算核心获得的性能增益产生不成比例的影响。 有人认为阿姆达尔定律未考虑当代多核系统设计中使用的硬件性能增强因素。这些观点表明，随着处理核心数量在现代计算机系统上继续增加，阿姆达尔定律可能不再适用。 编程挑战 多核系统的趋势继续给系统设计师和应用程序员带来了更大的压力，要更好地利用多个计算核心。操作系统的设计者必须编写使用多个处理核心的调度算法，以实现并行执行。对于应用程序员来说，挑战在于修改现有程序以及设计新的支持多线程的程序。 总的来说，在为多核系统编程时有五个方面的挑战： 识别任务： 这涉及检查应用程序，找到可以分为独立并发任务的领域。理想情况下，任务是相互独立的，因此可以在各个核心上并行运行。 平衡： 在识别可以并行运行的任务的同时，程序员还必须确保这些任务执行相等价值的相等工作。在某些情况下，某个任务对整个过程的贡献可能不如其他任务大。为了运行该任务，使用一个单独的执行核心可能不值得成本。 数据分割： 正如应用程序被划分为独立任务一样，任务访问和操作的数据必须分割以在不同的核心上运行。 数据依赖性： 必须检查任务访问的数据，以了解两个或更多任务之间的依赖关系。当一个任务依赖于另一个任务的数据时，程序员必须确保任务的执行是同步的，以适应数据依赖性。 测试和调试： 当一个程序在多个核心上并行运行时，可能有许多不同的执行路径。测试和调试这样的并发程序比测试和调试单线程应用程序更加困难。 并行性的类型 总的来说，有两种类型的并行性：数据并行性和任务并行性。数据并行性侧重于将相同数据的子集分布到多个计算核心上，并在每个核心上执行相同的操作。例如，考虑对大小为N的数组的内容求和。在单核系统上，一个线程将简单地对元素[0] . . . [N − 1]进行求和。然而，在双核系统上，运行在核心0上的线程A可以对元素[0] . . . [N/2 − 1]进行求和，同时在核心1上运行的线程B可以对元素[N/2] . . . [N − 1]进行求和。这两个线程将在分别的计算核心上并行运行。 任务并行性涉及在多个计算核心上分发任务（线程），而不是数据。每个线程执行唯一的操作。不同的线程可以操作相同的数据，也可以操作不同的数据。再次考虑上面的例子。与那种情况相反，任务并行性的一个例子可能涉及两个线程，每个线程在元素数组上执行唯一的统计操作。这两个线程再次在分别的计算核心上并行运行，但每个线程执行的是唯一的操作。 因此，基本上，数据并行性涉及在多个核心上分布数据，任务并行性涉及在多个核心上分布任务。然而，在实践中，很少有应用程序严格遵循数据或任务并行性。在大多数情况下，应用程序使用这两种策略的混合形式。 多线程模型 到目前为止，我们讨论的线程是在一个通用的范围内。然而，线程的支持可以在用户级别提供，用于用户线程，也可以由内核提供，用于内核线程。用户线程在内核之上得到支持，并且在没有内核支持的情况下进行管理，而内核线程由操作系统直接支持和管理。几乎所有当代操作系统，包括Windows、Linux、Mac OS X和Solaris，都支持内核线程。最终，用户线程和内核线程之间必须建立某种关系。我们将讨论建立这种关系的三种常见方式：多对一模型、一对一模型和多对多模型。 多对一模型 将多个用户级线程映射到一个内核线程。线程管理由用户空间中的线程库完成，因此它是高效的。然而，如果一个线程进行了阻塞系统调用，整个进程将被阻塞。而且，由于一次只能有一个线程访问内核，多个线程无法在多核系统上并行运行。绿色线程（Solaris系统上提供的线程库，在早期Java版本中采用了这种模型）使用了多对一模型。然而，由于无法充分利用多个处理核心，很少有系统继续使用这种模型。 一对一模型 将每个用户线程映射到一个内核线程。相较于多对一模型，它提供了更多的并发性，因为当一个线程进行阻塞系统调用时，允许另一个线程运行。它还允许多个线程在多处理器上并行运行。这个模型唯一的缺点是创建一个用户线程需要创建相应的内核线程。由于创建内核线程的开销可能会影响应用程序的性能，因此该模型的大多数实现会限制系统支持的线程数量。Linux以及Windows操作系统家族实现了一对一模型。 多对多模型 多对多模型将许多用户级线程复用到较小或同等数量的内核线程上。内核线程的数量可能特定于特定应用程序或特定机器（在多处理器上，与在单处理器上相比，一个应用程序可能会被分配更多的内核线程）。开发者可以创建任意数量的用户线程，相应的内核线程可以在多处理器上并行运行。此外，当一个线程执行阻塞系统调用时，内核可以调度另一个线程来执行。 多对多模型的一种变体仍然将许多用户级线程复用到较小或等于数量的内核线程上，但还允许将用户级线程绑定到内核线程上。这种变体有时被称为两级模型。Solaris操作系统在Solaris 9之前的版本中支持了两级模型。然而，从Solaris 9开始，该系统采用了一对一模型。 线程库 线程库为程序员提供了一个用于创建和管理线程的API。实现线程库有两种主要方法。第一种方法是在用户空间完全提供一个没有内核支持的库。库的所有代码和数据结构都存在于用户空间。这意味着调用库中的函数会导致用户空间中的本地函数调用，而不是系统调用。第二种方法是实现一个由操作系统直接支持的内核级库。在这种情况下，库的代码和数据结构存在于内核空间。调用库的API中的函数通常会导致对内核的系统调用。 今天有三个主要的线程库在使用中：POSIX Pthreads、Windows和Java。Pthreads是POSIX标准的线程扩展，可以提供作为用户级或内核级库。Windows线程库是一个在Windows系统上可用的内核级库。Java线程API允许在Java程序中直接创建和管理线程。然而，由于在大多数情况下JVM在主机操作系统之上运行，Java线程API通常是使用主机系统上可用的线程库实现的。这意味着在Windows系统上，Java线程通常是使用Windows API实现的；UNIX和Linux系统通常使用Pthreads。 对于POSIX和Windows线程，任何在函数外部声明的全局数据（即在任何函数外部声明的数据）都将在属于同一进程的所有线程之间共享。因为Java没有全局数据的概念，对共享数据的访问必须在线程之间明确安排。在函数内部声明的数据通常存储在堆栈上。由于每个线程都有自己的堆栈，每个线程都有自己的本地数据副本。 两种通用线程策略： 异步线程：一旦父线程创建了一个子线程，父线程就会恢复其执行，使得父线程和子线程同时执行。每个线程独立于其他每个线程运行，父线程无需知道其子线程何时终止。由于线程是独立的，通常在线程之间很少共享数据。 同步线程：发生在父线程创建一个或多个子线程，然后必须等待所有子线程终止才能继续执行的情况下，即所谓的fork-join策略。在这里，由父线程创建的线程并行执行工作，但是父线程在这项工作完成之前不能继续。一旦每个线程完成了它的工作，它就会终止并与其父线程合并。只有在所有子线程都合并后，父线程才能继续执行。通常，同步线程涉及大量线程之间的数据共享。 Pthreads Pthreads指的是POSIX标准（IEEE 1003.1c），定义了线程创建和同步的API。这是线程行为的规范，而不是具体的实现。操作系统设计者可以以任何他们希望的方式实现这个规范。许多系统实现了Pthreads规范；大多数是UNIX类型的系统，包括Linux、Mac OS X和Solaris。 下面显示的C程序演示了用于构建多线程程序的基本Pthreads API，该程序在单独的线程中计算非负整数的求和。当此程序开始运行时，一个控制线程从main()开始。在一些初始化之后，main()创建了一个第二个线程，该线程从runner()函数开始控制。两个线程共享全局数据sum。所有Pthreads程序都必须包含pthread.h头文件。语句pthread_t tid声明了我们将要创建的线程的标识符。每个线程都有一组属性，包括堆栈大小和调度信息。pthread_attr_t attr声明表示线程的属性。我们在函数调用pthread_attr_init(&amp;attr) 中设置这些属性。因为我们没有明确设置任何属性，所以使用了提供的默认属性。使用pthread_create()函数调用创建一个单独的线程。除了传递线程标识符和线程的属性外，我们还传递新线程将开始执行的函数的名称，即runner()函数。最后，我们传递从命令行提供的整数参数，即argv[1]。此时，程序有两个线程：在main()中的父线程和在runner()函数中执行求和操作的子线程。该程序遵循先前描述的fork-join策略：创建求和线程后，父线程将通过调用pthread_join()函数等待其终止。求和线程将在调用pthread_exit()函数时终止。一旦求和线程返回，父线程将输出共享数据sum的值。 123456789101112131415161718192021222324252627282930313233#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;int sum; /* this data is shared by the thread(s) */void *runner(void *param); /* threads call this function */int main(int argc, char *argv[])&#123; pthread_t tid; /* the thread identifier */ pthread_attr_t attr; /* set of thread attributes */ if (argc != 2) &#123; fprintf(stderr,&quot;usage: a.out &lt;integer value&gt;\\n&quot;); return -1; &#125; if (atoi(argv[1]) &lt; 0) &#123; fprintf(stderr,&quot;%d must be &gt;= 0\\n&quot;,atoi(argv[1])); return -1; &#125; /* get the default attributes */ pthread_attr_init(&amp;attr); /* create the thread */ pthread_create(&amp;tid,&amp;attr,runner,argv[1]); /* wait for the thread to exit */ pthread_join(tid,NULL); printf(&quot;sum = %d\\n&quot;,sum);&#125;/* The thread will begin control in this function */void *runner(void *param)&#123; int i, upper = atoi(param); sum = 0; for (i = 1; i &lt;= upper; i++) sum += i; pthread_exit(0);&#125; 随着多核系统的普及，编写包含多个线程的程序变得越来越普遍。使用pthread_join()函数等待多个线程的简单方法是将操作放在一个简单的for循环中。 12345#define NUM_THREADS 10/* an array of threads to be joined upon */pthread_t workers[NUM_THREADS];for (int i = 0; i &lt; NUM_THREADS; i++) pthread_join(workers[i], NULL); Java Threads 线程是Java程序中程序执行的基本模型，Java语言及其API提供了丰富的功能集，用于创建和管理线程。所有Java程序至少包含一个控制线程，即使是一个只包含main()方法的简单Java程序也会作为一个单线程在JVM中运行。Java线程可用于任何提供JVM的系统，包括Windows、Linux和Mac OS X。Java线程API也适用于Android应用程序。 在Java程序中，有两种创建线程的技术。一种方法是创建一个新类，该类派生自Thread类，并覆盖其run()方法。另一种——更常用的——技术是定义一个实现了Runnable接口的类。Runnable接口定义如下： 123public interface Runnable &#123; public abstract void run();&#125; 当一个类实现了Runnable接口时，它必须定义一个run()方法。实现run()方法的代码将作为一个单独的线程运行。 下面展示了一个在Java中确定非负整数求和的多线程程序的Java版本。Summation类实现了Runnable接口。线程的创建通过创建Thread类的对象实例并将构造函数传递给一个Runnable对象来完成。 12345678910111213141516171819202122232425262728293031323334353637383940414243class Sum private int sum; public int getSum() &#123; return sum; &#125; public void setSum(int sum) &#123; this.sum = sum; &#125;&#125;class Summation implements Runnable&#123; private int upper; private Sum sumValue; public Summation(int upper, Sum sumValue) &#123; this.upper = upper; this.sumValue = sumValue; &#125; public void run() &#123; int sum = 0; for (int i = 0; i &lt;= upper; i++) sum += i; sumValue.setSum(sum); &#125;&#125;public class Driver&#123; public static void main(String[] args) &#123; if (args.length &gt; 0) &#123; if (Integer.parseInt(args[0]) &lt; 0) System.err.println(args[0] + &quot; must be &gt;= 0.&quot;); else &#123; Sum sumObject = new Sum(); int upper = Integer.parseInt(args[0]); Thread thrd = new Thread(new Summation(upper, sumObject)); thrd.start(); try &#123; thrd.join(); System.out.println(&quot;The sum of &quot;+upper+&quot; is &quot;+sumObject.getSum()); &#125; catch (InterruptedException ie) &#123;&#125; &#125; else System.err.println(&quot;Usage: Summation &lt;integer value&gt;&quot;); &#125;&#125; 创建Thread对象并不会直接创建新线程；相反，start()方法创建新线程。对新对象调用start()方法会执行两件事情： 在JVM中分配内存并初始化一个新线程。 调用run()方法，使线程有资格在JVM中运行。 当求和程序运行时，JVM会创建两个线程。第一个是父线程，在main()方法中开始执行。第二个线程在调用Thread对象上的start()方法时创建。这个子线程在Summation类的run()方法中开始执行。在输出求和值后，此线程在退出其run()方法时终止。 在线程之间共享数据在Windows和Pthreads中很容易，因为共享数据只需在全局声明即可。作为一种纯面向对象的语言，Java没有全局数据的概念。如果Java程序中的两个或多个线程需要共享数据，共享是通过将对共享对象的引用传递给适当的线程来进行的。通过适当的getSum()和setSum()方法引用此共享对象。Pthreads库中的父线程使用pthread_join()来等待求和线程完成后继续的方式。Java中的join()方法提供了类似的功能。 JVM和主机操作系统 JVM通常是在主机操作系统之上实现的。这种设置使得JVM能够隐藏底层操作系统的实现细节，并提供一个一致的、抽象的环境，使Java程序能够在支持JVM的任何平台上运行。JVM的规范并未说明如何将Java线程映射到底层操作系统，而是将该决策留给JVM的具体实现。例如，Windows XP操作系统使用一对一模型；因此，在这样的系统上运行的JVM的每个Java线程都映射到一个内核线程。在使用多对多模型的操作系统（例如Tru64 UNIX）上，Java线程根据多对多模型进行映射。Solaris最初使用了多对一模型来实现JVM（前面提到的绿色线程库）。JVM的后续版本则使用了多对多模型。从Solaris 9开始，Java线程使用了一对一模型进行映射。此外，Java线程库和主机操作系统上的线程库之间可能存在关系。例如，针对Windows家族操作系统的JVM实现可能在创建Java线程时使用Windows API；而Linux、Solaris和Mac OS X系统可能使用Pthreads API。 隐式线程 随着多核处理的不断增长，包含数百甚至数千个线程的应用程序即将出现。为了更好地支持多线程应用程序的设计，一种方法是将线程的创建和管理从应用程序开发人员转移到编译器和运行时库中。这种策略被称为隐式线程implicit threading，是当今的一个流行趋势。 Thread Pools 我们描述了一个多线程的Web服务器。在这种情况下，每当服务器收到一个请求，它就会创建一个单独的线程来处理该请求。虽然创建单独的线程肯定比创建单独的进程更好，但是多线程服务器仍然存在潜在的问题。第一个问题涉及创建线程所需的时间，以及一旦线程完成工作就会被丢弃。第二个问题更为棘手。如果我们允许所有并发请求在新线程中得到服务，那么系统中同时活动的线程数量就没有限制。无限制的线程可能会耗尽系统资源，如CPU时间或内存。解决这个问题的一种方法是使用线程池。 线程池背后的一般思想是在进程启动时创建一些线程，并将它们放入一个池中，等待工作。当服务器收到一个请求时，它唤醒池中的一个线程（如果有的话），并将请求传递给它进行处理。一旦线程完成服务，它就返回到池中等待更多的工作。如果池中没有可用的线程，服务器将等待直到有一个线程空闲。 线程池提供以下优势： 使用现有线程来处理请求比等待创建线程更快。 线程池限制了任一时刻存在的线程数量。这在不能支持大量并发线程的系统中尤为重要。 将要执行的任务与创建任务的机制分离，使我们能够使用不同的策略来运行任务。例如，可以安排任务在一段时间后执行或定期执行。 线程池的线程数量可以根据启发式算法设置，考虑因素包括系统中的CPU数量、物理内存量和预期的并发客户端请求数。更复杂的线程池架构可以根据使用模式动态调整池中的线程数量。这样的架构在系统负载较低时提供更小的池，从而消耗更少的内存。 OpenMP OpenMP是一组编译器指令以及用于在C、C++或FORTRAN中编写的程序的API，为共享内存环境中的并行编程提供支持。OpenMP将并行区域标识为可能并行运行的代码块。应用程序开发人员在其代码中在并行区域插入编译器指令，这些指令指示OpenMP运行时库在并行中执行该区域。以下是一个包含printf()语句的并行区域上方的编译器指令的C程序示例： 12345678910#include &lt;omp.h&gt;#include &lt;stdio.h&gt;int main(int argc, char *argv[]) &#123; /* 顺序代码 */ #pragma omp parallel printf(&quot;I am a parallel region.\\n&quot;); /* 顺序代码 */ return 0;&#125; 当OpenMP遇到指令#pragma omp parallel时，它会创建与系统中的处理核心数量相同的线程。因此，对于双核系统，将创建两个线程；对于四核系统，将创建四个线程；依此类推。然后，所有线程同时执行并行区域。每个线程退出并行区域时，它将被终止。 OpenMP提供了一些额外的指令来并行运行代码区域，包括并行化循环。例如，假设我们有两个大小为N的数组a和b。我们希望将它们的内容相加并将结果放入数组c。我们可以通过使用以下包含并行化for循环指令的代码段来并行运行此任务： 1234#pragma omp parallel forfor (i = 0; i &lt; N; i++) &#123; c[i] = a[i] + b[i];&#125; OpenMP将for循环中的工作分配给它根据指令#pragma omp parallel for创建的线程。 除了提供并行化指令外，OpenMP还允许开发人员在多个并行性级别之间进行选择。例如，他们可以手动设置线程数。它还允许开发人员确定数据是否在线程之间共享或对线程私有。OpenMP在Linux、Windows和Mac OS X系统的多个开源和商业编译器上都可用。 Grand Central Dispatch Grand Central Dispatch (GCD) 是苹果的 Mac OS X 和 iOS 操作系统的一项技术，它是 C 语言的扩展、一个 API 和一个运行时库的组合，允许应用程序开发人员标识要并行运行的代码段。与 OpenMP 类似，GCD 管理大部分线程细节。 GCD 标识了称为 blocks 的 C 和 C++ 语言扩展。一个 block 简单地是一个自包含的工作单元，由插入在一对大括号 { } 前面的插入符 ^ 指定。下面是一个 block 的简单示例： 1^&#123; printf(&quot;I am a block&quot;); &#125; GCD 通过将 block 放置在调度队列上来为运行时执行调度 block。当它从队列中移除一个 block 时，它将该 block 分配给其管理的线程池中的一个可用线程。GCD 标识了两种类型的调度队列：串行队列和并发队列。 放置在串行队列上的 block 按照先进先出（FIFO）的顺序被移除。一旦一个 block 从队列中移除，它必须在移除另一个 block 之前完成执行。每个进程都有自己的串行队列（称为主队列）。开发人员可以创建局部于特定进程的额外串行队列。串行队列对于确保多个任务的顺序执行非常有用。 放置在并发队列上的 block 也按照先进先出的顺序被移除，但是可以同时移除多个 block，从而允许多个 block 并行执行。系统有三个全局并发调度队列，并且根据优先级进行区分：低、默认和高。优先级表示 block 相对重要性的近似值。简单来说，具有更高优先级的 block 应该放置在高优先级调度队列上。 以下代码段演示了如何获取默认优先级的并发队列并使用 dispatch_async() 函数将一个 block 提交到队列中： 12dispatch_queue_t queue = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0);dispatch_async(queue, ^&#123; printf(&quot;I am a block.&quot;); &#125;); 在内部，GCD 的线程池由 POSIX 线程组成。GCD 主动管理该池，允许线程的数量根据应用程序需求和系统容量而增长和收缩。 线程问题 The fork() and exec() System Calls fork() 系统调用用于创建一个独立的、重复的进程。在多线程程序中，fork() 和 exec() 系统调用的语义发生了变化。如果程序中的一个线程调用了 fork()，那么新进程是复制所有线程，还是新进程是单线程的呢？一些 UNIX 系统选择使用两个版本的 fork()，一个版本复制所有线程，另一个版本只复制调用了 fork() 系统调用的线程。 如果一个线程调用了 exec() 系统调用，那么参数中指定的程序将替换整个进程，包括所有线程。 选择使用 fork() 的哪个版本取决于应用程序。如果在 fork() 后立即调用 exec()，则复制所有线程是不必要的，因为参数中指定的程序将替换进程。在这种情况下，只复制调用线程是合适的。然而，如果在 fork() 后独立的进程没有调用 exec()，那么独立的进程应该复制所有线程。 信号处理 信号在UNIX系统中用于通知一个进程特定事件发生。信号可以是同步接收的，也可以是异步接收的，这取决于事件发生的源头和原因。所有信号，无论是同步还是异步，都遵循相同的模式： 通过发生特定事件生成信号。 将信号传递给一个进程。 一旦传递，必须处理信号。 同步信号的示例包括非法内存访问和除零。如果运行中的程序执行这些操作之一，就会生成一个信号。同步信号被传递给执行引起信号的操作的同一进程（这就是它们被认为是同步的原因）。 当由运行进程外部事件生成信号时，该进程异步接收信号。此类信号的示例包括使用特定按键（例如）终止进程以及计时器超时。通常，异步信号被发送到另一个进程。 一个信号可以由两种可能的处理程序之一处理： 默认信号处理程序 用户定义的信号处理程序 每个信号都有一个默认信号处理程序，内核在处理该信号时运行该处理程序。这个默认操作可以被用户定义的信号处理程序覆盖，后者被调用以处理信号。信号的处理方式各不相同。有些信号（例如更改窗口大小）被简单地忽略；其他信号（例如非法内存访问）通过终止程序来处理。 在单线程程序中处理信号是直截了当的：信号总是传递给一个进程。然而，在多线程程序中，一个进程可能有多个线程，因此传递信号更加复杂。那么，信号应该传递到哪里呢？ 将信号传递给引起信号的线程。 将信号传递给进程中的每个线程。 将信号传递给进程中的某些线程。 为接收进程的所有信号分配一个特定的线程。 传递信号的方法取决于生成的信号类型。例如，同步信号需要传递给引起信号的线程，而异步信号的情况则不那么明确。一些异步信号（例如终止进程的信号，如）应该发送到所有线程。 传递信号的标准UNIX函数是： 1int kill(pid_t pid, int signal); 这个函数指定了要向其发送特定信号的进程（pid）。大多数多线程版本的UNIX允许线程指定它们将接受哪些信号和哪些信号将被阻塞。因此，在某些情况下，异步信号可能只被传递到不阻塞它的那些线程。但是，由于信号只需要处理一次，因此通常只将信号传递到找到的第一个不阻塞它的线程。POSIX Pthreads提供了以下函数，允许将信号传递给指定的线程（tid）： 1int pthread_kill(pthread_t tid, int signal); 线程取消 线程取消涉及在其完成之前终止线程。例如，如果多个线程同时在数据库中搜索，其中一个线程返回结果，那么可能会取消其余的线程。另一种情况可能发生在用户按下 Web 浏览器上的按钮停止网页进一步加载时。通常，一个网页使用多个线程加载 ——每个图像都在单独的线程中加载。当用户按下浏览器上的停止按钮时，加载页面的所有线程都将被取消。 即将取消的线程通常称为目标线程。取消目标线程可能发生在两种不同的场景下： 异步取消。一个线程立即终止目标线程。 延迟取消。目标线程周期性地检查是否应该终止，允许其有机会以有序的方式自行终止。 如果资源已分配给要取消的线程或要取消的线程正在更新与其他线程所共享的数据，那么取消就会有困难。这在异步取消的情况下尤其麻烦。通常，操作系统将从已取消的线程中回收系统资源，但不会回收所有资源。因此，异步取消可能无法释放必要的系统范围资源。相反，延迟取消中，一个线程指示目标线程应该被取消，但取消只在目标线程检查标志以确定是否应该取消时发生。Pthread称这些点为取消点 (cancellation point)。 在Pthreads中，使用pthread_cancel()函数启动线程取消。目标线程的标识符作为参数传递给该函数。 123456pthread_t tid;/* 创建线程 */pthread_create(&amp;tid, 0, worker, NULL);. . ./* 取消线程 */pthread_cancel(tid); 然而，调用pthread_cancel()只是表示请求取消目标线程；实际的取消取决于目标线程如何设置以处理请求。Pthreads支持三种取消模式。每种模式都定义为一种状态和一种类型，如下表所示。线程可以使用API设置其取消状态和类型。 正如表格所示，Pthreads允许线程禁用或启用取消。显然，如果禁用取消，线程将无法被取消。但是，取消请求仍然挂起，因此线程稍后可以启用取消并响应请求。默认的取消类型是延迟取消。在这里，取消仅在线程到达取消点cancellation point时发生。建立取消点的一种技术是调用pthread_testcancel()函数。如果发现有挂起的取消请求，则将调用一个称为清理处理程序cleanup handler 的函数。此函数允许线程释放可能已经获取的任何资源，然后线程终止。 以下代码演示了线程如何使用延迟取消响应取消请求： 123456while (1) &#123; /* 进行一段时间的工作 */ /* . . . */ /* 检查是否有取消请求 */ pthread_testcancel();&#125; 由于前述问题，Pthreads文档不推荐使用异步取消。因此，我们在这里不进行介绍。有趣的是，在Linux系统上，使用Pthreads API进行线程取消是通过信号处理的。 Thread-Local Storage 属于一个进程的线程共享该进程的数据。事实上，这种数据共享是多线程编程的一个好处之一。然而，在某些情况下，每个线程可能需要拥有某些数据的自己的副本。我们将这样的数据称为线程本地存储（TLS）。例如，在事务处理系统中，我们可能在单独的线程中处理每个事务。此外，每个事务可能被分配一个唯一的标识符。为了将每个线程与其唯一标识符关联起来，我们可以使用线程本地存储。 很容易将 TLS 与局部变量混淆。然而，局部变量仅在单个函数调用期间可见，而 TLS 数据在函数调用之间是可见的。在某些方面，TLS 与静态数据类似。区别在于 TLS 数据对于每个线程是唯一的。大多数线程库，包括 Windows 和 Pthreads，都提供对线程本地存储的某种形式的支持；Java 也提供支持。 调度程序激活 多线程程序需要考虑的最后一个问题涉及内核与线程库之间的通信，这可能是由多对多和双层模型所要求的。这种协调允许动态调整内核线程的数量，以确保最佳性能。 许多实现多对多或双层模型的系统在用户线程和内核线程之间放置了一个中间数据结构。这个数据结构通常称为轻量级进程（Lightweight Process，LWP）。对于用户线程库来说，LWP 看起来像是可以调度用户线程运行的虚拟处理器。每个 LWP 都附加到一个内核线程上，而操作系统调度的是内核线程在物理处理器上运行。如果一个内核线程阻塞（例如，等待 I/O 操作完成），LWP 也会阻塞。在上层，附加到 LWP 的用户级线程也会阻塞。 一个应用程序可能需要任意数量的 LWPs 来有效运行。考虑在单个处理器上运行的 CPU 密集型应用程序。在这种情况下，一次只能运行一个线程，因此一个 LWP 就足够了。然而，I/O 密集型的应用程序可能需要多个 LWPs 来执行。通常，每个并发的阻塞系统调用都需要一个 LWP。例如，假设同时发生了五个不同的文件读取请求。需要五个 LWPs，因为它们都可能在内核中等待 I/O 完成。如果一个进程只有四个 LWPs，那么第五个请求必须等待其中一个 LWP 从内核返回。 用户线程库和内核之间的通信方案之一被称为调度程序激活（scheduler activation）。其工作原理如下：内核提供应用程序一组虚拟处理器（LWPs），应用程序可以将用户线程调度到可用的虚拟处理器上。此外，内核必须通知应用程序某些事件。这个过程被称为 upcall。Upcalls 由线程库处理，使用 upcall 处理程序，并且 upcall 处理程序必须在虚拟处理器上运行。 触发 upcall 的一个事件是应用程序线程即将阻塞。在这种情况下，内核通过 upcall 通知应用程序线程即将阻塞，并标识特定的线程。然后，内核为应用程序分配一个新的虚拟处理器。应用程序在这个新的虚拟处理器上运行一个 upcall 处理程序，该处理程序保存阻塞线程的状态并放弃正在运行阻塞线程的虚拟处理器。然后，upcall 处理程序调度另一个有资格在新虚拟处理器上运行的线程。当阻塞线程等待的事件发生时，内核再次发起 upcall 给线程库，通知它先前被阻塞的线程现在有资格运行。这个事件的 upcall 处理程序也需要一个虚拟处理器，内核可能分配一个新的虚拟处理器或抢占其中一个用户线程并在其虚拟处理器上运行 upcall 处理程序。在标记未阻塞的线程有资格运行之后，应用程序调度一个有资格在可用虚拟处理器上运行的线程。 Linux 线程 Linux提供了fork()系统调用，具有复制进程的传统功能。Linux还提供使用clone()系统调用创建线程的能力。然而，Linux不区分进程和线程。事实上，Linux在引用程序中的控制流时使用术语task而不是process或thread。 当调用clone()时，它会传递一组标志，这些标志确定父任务和子任务之间要共享多少。假设clone()传递了标志CLONE_FS、CLONE_VM、CLONE_SIGHAND和CLONE_FILES。那么父任务和子任务将共享相同的文件系统信息（例如当前工作目录）、相同的内存空间、相同的信号处理程序和相同的打开文件集。以这种方式使用clone()相当于创建线程，因为父任务与其子任务共享大多数资源。但是，如果在调用clone()时没有设置这些标志中的任何一个，将不会发生共享，结果类似于fork()系统调用提供的功能。 共享级别的差异是可能的，因为任务在Linux内核中的表示方式。对于系统中的每个任务，都存在一个唯一的内核数据结构（具体而言，是struct task_struct）。该数据结构不存储任务的数据，而是包含指向其他数据结构的指针，其中存储了这些数据，例如表示打开文件列表、信号处理信息和虚拟内存的数据结构。当调用fork()时，将创建一个新任务，以及父进程的所有相关数据结构的副本。当调用clone()系统调用时，也会创建一个新任务。但是，与其复制所有数据结构不同，新任务根据传递给clone()的标志集指向父任务的数据结构。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blackforest1990.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"进程管理","slug":"进程管理","permalink":"https://blackforest1990.github.io/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"how to get a job","slug":"how-to-get-a-job","date":"2023-12-02T00:49:53.000Z","updated":"2023-12-04T08:18:58.257Z","comments":true,"path":"2023/12/02/how-to-get-a-job/","link":"","permalink":"https://blackforest1990.github.io/2023/12/02/how-to-get-a-job/","excerpt":"","text":"维基百科指出，就业就是两个合作伙伴中的契约关系。契约关系就是合同关系，只有做到win-win，才能找到一份合适的工作。所以找工作的方法论应该如下：分析个人能力画像，分析目标雇主，如何达成交易。 个人能力画像 工作经历 公司 职位 描述 时间 华为 核心网工程师 软件开发：基于C/Linux/华为ATCA R9单板，负责核心网 IMS 业务开发。 市场技术：欧洲区市场技术接口，云化核心网大T集采，答标支持，需求分析，竞品分析。 2012.08-2016.10 华为 产品经理 行销代表：信令产品（核心网）全球行销代表, ，营销材料上市，出差支持关键项目。 一线行销产品经理：负责核心网产品在乌干达的销售，客户关系拓展，关键格局项目拓展，峰会策划 2016.10-2019.10 无公司 离职 因为媳妇第一个和第二个孩子都掉了，出现了心理问题，然后就一年没咋找工作 2019.10-2020.11 东莞固润科技有限公司 市场总监 父亲介绍，进入固高科技(深圳)有限公司，负责市场体系工作，担任固高子公司固润科技的市场总监（环保方向），21年9月份因为家庭原因离职。 2020.11-2021.09 无公司 离职 现在已经失业两年多了，也没找工作，辞职情况没有敢跟家里说。 2021.09-至今 个人能力模型 项目 描述 评估 英文 熟练阅读，写作，客户交流，workshop，但演进没有用英文做过 良好 通信行业 熟悉核心网，熟悉运营商市场，对于架构和运作方式较为了解 一般 云计算 有电信私有云的实操经验，但对于公有云缺乏理解，实际上来说公有云才是行业的基础 差 水务市场 对于国内的水务市场还停留在了解阶段，没有打过仗 差 编程能力 C语言熟练，但只是对于应用有开发经验，对于底层理解不够 一般 沟通能力 对于风格较为强硬的客户也能做到良好沟通，没有跟客户发展到良好的私人关系，仅限商务交流 一般 商务能力 给客户报过价，客户按照框架合同下的PO，合同谈判能力不足 差 销售能力 没有独立开发过客户，基本上是公司的资源，然后我们负责维护关键客户 一般 团队合作 组建过销售团队，只招到一个投标专员，团队没有成功组建起来 差 个人职业评估 产品经理或解决方案架构师： 你在华为的核心网产品经理职位可能为你提供了产品管理和解决方案设计的经验。这些技能可以转移到其他公司，从事类似的产品管理、解决方案设计或架构师等职位。 技术销售与业务发展： 由于你在华为有信令产品行销代表的经验，同时具备技术背景，可以考虑在技术销售领域寻找机会，尤其是涉及核心网等领域的产品销售和业务发展。 国际业务发展： 你有在国外工作的经验，可以考虑寻找涉及国际业务发展或跨国公司的职位。这可能包括国际销售、业务拓展或国际市场经理等角色。 分析目标雇主 通信，云计算，智能化设备市场优先 职位上先考虑产品经理，再考虑销售人员，偏技术的岗位国内可以投，偏市场的岗位海外市场多投一些 中小企业也可以考虑，但要查询相关企业的文化和雇员信息。 如何达成交易 简历优化，写在简历上的东西真实可靠，但不写对于自己不利的东西 根据任职资格要求，匹配达到60%以上进行投递。 根据岗位职责，写关于该岗位的理解，以及以往工作经验对于该岗位的帮助。 陈述gap year：1. 老婆的生病，照顾家庭 2. 一定的心理问题，承受不了压力 3. 通过学习和好好生活走出来了 精神状态一定要阳光，happy and tough 快速响应，不要瞻前顾后。","categories":[{"name":"如何赚钱","slug":"如何赚钱","permalink":"https://blackforest1990.github.io/categories/%E5%A6%82%E4%BD%95%E8%B5%9A%E9%92%B1/"}],"tags":[{"name":"工作","slug":"工作","permalink":"https://blackforest1990.github.io/tags/%E5%B7%A5%E4%BD%9C/"}]},{"title":"how to make money","slug":"how-to-make-money","date":"2023-11-29T03:39:24.000Z","updated":"2023-12-04T03:11:13.265Z","comments":true,"path":"2023/11/29/how-to-make-money/","link":"","permalink":"https://blackforest1990.github.io/2023/11/29/how-to-make-money/","excerpt":"","text":"如何赚钱呢，这是一个大问题，如何根据自己的能力模型，在有限的时间能够合法的赚到尽可能多的钱，本文先对于个人做分析，认清现实，再去思考每一条赚钱的路子是否可行，给出自己的分析，然后再去实践，然后根据实践结构反馈修正。 个人情况 工作情况 武汉理工大学毕业，理科生，毕业后任职于华为技术有限公司，一开始做13级的初级软件工程师，13级做了4年，绩效不好，而且产品线也不太行，后来转向市场营销，做过信令产品的行销代表，后去去做核心网产品经理，才升到15级了，中间有一些国家出差经验（阿根廷/墨西哥/奥地利/日本），后来在非洲一个小国常驻了一年，这个时期年收入有70万左右，后面因为媳妇在非洲有孕，就辞职回国，因为媳妇第一个和第二个孩子都掉了，出现了心理问题，然后就一年没咋找工作，后来父亲给我找了个深圳小公司的工作，做水务市场总监，也做了一年就辞了，现在已经失业两年多了，也没找工作，辞职情况没有敢跟家里说。 经济状况 本人父母在合肥有两套房，一套自住一套出租，深圳一套房，还有340万商业贷款，60万公积金贷款，每月商业贷款在1万8, 本人还有47万存款，老婆有60万存款，老婆父母在岳阳开缝纫店的，每个月有6000元收入，老婆在深圳做护士，每个月2万的收入。我和妻子目前有个女孩。 本人性格 谨慎型，在工作压力大的时候不愿意主动沟通，职业经历上来看，国外市场比较适应，国内市场做的不好，性格上比较急躁，学习东西较慢，对于编程有兴趣但是不够深入。 未来建议: 考虑调整工作环境以适应自身性格，可能更适合国际市场领域。 寻求心理健康支持，处理家庭经历的心理问题。 在职业规划中寻找平衡点，结合兴趣和能力，可能重新考虑技术领域的发展。 找工作 先从市场工作入手去找，海外的也可以考虑 程序员方面深入以后能够接一些私单了再考虑职业规划 gap year的解释，真诚是最美的，要跟别人先沟通起来 心理健康是最重要的，实在不行只能跟家里人坦白，离婚我也能接受，毕竟我撒谎了 要立刻去沟通了，行动起来 程序员接私活 创建个人项目集： 在GitHub或其他代码托管平台上展示你的项目和代码，这是潜在客户了解你技术水平的好方式。 参与社区：加入相关领域的社区，参与讨论，结识其他开发者和潜在雇主。 制定清晰的服务提供方案：确定你能够提供的服务，包括技术栈、项目类型、开发周期等。 利用在线平台：使用一些专门的平台，如Freelancer、Upwork等，可以找到各种各样的项目。 建立专业形象： 有一个专业的LinkedIn和个人网站，展示你的技能和项目。 炒金融产品 炒金融产品是指通过金融市场进行交易，赚取价格波动差价的行为。这可能涉及股票、外汇、期货、期权等不同类型的金融工具。在炒金融产品时，有一些重要的事项需要考虑： 知识储备： 在开始炒金融产品之前，建议充分了解所选择市场和金融工具的基本原理、交易机制和风险因素。深入理解市场和产品的特性将有助于更好地做出决策。 风险管理： 金融市场涉及高风险，价格波动可能对投资造成损失。制定明确的风险管理策略，包括设定止损点、分散投资、了解杠杆效应等，以保护资金免受大幅度波动的影响。 市场研究： 进行充分的市场研究，包括技术分析和基本面分析，以便更好地预测市场走势。了解市场消息和事件对价格的潜在影响也是重要的。 交易计划： 制定清晰的交易计划，包括进场点、出场点、目标收益等。不要轻率地进行交易，而应该基于策略和计划做出决策。 心理素质： 炒金融产品可能涉及到市场的情绪波动，保持冷静、理性是非常重要的。情绪化的决策往往容易导致损失。 投资目标和期限： 确定你的投资目标和期限，是长期投资还是短期波动性交易。不同的目标可能需要不同的投资策略。 短视频 创业短视频需要综合考虑内容创作、社交传播和商业运营等多个方面。以下是一些步骤和建议： 市场调研： 了解当前短视频行业的趋势和市场竞争状况。确定你的目标受众，探索他们的需求和喜好。 定位和创意： 确定你的短视频平台的定位和创意特色。这可以是特定领域的内容、独特的创作风格、或者是满足某种特定需求的内容。 平台选择： 选择适合你创意方向的短视频平台。目前，像抖音、快手、TikTok等平台是短视频创业比较热门的选择。 内容策划： 制定内容策略，包括频率、主题、风格等。确保你的内容能够引起观众的兴趣，建立粉丝基础。 创作团队： 如果可能，建立一个稳定的创作团队。团队成员可以负责不同的方面，包括拍摄、剪辑、策划等。 优化用户体验： 关注观众的用户体验。确保视频画面清晰、音质良好，同时考虑字幕、特效等元素的合理运用。 社交互动： 建立社交媒体账号，积极互动观众。回应评论、参与话题讨论，增加用户粘性。 合作和推广： 考虑与其他创作者、品牌或平台进行合作。这有助于扩大你的影响力和用户基础。 商业变现： 探索不同的商业变现方式，如品牌合作、广告投放、付费订阅等。建立多元化的变现渠道，降低经营风险。 法律合规： 注意遵守相关法规，尤其是涉及到版权、隐私等方面的法律规定。确保你的创业活动在法律框架内进行。 数据分析： 使用数据分析工具，了解观众行为、内容表现等数据。通过分析数据调整策略，提高内容质量和用户黏性。 持续学习： 短视频领域变化迅速，持续学习新的趋势、技术和市场动态，保持创新。 创业短视频需要不断尝试和调整，同时耐心积累观众基础。成功的关键在于创新、精细化运营和积极的用户互动。 利用人工智能做一些变现 利用人工智能（AI）进行变现可以涉及多个领域，包括产品开发、服务提供、内容创作等。以下是一些常见的AI变现策略： AI产品和服务： 开发AI应用： 利用AI技术开发有市场需求的应用，如语音助手、智能家居系统、自动化工具等。 提供AI服务： 提供定制的AI解决方案，包括机器学习模型开发、自然语言处理服务、图像识别等。 内容生成和创作： 自动化内容生成： 利用AI算法生成高质量的文本、图像或音频内容，可以用于博客、社交媒体或其他平台。 AI创作工具： 开发或提供AI辅助的创作工具，帮助创作者更高效地生成创意内容。 电子商务和推荐系统： 个性化推荐： 利用AI算法实现个性化产品或内容推荐，提高用户体验，同时获取推荐费用。 智能购物助手： 开发AI驱动的购物助手，帮助用户找到最佳价格、产品评价等信息。 金融和投资： 智能投顾： 利用机器学习分析市场趋势，提供个性化的投资建议。 量化交易： 使用AI算法进行量化交易，通过自动化交易策略获得收益。 在线教育和培训： 个性化学习： 利用AI技术为学生提供个性化的学习路径和内容，提高学习效果。 AI教育工具： 开发AI辅助的教育工具，如智能辅导系统、自适应学习平台等。 数据分析和预测： 行业报告和分析： 利用AI对行业趋势、市场数据进行分析，提供行业报告和预测服务。 定制数据分析： 提供基于AI的数据分析服务，帮助企业更好地理解和利用其数据。 游戏和娱乐： 智能游戏开发： 制作利用AI技术创新的游戏，提供独特的娱乐体验。 虚拟现实（VR）和增强现实（AR）： 利用AI增强虚拟或增强现实体验，吸引用户并提供付费服务。 在实施这些策略时，务必注重数据隐私和合规性，并建立良好的用户体验。不同领域的AI变现模式可能需要不同的技术和商业策略，因此在具体执行前，详细研究和规划是至关重要的。","categories":[{"name":"如何赚钱","slug":"如何赚钱","permalink":"https://blackforest1990.github.io/categories/%E5%A6%82%E4%BD%95%E8%B5%9A%E9%92%B1/"}],"tags":[{"name":"导论","slug":"导论","permalink":"https://blackforest1990.github.io/tags/%E5%AF%BC%E8%AE%BA/"}]},{"title":"进程","slug":"进程","date":"2023-11-28T06:01:38.000Z","updated":"2024-01-09T05:17:03.533Z","comments":true,"path":"2023/11/28/进程/","link":"","permalink":"https://blackforest1990.github.io/2023/11/28/%E8%BF%9B%E7%A8%8B/","excerpt":"","text":"进程 在所有操作系统中，一个重要的概念是进程（process）。进程本质上是正在执行的一个程序。进程不止是程序代码，程序代码有时被称为文本段（text section）。进程还包括当前活动，通过程序计数器（program counter）的值和处理器寄存器的内容来表示。另外，进程还包括堆栈段stack（函数参数，返回地址和局部变量）和数据段data section（全局变量）。进程还包括堆（heap），是在进程运行期间动态分配内存。 这里强调:程序本身不是进程:程序是被动实体，如存储在磁盘上包含一系列指令的文件内容(常被称为可执行文件) ，而进程是活动实体，它有一个程序计数器用来表示下一个要执行的命令和相关资源集合。当一个可执行文件被装入内存时，一个程序才能成为进程。装载可执行文件通常有两种方法，即双击一个代表此可执行文件的图标或在命令行中输入该文件的文件名(如prog.exe 或 a.out)。 进程状态 ● new: 进程被创建 ● running: 指令正被执行 ● waiting: 该进程正在等待/阻止某些事件的发生 ● ready: 该进程正在等待被分配给一个处理器 ● terminated: 该进程已完成执行 进程控制块 每个进程在操作系统内用进程控制块 (process control block. PCB)来表示。 进程状态:状态可包括new/running/waiting/ready/terminated。 程序计数器:计数器表示进程要执行的下个指令的地址。 CPU 寄存器:根据计算机体系结构的不同，寄存器的数量和类型也不同。它们包括累加器、索引寄存器、堆栈指针、通用寄存器和其他条件码信息寄存器。与程序计数器一起，这些状态信息在出现中断时也需要保存，以便进程以后能正确地继续执行。 CPU 调度信息:这类信息包括进程优先级、调度队列的指针和其他调度参数 内存管理信息:根据操作系统所使用的内存系统，这类信息包括基址和界限寄存器的值、页表或段表。 记账信息:这类信息包括 CPU 时间、实际使用时间、时间界限、记账数据、作业或进程数量等。 I/O 状态信息:这类信息包括分配给进程的 I/O 设备列表、打开的文件列表等。 Linux中的进程表示 Linux 操作系统中的进程控制块是通过 &lt;linux/sched.h&gt; 中的 task_struct 来表示的。这个结构包含了表示一个进程所需要的所有信息，包括进程的状态、调度和内存管理信息、打开文件列表和指向父进程和所有子进程的指针(创建进程的进程是父进程，被进程创建的进程为子进程) 123456long state; /* state of the process */struct sched_entity se; /* scheduling information */struct task_struct *parent; /* this process’s parent */struct list_head children; /* this process’s children */struct files_struct *files; /* list of open files */struct mm_struct *mm; /* address space of this process */ 例如，进程的状态是通过这个结构中的long state 字段来表示的。在Linux 内核里，所有活动的进程是通过一个名为task_struct 的双向链表来表示的，内核为当前正在运行的进程保存了一个指针(current)。 解释一下内核如何操作一个指定进程的 task_struct 字段。假定操作系统想把当前运行进程的状态值修改成 new state。如果 current是指向当前进程的指针，那么要改变状态可以如下进行: 1current-&gt;state = new state; 进程调度 多道程序设计的目的是无论何时都有进程在运行，从而使 CPU 利用率达到最大化。分时系统在进程之间快速切换 CPU 以便用户在程序运行时能与其进行交互。为了达到此目的，进程调度选择一个可用的进程(可能从多个可用进程集合中选择)到 CPU 上执行。单处理器系统从不会有超过一个进程在运行。如果有多个进程，那么余下的则需要等待 CPU空闲并重新调度。 调度队列 进程进入系统时，会被加入到作业队列(job queue)中,该队列包括系统中所有进程。驻留在内存中就绪的、等待运行的进程保存在就绪队列(ready queue)中, 该队列通常用链表实现，其头结点指向链表的第一个和最后一个PCB块的指针。每个PCB包括一个指向就绪队列的下一个PCB的指针域。 操作系统也有其他队列。当给进程分配了CPU 后，它开始执行并最终完成，或被中断，或等待特定事件发生(如完成I/O 请求)。假设进程向一个共享设备(如磁盘)发送I/O 请求，由于系统有许多进程，磁盘可能会忙于其他进程的I/O 请求，因此该进程可能需要等待磁盘。等待特定 I/O 设备的进程列表称为设备队列(device queue)。 新进程开始处于就绪队列。它在就绪队列中等待直到被选中执行或被派遣。当进程分配到 CPU 并执行时，可能发生下面事件中的一种: 进程可能发出一个 I/O 请求，并被放到 I/O 队列中。 进程可能创建一个新的子进程，并等待其结束。 进程可能会由于中断而强制释放 CPU ，并被放回到就绪队列中。 对于前两种情况，进程最终从等待状态切换到就绪态，并放回到就绪队列中。进程继续这一循环直到终止，到时它将从所有队列中删除，其PCB 和资源将得以释放。 调度程序 进程选择是由相应的调度程序(scheduler) 来执行的。通常对于批处理系统，进程更多地是被提交，而不是马上执行。这些进程被放到大容量存储设备(通常为磁盘)的缓冲池中，保存在那里以便以后执行。长期调度程序(long-term scheduler) 或作业调度程序 (job scheduler) 从该池中选择进程，并装入内存准备执行(秒/分钟级别调度)。短期调度程序 (short-term scheduler) 或 CPU 调度程序从准备执行的进程中选择进程(毫秒级别调度)，并为之分配 CPU 。达到最好性能，长期调度程序应该选择一个合理的包含I/O 为主的和 CPU 为主的组合进程。 对于有些系统，可能没有长期调度程序。例如，UNIX 或Windows 的分时系统通常没有长期调度程序，只是简单地将所有新进程放在内存中以供短期调度程序使用。这些系统的稳定性依赖于物理限制(如可用的终端数)或用户的自我调整。如果多用户系统性能下降到令人难以接受，那么将有用户退出。 有的操作系统如分时系统，可能引入另外的中期调度程序( medium-term scheduler) 。中期调度程序的核心思想是能将进程从内存(或从 CPU 竞争)中移出，从而降低多道程序设计的程度。之后，进程能被重新调入内存，并从中断处继续执行。这种方案称为交换 (swapping) 。通过中期调度程序，进程可换出，并在后来可被换入。为了改善进程组合，或者因内存要求的改变引起了可用内存的过度使用而需要释放内存，就有必要使用交换。 上下文切换 将 CPU 切换到另一个进程需要保存当前进程的状态并恢复另一个进程的状态，这一任务称为上下文切换 (context switch) 。当发生上下文切换时，内核会将旧进程的状态保存在其 PCB 中，然后装入经调度要执行的并己保存的新进程的上下文。上下文切换时间是额外开销，因为切换时系统并不能做什么工作。上下文切换速度因机器而不同，它依赖于内存速度、必须复制的寄存器的数量、是否有特殊指令(如装入或保存所有寄存器的单个指令)，一般需几毫秒。 上下文切换时间与硬件支持密切相关。例如，有的处理器(如 Sun UltraSPARC) 提供了多组寄存器集合，上下文切换只需要简单地改变当前寄存器组的指针。当然，如果活动进程数超过了寄存器集合数量，那么系统需要像以前一样在寄存器与内存之间进行数据复制。而且，操作系统越复杂，上下文切换所要做的工作就越多。 进程操作 绝大多数系统内的进程能并发执行，它们可以动态创建和删除，因此操作系统必须提供某种机制(或工具)以创建和终止进程。 进程创建 在UNIX中，每个进程都由其进程标识符（PID）唯一标识。通过fork()系统调用创建一个新进程。新进程由原始进程的地址空间的副本组成。这种机制允许父进程与其子进程轻松通信。两个进程都在fork()之后的指令继续执行，唯一的区别是fork()的返回码对于新（子）进程是零，而子进程的（非零）进程标识符被返回给父进程。 在fork()系统调用之后，通常有两个进程中的一个使用exec()系统调用来用一个新程序替换进程的内存空间。exec()系统调用将一个二进制文件加载到内存中（销毁包含exec()系统调用的程序的内存映像）并开始执行。通过这种方式，两个进程能够通信然后各自进行。父进程然后可以创建更多的子进程；或者，如果它在子进程运行时没有其他事情可做，它可以发出wait()系统调用，将自己移出就绪队列直到子进程终止。由于对exec()的调用用新程序覆盖进程的地址空间，所以exec()的调用除非发生错误否则不会返回控制。 下面显示的C程序演示了先前描述的UNIX系统调用。现在我们有两个运行相同程序的不同进程。唯一的区别是子进程的pid（进程标识符）的值为零，而父进程的值为大于零的整数（实际上，它是子进程的实际pid）。子进程从父进程继承特权和调度属性，以及某些资源，如打开的文件。然后，子进程使用execlp()系统调用（execlp()是exec()系统调用的一种版本）命令/bin/ls覆盖其地址空间。父进程等待子进程完成，使用wait()系统调用。当子进程完成（通过隐式或显式调用exit()）时，父进程从wait()调用处恢复，然后使用exit()系统调用完成。 12345678910111213141516171819202122#include &lt;sys/types.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;int main()&#123; pid t pid; /* fork a child process */ pid = fork(); if (pid &lt; 0) &#123; /* error occurred */ fprintf(stderr, &quot;Fork Failed&quot;); return 1; &#125; else if (pid == 0) &#123; /* child process */ execlp(&quot;/bin/ls&quot;,&quot;ls&quot;,NULL); &#125; else &#123; /* parent process */ /* parent will wait for the child to complete */ wait(NULL); printf(&quot;Child Complete&quot;); &#125; return 0;&#125; 某些系统中(UNIX)，当进程创建了另一个进程后，父进程和子进程就以某种形式继续保持关联。子进程自身可以创建更多的进程，组成一个进程的树形结构。进程和它的所有子女以及后裔共同组成一个进程组。当用户从键盘发出一个信号时，该信号被送给当前与键盘相关的进程组中的所有成员（它们通常是在当前窗口创建的所有活动进程）。每个进程可以分别捕获该信号、忽略该信号或采取默认的动作，即被该信号杀死。 下图展示了Linux操作系统的典型进程树，显示了每个进程及其PID（进程标识符）的名称。在这里我们使用术语“进程”比较宽泛，因为Linux更倾向于使用task。init进程（始终具有PID 1）充当所有用户进程的根父进程。一旦系统启动，init进程还可以创建各种用户进程，如Web服务器、打印服务器、SSH服务器等。我们看到init的两个子进程是kthreadd和sshd。kthreadd进程负责创建代表内核执行任务的其他进程（在这种情况下是khelper和pdflush）。sshd进程负责管理通过SSH（安全外壳）连接到系统的客户端。登录进程负责管理直接登录到系统的客户端。在这个示例中，一个客户端已经登录并正在使用bash shell，其分配的PID为8416。使用bash命令行接口，该用户创建了进程ps和emacs编辑器。 进程的终止 一个进程在执行完最后一条语句并通过使用 exit() 系统调用请求操作系统删除它时终止。在这一刻，进程可以通过 wait() 系统调用向其父进程返回一个状态值（通常是一个整数）。进程的所有资源，包括物理和虚拟内存、打开的文件以及I/O缓冲区，都会被操作系统释放。 终止也可能发生在其他情况下。一个进程可以通过适当的系统调用（例如在Windows中的TerminateProcess()）引发另一个进程的终止。通常，这样的系统调用只能由要终止的进程的父进程调用。否则，用户可以任意终止彼此的任务。请注意，如果父进程要终止子进程，父进程需要知道子进程的标识。因此，当一个进程创建一个新的进程时，新创建的进程的标识会传递给父进程。 父进程可能出于多种原因终止其子进程的执行： 子进程已经超出了其被分配的一些资源的使用限制。（要确定是否发生了这种情况，父进程必须有一种机制来检查其子进程的状态。） 分配给子进程的任务不再需要执行。 父进程正在退出，而如果其父进程终止，操作系统不允许子进程继续执行。 在一些系统中，如果一个进程的父进程终止，那么该进程就不能存在。在这种系统中，如果一个进程终止（无论是正常还是异常终止），那么它的所有子进程也必须被终止。这种现象被称为级联终止，通常由操作系统启动。 为了说明进程的执行和终止，在Linux和UNIX系统中，我们可以使用 exit() 系统调用来终止一个进程，并提供一个退出状态作为参数： 12/* exit with status 1 */exit(1); 实际上，在正常终止情况下，exit() 可以直接调用（如上所示）或间接调用（通过 main() 函数中的返回语句）。 父进程可以通过使用 wait() 系统调用等待子进程的终止。wait() 系统调用接受一个参数，允许父进程获取子进程的退出状态。此系统调用还返回终止的子进程的进程标识符，以便父进程可以知道其哪个子进程已经终止。 123pid t pid;int status;pid = wait(&amp;status); 当一个进程终止时，其资源由操作系统释放。然而，它在进程表中的条目必须一直保留，直到父进程调用 wait()，因为进程表包含了进程的退出状态。一个已经终止但其父进程尚未调用 wait() 的进程被称为僵尸进程。所有进程在终止时都会过渡到这个状态，但通常它们只会短暂存在。一旦父进程调用了 wait()，僵尸进程的进程标识符和其在进程表中的条目就会被释放。 现在考虑一下，如果父进程没有调用 wait() 而是终止了，从而使其子进程成为孤儿进程，会发生什么情况。Linux 和 UNIX 通过将 init 进程指定为孤儿进程的新父进程来解决这种情况。init 进程定期调用 wait()，从而允许收集任何孤儿进程的退出状态，并释放孤儿进程的进程标识符和进程表条目。 进程间通信 提供允许进程合作的环境有几个原因： 信息共享。由于可能有多个用户对同一信息感兴趣（例如共享文件），我们必须提供一种环境，允许对这样的信息进行并发访问。 计算加速。如果我们希望某个任务运行得更快，我们必须将其分解为子任务，每个子任务将与其他子任务并行执行。请注意，只有计算机具有多个处理核心时，才能实现这样的加速。 模块化。我们可能希望以模块化的方式构建系统，将系统功能划分为独立的进程或线程。 方便。即使是单个用户也可能同时处理许多任务。例如，用户可能同时进行编辑、听音乐和编译。 合作进程需要一种进程间通信（IPC）机制，使它们能够交换数据和信息。有两种基本的进程间通信模型：共享内存和消息传递。在共享内存模型中，建立了由合作进程共享的内存区域。进程可以通过读写数据到共享区域来交换信息。在消息传递模型中，通信通过合作进程之间交换的消息进行。 这两种模型在操作系统中都很常见，许多系统都同时实现了它们。消息传递对于交换较小量的数据很有用，因为不需要避免冲突。在分布式系统中，消息传递也比共享内存更容易实现。共享内存可能比消息传递更快，因为消息传递系统通常是通过系统调用实现的，因此需要更耗时的内核干预。在共享内存系统中，只有在建立共享内存区域时才需要系统调用。一旦共享内存建立，所有访问都被视为常规内存访问，不需要内核的帮助。 最近对具有多个处理核心的系统进行的研究表明，在这些系统上，消息传递提供了比共享内存更好的性能。共享内存存在缓存一致性问题，因为共享数据在多个缓存之间迁移。随着系统上处理核心数量的增加，我们可能会看到消息传递作为IPC的首选机制。 多进程架构 — Chrome 浏览器 许多网站包含诸如 JavaScript、Flash 和 HTML5 等主动内容，以提供丰富而动态的网页浏览体验。不幸的是，这些 Web 应用程序也可能包含软件缺陷，这可能导致响应时间变慢，甚至导致 Web 浏览器崩溃。在仅显示来自一个网站的内容的 Web 浏览器中，这并不是一个大问题。但是，大多数现代 Web 浏览器提供标签式浏览，允许单个 Web 浏览器应用程序同时打开多个网站，每个站点在单独的标签中。用户只需点击相应的标签即可在不同的站点之间切换。这种排列如下图所示： 这种方法的一个问题是，如果任何一个标签中的 Web 应用程序崩溃，整个进程，包括显示其他网站的所有其他标签，也会崩溃。谷歌的 Chrome Web 浏览器通过采用多进程架构来解决这个问题。Chrome 将进程分为三种类型：浏览器、渲染器和插件。 浏览器进程 负责管理用户界面以及磁盘和网络 I/O。在启动 Chrome 时会创建一个新的浏览器进程。只会创建一个浏览器进程。 渲染器进程 包含用于呈现网页的逻辑。因此，它们包含处理 HTML、JavaScript、图像等的逻辑。通常情况下，每个在新标签中打开的网站都会创建一个新的渲染器进程，因此可以同时存在多个渲染器进程。 插件进程 为每种正在使用的插件（如 Flash 或 QuickTime）创建一个进程。插件进程包含插件的代码以及额外的代码，使插件能够与相关的渲染器进程和浏览器进程进行通信。 多进程方法的优势在于各个网站之间运行时是隔离的。如果一个网站崩溃，只有它的渲染器进程受到影响，所有其他进程都不受影响。此外，渲染器进程在沙箱中运行，这意味着对磁盘和网络 I/O 的访问受到限制，从而最小化了任何安全漏洞的影响。 共享内存系统 使用共享内存进行进程间通信需要通信的进程建立一个共享内存区域。通常，共享内存区域存在于创建该共享内存段的进程的地址空间中。希望使用这个共享内存段进行通信的其他进程必须将其连接到它们的地址空间。通常情况下，操作系统会阻止一个进程访问另一个进程的内存。共享内存要求两个或多个进程同意解除这个限制。然后，它们可以通过在共享区域中读写数据来交换信息。数据的形式和位置由这些进程决定，并不受操作系统的控制。这些进程还负责确保它们不会同时写入相同的位置。 为了阐述合作进程的概念，让我们考虑一下生产者-消费者问题，这是一种常见的合作进程范例。生产者进程生成由消费者进程消耗的信息。例如，编译器可能生成汇编代码，由汇编器消耗。然后，汇编器可能生成目标模块，由加载器消耗。生产者-消费者问题还为客户端-服务器范式提供了一个有用的隐喻。通常我们将服务器视为生产者，客户端视为消费者。例如，Web 服务器生成（即提供）HTML 文件和图像，而客户端 Web 浏览器请求这些资源并消耗（即读取）它们。 生产者-消费者问题的一个解决方案使用了共享内存。为了允许生产者和消费者进程同时运行，我们必须有一个可以由生产者填充并由消费者清空的项目缓冲区。这个缓冲区将位于由生产者和消费者进程共享的内存区域。生产者可以在消费者正在消耗另一项时生成一项。生产者和消费者必须同步，以确保消费者不会尝试消耗尚未生成的项目。 可以使用两种类型的缓冲区。无界缓冲区对缓冲区的大小没有实际限制。消费者可能必须等待新项目，但生产者始终可以生成新项目。有界缓冲区假定一个固定的缓冲区大小。在这种情况下，如果缓冲区为空，消费者必须等待；如果缓冲区已满，生产者必须等待。 让我们更仔细地看一下有界缓冲区是如何通过共享内存进行进程间通信的。以下变量存在于生产者和消费者进程共享的内存区域中： 1234567#define BUFFER SIZE 10typedef struct &#123;. . .&#125;item;item buffer[BUFFER SIZE];int in = 0;int out = 0; 共享缓冲区被实现为一个带有两个逻辑指针（in和out）的循环数组：in指向缓冲区中的下一个空位置；out指向缓冲区中的第一个满位置。当in == out时，缓冲区为空；当((in + 1) % BUFFER SIZE) == out时，缓冲区为满。生产者进程有一个本地变量nextProduced，用于存储要生成的新项。消费者进程有一个本地变量nextConsumed，用于存储要消耗的项。 1234567891011121314151617item next_produced;while (true) &#123; /* produce an item in next produced */ while (((in + 1) % BUFFER SIZE) == out) ; /* do nothing */ buffer[in] = next_produced; in = (in + 1) % BUFFER SIZE;&#125;item next consumed;while (true) &#123; while (in == out) ; /* do nothing */ next_consumed = buffer[out]; out = (out + 1) % BUFFER SIZE; /* consume the item in next consumed */&#125; 这种方案允许在同一时间最多有BUFFER SIZE − 1个项目在缓冲区中。这个例子未解决的问题是生产者进程和消费者进程同时尝试访问共享缓冲区的情况。 An Example: POSIX Shared Memory 在POSIX系统中有多种IPC机制，包括共享内存和消息传递。在这里，我们探讨一下用于共享内存的POSIX API。POSIX共享内存使用内存映射文件进行组织，将共享内存区域与文件关联起来。一个进程首先必须使用shm_open()系统调用创建一个共享内存对象，如下所示： 1shm_fd = shm_open(name, O_CREAT | O_RDWR, 0666); 第一个参数指定了共享内存对象的名称。希望访问这个共享内存的进程必须使用这个名称引用对象。后续的参数指定了如果对象不存在就创建它（O_CREAT），并且对象是可读写的（O_RDWR）。最后一个参数设置了共享内存对象的目录权限。对shm_open()的成功调用会返回一个整数文件描述符，用于表示共享内存对象。一旦对象建立，ftruncate()函数被用于配置对象的大小，单位是字节。调用ftruncate(shm_fd, 4096)将对象的大小设置为4096字节。最后，mmap()函数建立了一个包含共享内存对象的内存映射文件，并返回一个指向用于访问共享内存对象的内存映射文件的指针。 生产者创建了一个名为&quot;OS&quot;的共享内存对象，并向共享内存写入了&quot;Hello World!&quot;这个著名的字符串。该程序内存映射了一个指定大小的共享内存对象，并允许对该对象进行写入（显然，对于生产者来说只有写入是必要的）。标志MAP_SHARED指定对共享内存对象的更改将对所有共享该对象的进程可见。注意，我们通过调用sprintf()函数并将格式化的字符串写入指针ptr来写入共享内存对象。在每次写入之后，我们必须将指针按照写入的字节数递增。 1234567891011121314151617181920212223242526272829303132#include &lt;stdio.h&gt;#include &lt;stlib.h&gt;#include &lt;string.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/shm.h&gt;#include &lt;sys/stat.h&gt;int main()&#123; /* the size (in bytes) of shared memory object */ const int SIZE 4096; /* name of the shared memory object */ const char *name = &quot;OS&quot;; /* strings written to shared memory */ const char *message 0 = &quot;Hello&quot;; const char *message 1 = &quot;World!&quot;; /* shared memory file descriptor */ int shm_fd; /* pointer to shared memory obect */ void *ptr; /* create the shared memory object */ shm_fd = shm_open(name, O_CREAT | O_RDRW, 0666); /* configure the size of the shared memory object */ ftruncate(shm_fd, SIZE); /* memory map the shared memory object */ ptr = mmap(0, SIZE, PROT_WRITE, MAP_SHARED, shm_fd, 0); /* write to the shared memory object */ sprintf(ptr,&quot;%s&quot;,message 0); ptr += strlen(message 0); sprintf(ptr,&quot;%s&quot;,message 1); ptr += strlen(message 1); return 0;&#125; 消费者进程读取并输出共享内存的内容。消费者还调用shm_unlink()函数，在消费者访问完共享内存后删除共享内存段。 12345678910111213141516171819202122232425#include &lt;stdio.h&gt;#include &lt;stlib.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/shm.h&gt;#include &lt;sys/stat.h&gt;int main()&#123; /* the size (in bytes) of shared memory object */ const int SIZE 4096; /* name of the shared memory object */ const char *name = &quot;OS&quot;; /* shared memory file descriptor */ int shm_fd; /* pointer to shared memory obect */ void *ptr; /* open the shared memory object */ shm_fd = shm_open(name, O_RDONLY, 0666); /* memory map the shared memory object */ ptr = mmap(0, SIZE, PROT_READ, MAP_SHARED, shm_fd, 0); /* read from the shared memory object */ printf(&quot;%s&quot;,(char *)ptr); /* remove the shared memory object */ shm_unlink(name); return 0;&#125; 消息传递系统 消息传递提供了一种机制，允许进程在不共享相同地址空间的情况下进行通信和同步它们的操作。在分布式环境中特别有用，其中通信的进程可能驻留在由网络连接的不同计算机上。例如，一个互联网聊天程序可以设计成参与聊天的用户通过交换消息进行通信。 消息传递设施至少提供两个操作： send(message)（发送消息） receive(message)（接收消息） 由进程发送的消息可以是固定大小或可变大小的。如果只能发送固定大小的消息，则系统级实现比较直接。然而，这种限制使编程任务变得更加困难。相反，可变大小的消息需要更复杂的系统级实现，但编程任务变得更简单。这是操作系统设计中经常遇到的一种权衡。 如果进程P和Q想要通信，它们必须相互发送消息并接收消息：它们之间必须存在一种通信链路。这个链接可以以多种方式实现。我们关心的不是链接的物理实现（例如共享内存、硬件总线或网络），而是它的逻辑实现。以下是逻辑实现链接和send()/receive()操作的几种方法： 直接或间接通信 同步或异步通信 自动或显式缓冲 命名 进程之间要进行通信，它们必须有一种方式来引用彼此。可以使用直接通信或间接通信。 在直接通信中，每个想要通信的进程必须明确命名通信的接收方或发送方。原语被定义如下： send(P, message) — 向进程 P 发送消息。 receive(Q, message) — 从进程 Q 接收消息。 在这个方案中，通信链具有以下属性： 每对想要通信的进程之间会自动建立一个连接。进程只需知道对方的身份就可以进行通信。 一个链接与两个进程关联。 每对进程之间存在且仅存在一个链接。 这个方案在寻址上表现出对称性，即发送方和接收方都必须命名对方才能进行通信。这个方案的变体采用非对称的寻址方式。在这种情况下，只有发送方命名接收方，而不要求接收方命名发送方。原语被定义如下： send(P, message) — 向进程 P 发送消息。 receive(id, message) — 从任何进程接收消息。变量 id 被设置为发生通信的进程的名称。 这两种方案（对称和非对称）的缺点是由于生成的进程定义的模块性有限。更改进程标识符可能需要检查所有其他进程定义。必须找到对旧标识符的所有引用，以便可以将它们修改为新标识符。总的来说，任何这种硬编码技术，在其中标识符必须明确说明的地方，都不如涉及间接寻址的技术更为可取。 在间接通信中，消息被发送到和从邮箱或端口中接收。**邮箱可以抽象地看作是一个对象，进程可以将消息放入其中，也可以从中移除消息。每个邮箱都有一个唯一的标识。**例如，POSIX 消息队列使用整数值来标识邮箱。一个进程可以通过许多不同的邮箱与另一个进程通信，但只有在它们有一个共享的邮箱时，两个进程才能通信。原语被定义如下： send(A, message) — 向邮箱 A 发送消息。 receive(A, message) — 从邮箱 A 接收消息。 在这个方案中，通信链具有以下属性： 仅当一对进程都有一个共享的邮箱时，才会在它们之间建立连接。 一个链接可以与多于两个进程关联。 对于每一对通信的进程，可能存在多个不同的链接，每个链接对应一个邮箱。 **邮箱可以由进程或操作系统拥有。**如果邮箱由进程拥有（即邮箱是进程的地址空间的一部分），那么我们区分所有者（只能通过这个邮箱接收消息）和用户（只能向邮箱发送消息）。由于每个邮箱都有一个唯一的所有者，所以不会混淆应该接收发送到该邮箱的消息的进程。当拥有邮箱的进程终止时，邮箱消失。随后任何尝试向这个邮箱发送消息的进程都必须得到通知，告诉它该邮箱已经不存在。 相反，由操作系统拥有的邮箱是独立的，不附属于任何特定的进程。操作系统必须提供一种机制，允许进程执行以下操作： 创建一个新的邮箱。 通过邮箱发送和接收消息。 删除一个邮箱。 创建新邮箱的进程默认是那个邮箱的所有者。最初，只有所有者可以通过该邮箱接收消息。但是，通过适当的系统调用，所有权和接收权限可以传递给其他进程。当然，这种规定可能导致每个邮箱有多个接收者。 同步 进程之间的通信通过对send()和receive()原语的调用来实现。实现每个原语的方式有不同的设计选项。消息传递可以是阻塞的或非阻塞的，也称为同步和异步。 阻塞发送。发送进程被阻塞，直到消息被接收进程或邮箱接收。 非阻塞发送。发送进程发送消息并继续操作。 阻塞接收。接收者被阻塞，直到有消息可用。 非阻塞接收。接收者检索到一个有效的消息或一个空消息。 send()和receive()的不同组合是可能的。当send()和receive()都是阻塞的时候，我们有了发送者和接收者之间的汇合。当我们使用阻塞的send()和receive()语句时，生产者-消费者问题的解决方案变得非常简单。生产者只需调用阻塞的send()调用，等待消息被传递给接收者或邮箱。同样，当消费者调用receive()时，它会阻塞，直到有消息可用。 1234567891011message next_produced;while (true) &#123; /* produce an item in next_produced */ send(next_produced);&#125;message next_consumed;while (true) &#123; receive(next_consumed); /* consume the item in next_consumed */&#125; 缓冲 无论通信是直接还是间接的，由通信进程交换的消息都存在于一个临时队列中。基本上，这样的队列可以通过三种方式实现： 零容量（Zero capacity）：队列的最大长度为零；因此，链接不能有任何等待的消息。在这种情况下，发送方必须阻塞，直到接收方接收到消息。 有界容量（Bounded capacity）：队列的长度有限，为n；最多可以容纳n条消息。如果在发送新消息时队列没有满，消息将被放入队列中（可以是消息的副本或消息的指针），发送方可以继续执行而无需等待。然而，链接的容量是有限的。如果链接已满，发送方必须阻塞，直到队列中有空间。 无界容量（Unbounded capacity）：队列的长度是潜在无限的；因此，任意数量的消息都可以在其中等待。发送方永远不会阻塞。 零容量的情况有时被称为没有缓冲的消息系统。其他情况被称为具有自动缓冲的系统。 客户端-服务器系统中的通信 在本节中，我们将探讨客户端-服务器系统中通信的另外三种策略：套接字（sockets）、远程过程调用（RPCs）和管道（pipes）。 Sockets 套接字被定义为通信的端点。在网络上通信的一对进程使用一对套接字，每个进程一个。套接字由IP地址和端口号拼接而成。一般来说，套接字采用客户端-服务器体系结构。服务器通过监听指定端口等待传入的客户端请求。一旦接收到请求，服务器接受来自客户端套接字的连接以完成连接。实现特定服务的服务器（例如telnet、FTP和HTTP）监听知名端口（telnet服务器监听端口23；FTP服务器监听端口21；Web或HTTP服务器监听端口80）。所有小于1024的端口都被视为知名端口；我们可以使用它们来实现标准服务。 当客户端进程发起连接请求时，它会被分配一个由其主机计算机指定的端口。此端口具有大于1024的某个任意数字。例如，如果主机X上的具有IP地址146.86.5.20的客户端希望与在地址161.25.19.8上监听端口80的Web服务器建立连接，主机X可能会被分配端口1625。连接将由一对套接字组成：主机X上的(146.86.5.20:1625)和Web服务器上的(161.25.19.8:80)。在主机之间传输的数据包将根据目标端口号传递到适当的进程。 所有连接必须是唯一的。因此，如果主机X上的另一个进程也希望与相同的Web服务器建立另一个连接，它将被分配一个大于1024且不等于1625的端口号。这确保所有连接都由唯一的套接字对组成。 Java提供了三种不同类型的套接字。基于连接的（TCP）套接字使用Socket类实现。无连接的（UDP）套接字使用DatagramSocket类。最后，MulticastSocket类是DatagramSocket类的子类。多播套接字允许将数据发送给多个接收者。 我们的示例描述了一个使用基于连接的TCP套接字的日期服务器。该操作允许客户端从服务器请求当前日期和时间。服务器监听端口6013，尽管端口可以是大于1024的任意任意数字。当接收到连接时，服务器将日期和时间返回给客户端。服务器创建一个指定将监听端口6013的ServerSocket。然后，服务器开始使用accept()方法监听该端口。服务器在accept()方法上阻塞，等待客户端请求连接。当接收到连接请求时，accept()返回一个套接字，服务器可以用来与客户端通信。 123456789101112131415161718192021222324import java.net.*;import java.io.*;public class DateServer&#123; public static void main(String[] args) &#123; try &#123; ServerSocket sock = new ServerSocket(6013); /* now listen for connections */ while (true) &#123; Socket client = sock.accept(); PrintWriter pout = new PrintWriter(client.getOutputStream(), true); /* write the Date to the socket */ pout.println(new java.util.Date().toString()); /* close the socket and resume */ /* listening for connections */ client.close(); &#125; &#125; catch (IOException ioe) &#123; System.err.println(ioe); &#125; &#125;&#125; 服务器与套接字通信的详细步骤如下。服务器首先创建一个PrintWriter对象，用于与客户端通信。PrintWriter对象允许服务器使用print()和println()方法向套接字写入输出。服务器进程通过调用println()方法向客户端发送日期。一旦将日期写入套接字，服务器关闭与客户端的套接字，并继续等待更多请求。 客户端通过创建一个套接字并连接到服务器正在监听的端口来与服务器通信。客户端创建一个Socket，并请求与IP地址为127.0.0.1、端口为6013的服务器建立连接。一旦建立连接，客户端可以使用正常的流I/O语句从套接字读取数据。在从服务器接收到日期后，客户端关闭套接字并退出。IP地址127.0.0.1是一个特殊的IP地址，被称为回环地址。当计算机引用IP地址127.0.0.1时，它指的是自己。这种机制允许同一主机上的客户端和服务器使用TCP/IP协议进行通信。IP地址127.0.0.1可以替换为运行日期服务器的另一台主机的IP地址。除了IP地址外，还可以使用实际主机名。 1234567891011121314151617181920212223import java.net.*;import java.io.*;public class DateClient&#123; public static void main(String[] args) &#123; try &#123; /* make connection to server socket */ Socket sock = new Socket(&quot;127.0.0.1&quot;,6013); InputStream in = sock.getInputStream(); BufferedReader bin = new BufferedReader(new InputStreamReader(in)); /* read the date from the socket */ String line; while ( (line = bin.readLine()) != null) System.out.println(line); /* close the socket connection*/ sock.close(); &#125; catch (IOException ioe) &#123; System.err.println(ioe); &#125; &#125;&#125; 使用套接字进行通信，尽管普遍而高效，被认为是在分布式进程之间进行低级通信的一种形式。其中一个原因是套接字仅允许在通信线程之间交换无结构的字节流。客户端或服务器应用程序有责任对数据施加结构。 远程过程调用 远程服务的最常见形式之一是RPC范例，RPC被设计为一种抽象的过程调用机制，用于在具有网络连接的系统之间使用。在许多方面，它类似于IPC机制，并且通常构建在这样的系统之上。然而，在这里，因为我们处理的是进程在不同系统上执行的环境，我们必须使用基于消息的通信方案来提供远程服务。 与IPC消息不同，RPC通信中交换的消息是结构良好的，因此不再只是数据包。每个消息都寻址到监听远程系统上某个端口的RPC守护程序，并且每个消息都包含一个标识符，指定要执行的函数以及传递给该函数的参数。然后按照请求执行函数，并将任何输出发送回请求者，以独立的消息形式。 端口只是包含在消息数据包开头的一个数字。虽然系统通常只有一个网络地址，但它可以在该地址内有多个端口，以区分它支持的许多网络服务。如果远程进程需要一个服务，它会将消息寻址到适当的端口。例如，如果一个系统希望允许其他系统能够列出其当前用户，它将具有支持这样一个RPC的守护程序，附加到一个端口上，比如端口3027。任何远程系统都可以通过向服务器的端口3027发送RPC消息来获取所需的信息（即当前用户列表）。数据将在回复消息中接收到。 RPC的语义允许客户端调用远程主机上的过程，就像在本地调用过程一样。RPC系统通过在客户端侧提供一个存根来隐藏允许通信发生的细节。通常，每个单独的远程过程都有一个单独的存根。当客户端调用远程过程时，RPC系统调用适当的存根，将提供给远程过程的参数传递给它。该存根定位服务器上的端口并对参数进行编组。参数编组涉及将参数封装为可以通过网络传输的形式。然后，存根使用消息传递向服务器发送消息。服务器端的类似存根接收此消息并在服务器上调用该过程。如果需要，返回值将使用相同的技术传递回客户端。在Windows系统上，存根代码是从使用Microsoft Interface Definition Language（MIDL）编写的规范中编译出来的，该语言用于定义客户端和服务器程序之间的接口。 必须处理的一个问题涉及客户端和服务器机器上数据表示的差异。考虑32位整数的表示。一些系统（称为big-endian）首先存储最高有效字节，而其他系统（称为little-endian）首先存储最低有效字节。在计算机体系结构内，两种顺序都没有本质的“更好”之分；相反，选择在计算机体系结构内是任意的。为了解决这样的差异，许多RPC系统定义了数据的机器无关表示。其中一种表示被称为外部数据表示（XDR）。在客户端侧，参数编组涉及在将数据发送到服务器之前将机器相关的数据转换为XDR。在服务器端，XDR数据进行解组，并转换为服务器的机器相关表示。 另一个重要问题涉及调用的语义。而本地过程调用仅在极端情况下失败，RPC可能会因为常见网络错误而失败，或者被重复执行多次。解决这个问题的一种方法是让操作系统确保消息仅被执行一次，而不是至多一次。大多数本地过程调用具有“仅一次”功能，但实现起来更为困难。 首先，考虑“至多一次”。这种语义可以通过将时间戳附加到每个消息上来实现。服务器必须保留其已处理的所有消息的时间戳历史记录，或者历史记录足够大，以确保检测到重复的消息。具有已在历史记录中的时间戳的传入消息将被忽略。然后，客户端可以发送一条或多条消息，并确保它只执行一次。 对于“仅一次”，我们需要消除服务器永远不会接收到请求的风险。为了实现这一点，服务器必须实现上述“至多一次”协议，但还必须向客户端确认已接收和执行了RPC调用。这些ACK消息在整个网络中都很常见。客户端必须定期重新发送每个RPC调用，直到收到该调用的ACK为止。 另一个重要问题涉及服务器和客户端之间的通信。**在标准过程调用中，通常在链接、加载或执行时间发生某种绑定，以便过程调用的名称被过程调用的内存地址替换。**RPC方案要求对客户端和服务器端口进行类似的绑定，但是客户端如何知道服务器上的端口号呢？由于它们不共享内存，因此两个系统都没有关于对方的完整信息。 有两种常见的方法。首先，绑定信息可以是预先确定的，以固定的端口地址的形式存在。在编译时，RPC调用与其关联的固定端口号。一旦程序被编译，服务器就不能更改所请求服务的端口号。其次，可以通过会合机制动态地进行绑定。通常，在固定的RPC端口上提供一个会合守护程序。然后，客户端发送一个包含所需执行的RPC的名称的消息给会合守护程序，请求该RPC的端口地址。返回端口号后，就可以将RPC调用发送到该端口，直到该进程终止（或服务器崩溃）。这种方法需要初始请求的额外开销，但比第一种方法更灵活。 RPC方案在实现分布式文件系统时非常有用。这样的系统可以作为一组RPC守护程序和客户端来实现。消息寻址到服务器上将执行文件操作的分布式文件系统端口。消息包含要执行的磁盘操作。磁盘操作可能是读取、写入、重命名、删除或状态，对应于常见的文件相关系统调用。返回消息包含由客户端的DFS守护程序代表客户端执行的该调用产生的任何数据。例如，一条消息可能包含一个请求将整个文件传输给客户端，也可能仅限于简单的块请求。在后一种情况下，如果要传输整个文件，可能需要多次请求。 管道 管道允许两个进程进行通信。在早期的UNIX系统中，管道是最早的IPC机制之一。它们通常为进程相互通信提供了较为简单的方式，尽管它们也有一些局限性。在实现管道时，需要考虑四个问题： 管道是否允许双向通信，还是通信是单向的？ 如果允许双向通信，它是半双工的（数据只能单向传输）还是全双工的（数据可以同时在两个方向传输）？ 通信进程之间是否必须存在某种关系（如父子关系）？ 管道是否可以在网络上通信，还是通信进程必须位于同一台机器上？ 普通管道 普通管道允许两个进程以标准的生产者-消费者方式进行通信：生产者向管道的一端写入（写端），而消费者从另一端读取（读端）。**因此，普通管道是单向的，只允许单向通信。**如果需要双向通信，必须使用两个管道，每个管道在不同的方向发送数据。接下来，我们将演示如何在UNIX上构建普通管道。在这两个程序示例中，一个进程向管道写入消息“Greetings”，而另一个进程从管道中读取这条消息。 在UNIX系统上，使用函数pipe(int fd[])构建普通管道。这个函数创建一个通过int fd[]文件描述符访问的管道：fd[0]是管道的读端fd[1]是写端。UNIX将管道视为一种特殊类型的文件，因此可以使用普通的read()和write()系统调用访问管道。 普通管道无法从创建它的进程外部访问。通常，父进程创建一个管道，并使用它与通过fork()创建的子进程进行通信。下图说明了文件描述符fd与父进程和子进程之间的关系。 在下面的UNIX程序中，父进程创建了一个管道，然后调用fork()创建子进程。在fork()调用之后发生的事情取决于数据如何通过管道流动。在这个示例中，父进程写入管道，而子进程从管道中读取。重要的是要注意，父进程和子进程最初都关闭了他们未使用的管道端。这是一个重要的步骤，以确保从管道读取的进程能够检测到文件末尾（read()返回0），当写入端关闭其端口时。 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;sys/types.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#define BUFFER_SIZE 25#define READ_END 0#define WRITE_END 1int main(void)&#123; char write msg[BUFFER_SIZE] = &quot;Greetings&quot;; char read msg[BUFFER_SIZE]; int fd[2]; pid_t pid; /* create the pipe */ if (pipe(fd) == -1) &#123; fprintf(stderr,&quot;Pipe failed&quot;); return 1; &#125; /* fork a child process */ pid = fork(); if (pid &lt; 0) &#123; /* error occurred */ fprintf(stderr, &quot;Fork Failed&quot;); return 1; &#125; if (pid &gt; 0) &#123; /* parent process */ /* close the unused end of the pipe */ close(fd[READ_END]); /* write to the pipe */ write(fd[WRITE_END], write msg, strlen(write msg)+1); /* close the write end of the pipe */ close(fd[WRITE_END]); &#125; else &#123; /* child process */ /* close the unused end of the pipe */ close(fd[WRITE_END]); /* read from the pipe */ read(fd[READ_END], read msg, BUFFER SIZE); printf(&quot;read %s&quot;,read msg); /* close the write end of the pipe */ close(fd[READ_END]); &#125; return 0;&#125; 请注意，普通管道在UNIX系统上都要求通信进程之间存在父-子关系。这意味着这些管道只能用于在同一台机器上的进程之间进行通信。 命名管道 普通管道提供了一个简单的机制，允许一对进程进行通信。然而，普通管道只存在于进程在彼此通信时。在UNIX系统上，一旦进程完成通信并终止，普通管道就会停止存在。命名管道提供了一种更强大的通信工具。通信可以是双向的，并且不需要父子关系。一旦建立了命名管道，多个进程可以使用它进行通信。事实上，在典型情况下，一个命名管道可能有多个写入者。此外，命名管道在通信进程完成后仍然存在。 在UNIX系统中，命名管道被称为FIFO（先进先出）。一旦创建，它们会在文件系统中显示为典型的文件。可以使用mkfifo()系统调用创建FIFO，并使用普通的open()、read()、write()和close()系统调用对其进行操作。它将继续存在，直到在文件系统中明确删除为止。虽然FIFO允许双向通信，但通常只允许半双工传输。如果数据必须在两个方向上传输，通常会使用两个FIFO。此外，通信进程必须驻留在同一台机器上。如果需要跨机器通信，则必须使用套接字。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blackforest1990.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"进程管理","slug":"进程管理","permalink":"https://blackforest1990.github.io/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"}]},{"title":"操作系统原理导论","slug":"操作系统原理导论","date":"2023-11-28T03:09:28.000Z","updated":"2023-12-29T06:34:04.164Z","comments":true,"path":"2023/11/28/操作系统原理导论/","link":"","permalink":"https://blackforest1990.github.io/2023/11/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%9F%E7%90%86%E5%AF%BC%E8%AE%BA/","excerpt":"","text":"根据维基百科对于操作系统的总结：操作系统（英语：Operating System，缩写：OS）是一组主管并控制计算机操作、运用和运行硬件、软件资源和提供公共服务来组织用户交互的相互关联的系统软件程序，同时也是计算机系统的内核与基石。 操作系统的历史 第一代（1945~1955）：真空管和穿孔卡带 同一个小组的人设计、建造、编程、操作并维护一台机器。所有的程序设计是用纯粹的机器语言编写的，甚至更糟糕，需要通过将上千根电缆接到插件板上连接成电路，以便控制机器的基本功能。没有程序设计语言（甚至汇编语言也没有），操作系统则从来没有听说过。使用机器的一般方式是，程序员在墙上的机时表上预约一段时间，然后到机房中将他的插件板接到计算机里，在接下来的几小时里，期盼正在运行中的两万多个真空管不会烧坏。那时，所有的计算问题实际都只是简单的数字运算，如制作正弦、余弦以及对数表等。到了20世纪50年代早期有了改进，出现了穿孔卡片，这时就可以将程序写在卡片上，然后读入计算机而不用插件板，但其他过程则依然如旧。 第二代（1955～1965）：晶体管和批处理系统 20世纪50年代晶体管的发明极大地改变了整个状况。计算机已经很可靠，厂商可以成批地生产并销售计算机给用户，用户可以指望计算机长时间运行，完成一些有用的工作。此时，设计人员、生产人员、操作人员、程序人员和维护人员之间第一次有了明确的分工。 这些机器，现在被称作大型机（mainframe），锁在有专用空调的房间中，由专业操作人员运行。只有少数大公司、重要的政府部门或大学才接受数百万美元的标价。要运行一个作业（job，即一个或一组程序），程序员首先将程序写在纸上（用FORTRAN语言或汇编语言），然后穿孔成卡片，再将卡片盒带到输入室，交给操作员，接着就喝咖啡直到输出完成。 由于当时的计算机非常昂贵，人们很自然地要想办法减少机时的浪费。通常采用的解决方法就是批处理系统（batch system）。在输入室收集全部的作业，然后用一台相对便宜的计算机，如IBM 1401计算机，将它们读到磁带上。IBM 1401计算机适用于读卡片、复制磁带和输出打印，但不适用于数值运算。另外用较昂贵的计算机，如IBM 7094来完成真正的计算。 第三代（1965～1980）：集成电路芯片和多道程序设计 IBM 360是一个软件兼容的计算机系列，其低档机与1401相当，高档机则比7094功能强很多。由于所有的计算机都有相同的体系结构和指令集，因此，在理论上，为一种型号机器编写的程序可以在其他所有型号的机器上运行。而且360被设计成既可用于科学计算，又可用于商业计算，这样，一个系列的计算机便可以满足所有用户的要求。360是第一个采用（小规模）芯片（集成电路）的主流机型，与采用分立晶体管制造的第二代计算机相比，其性能/价格比有很大提高。“单一家族”思想的最大优点同时也是其最大的缺点。IBM（或其他公司）无法写出同时满足这些相互冲突需要的软件，其结果是一个庞大的又极其复杂的操作系统。 它也使第二代操作系统所缺乏的几项关键技术得到了广泛应用。 其中最重要的应该是多道程序设计（multiprogramming）。当一个作业等待I/O操作完成时，另一个作业可以使用CPU。如果内存中可以同时存放足够多的作业，则CPU利用率可以接近100%。在内存中同时驻留多个作业需要特殊的硬件来对其进行保护，以避免作业的信息被窃取或受到攻击。 同时的外部设备联机操作（Simultaneous Peripheral Operation On Line，SPOOLing），任何时刻当一个作业运行结束时，操作系统就能将一个新作业从磁盘读出，装进空出来的内存区域运行。 分时系统（timesharing）的出现 【Unix诞生】 一位曾参加过MULTICS研制的贝尔实验室计算机科学家Ken Thompson，后来找到一台无人使用的PDP-7机器，并开始开发一个简化的、单用户版MULTICS。他的工作后来导致了UNIX操作系统的诞生。接着，UNIX在学术界，政府部门以及许多公司中流行。为了使编写的程序能够在任何版本的UNIX上运行，IEEE提出了一个UNIX的标准，称作POSIX，目前大多数UNIX版本都支持它。对UNIX版本免费产品（不同于教育目的）的愿望，导致芬兰学生Linus Torvalds编写了Linux。 第四代（1980年至今）：个人计算机 随着LSI（大规模集成电路）的发展，在每平方厘米的硅片芯片上可以集成数千个晶体管，个人计算机时代到来了。 1974年，当Intel 8080，第一代通用8位CPU出现时，Intel希望有一个用于8080的操作系统，部分是为了测试目的。Intel请求其顾问Gary Kildall编写。Kildall和一位朋友首先为新推出的Shugart Associates 8英寸软盘构造了一个控制器，并把这个软磁盘同8080相连，从而制造了第一个配有磁盘的微型计算机。 1977年，Digital Research重写了CP/M，使其可以在使用8080、Zilog Z80以及其他CPU芯片的多种微型计算机上运行，从而使得CP/M完全控制了微型计算机世界达5年之久。 在20世纪80年代的早期，IBM设计了IBM PC并寻找可在上面运行的软件。来自IBM的人员同Bill Gates联系有关他的BASIC解释器的许可证事宜，他们也询问是否他知道可在PC机上运行的操作系统。Gates建议IBM同Digital Research联系，即当时世界上主宰操作系统的公司。在做出毫无疑问是近代历史上最糟的商业决策后，Kildall拒绝与IBM会见。 在IBM返回时，Gates了解到一家本地计算机制造商，Seattle Computer Products，有合适的操作系统DOS（Disk Operating System）。他联系对方并提出购买（宣称75 000美元），对方接受了。然后Gates提供给IBM成套的DOS/BASIC，IBM也接受了。IBM希望做某些修改，于是Gates雇佣了那个写DOS的作者，Tim Paterson，作为Gates的微软公司早期的一个雇员，并开展工作。修改版称为MS-DOS（MicroSoft Disk Operating System），并且很快主导了IBM PC市场。同Kildall试图将CP/M每次卖给用户一个产品相比（至少 开始是这样），这里一个关键因素是Gates（回顾起来，极其聪明）的决策，将MS-DOS与计算机公司的硬件捆绑在一起出售。 1983年，IBM PC后续机型IBM PC/AT推出，配有Intel 80286 CPU。此时，MS-DOS已经确立了地位。 Steve Jobs访问PARC,Jobs一看到GUI，立即意识到它的潜在价值，而Xerox管理层恰好没有认识到。Jobs随后着手设计了带有GUI的苹果计算机。Jobs的第二次尝试，即苹果Macintosh，取得了巨大的成功，它是为那些不仅没有计算机知识，而且也根本不打算学习计算机的用户们准备的。在图像设计、专业数码摄影，以及专业数字视频生产的创意世界里，Macintosh得到广泛的应用。 在微软决定构建MS-DOS的后继产品时，受到了Macintosh成功的巨大影响。微软开发了名为Windows的基于GUI的系统，早期它运行在MS-DOS上层（它更像shell而不像真正的操作系统）。在从1985年至1995年的10年之间，Windows只是在MS-DOS上层的一个图形环境。然而，到了1995年，一个独立的Windows版本，具有许多操作系统功能的Windows 95发布了。Windows 95仅仅把底层的MS-DOS作为启动和运行老的MS-DOS程序之用。1998年，一个稍做修改的系统，Windows 98发布。不过Windows 95和Windows 98仍然使用了大量16位Intel汇编语言。 在个人计算机世界中，另一个主要竞争者是UNIX（和它的各种变体）。UNIX在网络和企业服务器等领域强大，在台式计算机上，特别是在诸如印度和中国这些发展中国家里，UNIX的使用也在增加。 操作系统功能 操作系统位于底层硬件与用户之间，是两者沟通的桥梁。用户可以通过操作系统的用户界面，输入命令。操作系统则对命令进行解释，驱动硬件设备，实现用户要求。操作系统的主要标准功能：进程管理，内存管理，文件系统管理，输入输出管理。 对于操作系统功能总结如下： 同样理论需要向实践服务，知行需要合一，本博客同样针对一种一种多应用与服务端的操作系统进行研究，Linux。 参考资料 维基百科 操作系统概念(第9版) 英文版 操作系统设计与实现 第3版 现代操作系统（原书第3版） (计算机科学丛书) 后续阅读链接","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blackforest1990.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"导论","slug":"导论","permalink":"https://blackforest1990.github.io/tags/%E5%AF%BC%E8%AE%BA/"}]},{"title":"how to read a book","slug":"how-to-read-a-book","date":"2023-11-21T08:10:05.000Z","updated":"2023-12-04T03:11:19.897Z","comments":true,"path":"2023/11/21/how-to-read-a-book/","link":"","permalink":"https://blackforest1990.github.io/2023/11/21/how-to-read-a-book/","excerpt":"","text":"如何阅读一本书 读书多而无所得，遇到经典书籍很难坚持下去，读不到自己脑子里去，找到一本【如何阅读一本书】，从几个层次来讨论书籍如何来阅读。 读书分为四个层次，基础阅读，检视阅读，分析阅读，主题阅读，层层递进，一层比一层深入。 基础阅读 基础阅读为基本能力，逐句阅读，为信息检索。 检视阅读 检视阅读为了解作者写作的框架，粗粗略略的快速读过，也是读者对于书的挑选，如果是煌煌巨著，再深入之。 (1)先看书名页，然后如果有序就先看序 (2)研究目录页 (3)如果书中附有索引，也要检阅一下 (4)如果那是本包着书衣的新书，不妨读一下出版社的介绍 (5)从你对一本书的目录很概略，甚至有点模糊的印象中，开始挑几个看来跟主题息息相关的篇章来看。 (6)最后一步，把书打开来，东翻翻西翻翻，念个一两段，有时候连续读几页，但不要太多 分析阅读 分析阅读有时候也可以称为“精读”。显然，只有对有价值的书，才值得花力气做“分析阅读”。“烂书或平庸的书”是没有这种待遇的。 这本书花了大量的篇幅来介绍“分析阅读”。这部分是此书【重点中的重点】。 第一阶段 找出一本书在谈些什么： (1)依照书本的种类与主题作分类。 (2)用最简短的句子说出整本书在谈些什么。 (3)按照顺序与关系，列出全书的重要部分。将全书的纲要拟出来之后，再将各个部分的纲要也一一列出。 (4)找出作者在问的问题，或作者想要解决的问题。 第二阶段 诠释一本书的内容： (5)诠释作者使用的关键字，与作者达成共识。 (6)从最重要的句子中抓出作者的重要主旨。 (7)找出作者的论述，重新架构这些论述的前因后果，以明白作者的主张。 (8)确定作者已经解决了哪些问题，还有哪些是未解决的。在未解决的问题中，确定哪些是作者认为自己无法解决的问题。 第三阶段 像是沟通知识一样地评论一本书： A．智慧礼节的一般规则 (9)除非你已经完成大纲架构，也能诠释整本书了，否则不要轻易批评。（在你说出：“我读懂了!”之前，不要说你同意、不同意或暂缓评论。） (10)不要争强好胜，非辩到底不可。 (11)在说出评论之前，你要能证明自己区别得出真正的知识与个人观点的不同。 B．批评观点的特别标准 (12)证明作者的知识不足。 (13)证明作者的知识错误。 (14)证明作者不合逻辑。 (15)证明作者的分析与理由是不完整的。 注意：关于最后这四点，前三点是表示不同意见的准则，如果你无法提出相关的佐证，就必须同意作者的说法，或至少一部分说法。你只能因为最后一点理由，对这本书暂缓评论。 主题阅读 所谓的“主题阅读”，通俗而言就是：为了研究某个主题，阅读跟该主题相关的多本书籍。这种阅读主要包括5个步骤： 步骤一：找到相关的章节。在主题阅读中，你及你关心的主题才是基本的重点，而不是你阅读的书。总之，要记得你最主要的工作不是理解整本书的内容，而是找出这本书对你的主题有什么帮助，而这可能与作者本身的写作目的相去甚远。 步骤二：带引作者与你达成共识。真正的困难在于要强迫作者使用你的语言，而不是使用他的语言。 步骤三：厘清问题。把我们的问题说得比较明白的问题，然后让那些作者来回答这些问题。 步骤四：界定议题。设定了一个不偏不倚的共识，适用于所有被检视过的作者，再设定出一整套的问题，其中大部分都能在作者的说明中找到答案。然后就不同的答案界定并安排出议题。 步骤五：分析讨论。找到有价值的问题之后，就需要通过自己的综合分析，思考一下：为什么这几本书的作者，对同一个问题会有不同的答案。如果你能想明白，那么你对该主题所处的领域，就有了更深刻的理解。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://blackforest1990.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"实用","slug":"实用","permalink":"https://blackforest1990.github.io/tags/%E5%AE%9E%E7%94%A8/"},{"name":"工具书","slug":"工具书","permalink":"https://blackforest1990.github.io/tags/%E5%B7%A5%E5%85%B7%E4%B9%A6/"}]},{"title":"邓小平时代","slug":"邓小平时代","date":"2023-03-21T08:25:20.000Z","updated":"2024-01-09T05:14:10.942Z","comments":true,"path":"2023/03/21/邓小平时代/","link":"","permalink":"https://blackforest1990.github.io/2023/03/21/%E9%82%93%E5%B0%8F%E5%B9%B3%E6%97%B6%E4%BB%A3/","excerpt":"","text":"傅高义这本书，基本上站在客观角度观察邓小平，说明了邓在各个阶段的人生经历和施政要领。 邓是一名忠诚的共产党员和民族主义者，贯穿整个人生他都做到了这一点，他在法国留学，但是由于时局突变，没有机会学习，进行了革命运动，但终其一生他都对于知识和科学技术保留了尊重，明白科技为第一生产力。在毛主政时期，虽然三上三下，屡受打压，但是他没有让打压阻碍了工作，仍然宠辱不惊的完成了外交任务，同时恪守原则，在路线问题上不退后一步，但同时因为与毛的私交没有被开除党籍，仍然保留了希望；邓在施政上以稳定为第一原则，对于文革没有清算，保存了党和政权的威严，在经济发展上，摸着石头过河，有问题先去实践，看看效果，再决定全国是否推广。坚持改革开放不动摇，由地方去影响北京。在学潮问题中，以强悍的手腕维持了稳定，同时积极跟美国沟通，后面虽然遭受了制裁但事情仍有余地，邓的治国，让中国迅速拜托了阶级斗争，封印了文革的伤痛，发展壮大了起来，他始终保持客观与强悍，信奉精英治国，维持了中国的稳定。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://blackforest1990.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"人物传记","slug":"人物传记","permalink":"https://blackforest1990.github.io/tags/%E4%BA%BA%E7%89%A9%E4%BC%A0%E8%AE%B0/"}]},{"title":"读超新星纪元有感","slug":"读超新星纪元有感","date":"2023-03-14T14:12:11.000Z","updated":"2023-03-14T14:21:11.715Z","comments":true,"path":"2023/03/14/读超新星纪元有感/","link":"","permalink":"https://blackforest1990.github.io/2023/03/14/%E8%AF%BB%E8%B6%85%E6%96%B0%E6%98%9F%E7%BA%AA%E5%85%83%E6%9C%89%E6%84%9F/","excerpt":"","text":"超新星纪元 读书笔记 作者：刘慈欣 残酷的幻想，人类被星际灾变拦腰截断。 人类在有一线希望的时候总能迸发强大的生机。 孩子和大人是两种不同的物种，双方对于对方都有误判。 当失去了领土，一种骨子里流淌的东西也失去了。 需要有智囊，同样也要有决断。 国际政治的均衡实际上很脆弱。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://blackforest1990.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"科幻","slug":"科幻","permalink":"https://blackforest1990.github.io/tags/%E7%A7%91%E5%B9%BB/"}]},{"title":"读史有感","slug":"读史有感","date":"2023-03-14T13:58:14.000Z","updated":"2024-01-23T14:53:01.208Z","comments":true,"path":"2023/03/14/读史有感/","link":"","permalink":"https://blackforest1990.github.io/2023/03/14/%E8%AF%BB%E5%8F%B2%E6%9C%89%E6%84%9F/","excerpt":"","text":"秦：国家军国主义，丈量全国土地，登记造册全国资源，对于人民压榨太过，没有很好地消化六国残余势力 项羽：军神级别，勇略为第一将，而无战略，以自己的喜怒而支配政治（烧咸阳宫，杀秦降将，失关中之心） 刘邦：49岁斩白蛇，取得关中，军霸上，财务无所取，妇女无所辛，完成蜕变（成大事要有第一等的克制），永远用正确的人做事，宽以待人，团结一切力量，对于制度的探索要摸着石头过河，黑猫白猫抓住老鼠就是好猫。 韩信：长于军事战略，能够快速判断局势，趁关中立足未稳而定关中，10个月平魏，定赵，灭齐，降燕，充分收集情报，实实虚虚，以比之长攻彼之短，但是在身居高位的时候没有三分天下，终究是国士无双，而没有意识到政治斗争的残酷性。 吕后：用黄老之道治国，维持小政府，在没有大动乱（战争和大灾），能够很好地与民休息，不与军功集团争相权，保持政治平衡，对于权力克制不够，对于政敌迫害过大，导致后面反弹太大。 文帝：宽厚而福报深厚，在政治和权力面前永远是谨慎的，推恩令逐渐蚕食诸侯的权力，继续用黄老之道治国。 武帝：为千古一帝，权术的顶峰，文化上独尊儒术，儒学也彻底倒向统治者，创造了很多压榨人民的手段，官方统一货币，国有企业出现（盐，铁），人民被无止境的盘剥，允许买官，通过压榨天下，拥有了庞大的经费，建立起了天下无敌的骑兵，发出了犯强汉者虽远必诛的强音，然后在晚年通过权术，让太子自杀，发布罪己诏，让政策软着陆，定下了昭宣的政策方针（由军略和盘剥改为与民休息），选择了最优秀的接班人霍光，让自己的政策能够执行。 宣帝：民间长大，了解民间疾苦，不搞政治清算，对于霍光的政策能够延续，“汉家自有制度，本以霸王道杂之。奈何纯任德教，用周政乎！”是对于汉朝制度最好的注解，然而儒家没有被关进笼子里，太学制度让儒家成为了大祸。 王莽：乱天下者，儒家理想主义者，糟糕的经济政策，糟糕的豪强政策，加上糟糕的天气，一世而终。 光武：安定天下，豪族投票出的代理人，重新确立儒学的地位，以夷制夷的优秀策略。 曹操：浪漫的诗人和强大的军事家，优秀的政治家，年轻时候想成为大汉的一名优秀官吏，后来讨伐董卓后认清现实，武以涿郡老家的武人集团起兵，后来得到颍川荀彧的加盟，从而确立了文以颍川文人集团，在于袁绍的官渡之战中，在最后关头亲自带5000骑兵攻打乌巢，真英雄自风流。 平定北方，统一了全国80%人口的地方，但是同时造成的破坏也很多，屠戮徐州，迁徙百姓，对于曾经得王佐之才，为了能够以魏代汉，也诛杀了荀彧， 最后曹氏不得善终。 李世民：7世纪地表最强，少年英雄，布局深远，军略上能够洞悉战场的局势，以最小的成本取得最大的战果，政治上以自我的克制造成了清明的政治环境，对于北疆的策略非常高明，作为天可汗，能够集合草原部落去对付不听话的野心家，种种布局，以最小的代价确定了北疆的和平，唯一比较诟病的是对于继承人的策略。 李世民： 1、永远亲临现场调研，具体问题具体分析。 2、永远注意士气，永远跟同志们讲明白革命因何成功的理论依据。 3、永远直面困难，永远解决问题，永远亲自带队攻坚最难的任务。 4、战争是政治的延续，打仗永远算账，不是单纯地为了打仗而打仗，永远全局一盘棋。 李世民：人这物种，半瓶子水时最晃荡，一瓶子水时都没声音，之所以“惟大英雄能本色”，是因为像炫耀、忐忑、不自信等等的关卡他都已经过去了，他该啥样就啥样，他从不需要来证明自己什么。 武则天：唐朝衰弱由武氏开始，任用酷吏，破坏政治清明，好大喜功，军事上昏招频出，从而使府兵制衰弱下去，为藩镇割据打好基础。 成大事者，无不历经各种险阻，内修德行，有第一流的克制和自强不息，一心一意，才能得窥第一流的风景。","categories":[{"name":"历史","slug":"历史","permalink":"https://blackforest1990.github.io/categories/%E5%8E%86%E5%8F%B2/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"https://blackforest1990.github.io/tags/%E6%9D%82%E8%AE%B0/"}]}],"categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://blackforest1990.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"经验总结","slug":"经验总结","permalink":"https://blackforest1990.github.io/categories/%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/"},{"name":"编程","slug":"编程","permalink":"https://blackforest1990.github.io/categories/%E7%BC%96%E7%A8%8B/"},{"name":"历史","slug":"历史","permalink":"https://blackforest1990.github.io/categories/%E5%8E%86%E5%8F%B2/"},{"name":"如何赚钱","slug":"如何赚钱","permalink":"https://blackforest1990.github.io/categories/%E5%A6%82%E4%BD%95%E8%B5%9A%E9%92%B1/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://blackforest1990.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"内存管理","slug":"内存管理","permalink":"https://blackforest1990.github.io/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"name":"进程管理","slug":"进程管理","permalink":"https://blackforest1990.github.io/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"工作语言","slug":"工作语言","permalink":"https://blackforest1990.github.io/tags/%E5%B7%A5%E4%BD%9C%E8%AF%AD%E8%A8%80/"},{"name":"销售管理","slug":"销售管理","permalink":"https://blackforest1990.github.io/tags/%E9%94%80%E5%94%AE%E7%AE%A1%E7%90%86/"},{"name":"电信运营商","slug":"电信运营商","permalink":"https://blackforest1990.github.io/tags/%E7%94%B5%E4%BF%A1%E8%BF%90%E8%90%A5%E5%95%86/"},{"name":"与虎谋皮","slug":"与虎谋皮","permalink":"https://blackforest1990.github.io/tags/%E4%B8%8E%E8%99%8E%E8%B0%8B%E7%9A%AE/"},{"name":"云计算","slug":"云计算","permalink":"https://blackforest1990.github.io/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"},{"name":"how to make","slug":"how-to-make","permalink":"https://blackforest1990.github.io/tags/how-to-make/"},{"name":"黄仁宇","slug":"黄仁宇","permalink":"https://blackforest1990.github.io/tags/%E9%BB%84%E4%BB%81%E5%AE%87/"},{"name":"工作","slug":"工作","permalink":"https://blackforest1990.github.io/tags/%E5%B7%A5%E4%BD%9C/"},{"name":"导论","slug":"导论","permalink":"https://blackforest1990.github.io/tags/%E5%AF%BC%E8%AE%BA/"},{"name":"实用","slug":"实用","permalink":"https://blackforest1990.github.io/tags/%E5%AE%9E%E7%94%A8/"},{"name":"工具书","slug":"工具书","permalink":"https://blackforest1990.github.io/tags/%E5%B7%A5%E5%85%B7%E4%B9%A6/"},{"name":"人物传记","slug":"人物传记","permalink":"https://blackforest1990.github.io/tags/%E4%BA%BA%E7%89%A9%E4%BC%A0%E8%AE%B0/"},{"name":"科幻","slug":"科幻","permalink":"https://blackforest1990.github.io/tags/%E7%A7%91%E5%B9%BB/"},{"name":"杂记","slug":"杂记","permalink":"https://blackforest1990.github.io/tags/%E6%9D%82%E8%AE%B0/"}]}