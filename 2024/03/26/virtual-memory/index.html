<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>virtual memory | 黑暗森林</title><meta name="author" content="BlackForest1990"><meta name="copyright" content="BlackForest1990"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="虚拟内存是一种允许执行部分未完全加载到内存中的进程的技术。这种方案的一个主要优势是程序可以比物理内存更大。此外，虚拟内存将主存储器抽象为一个非常大、统一的存储数组，将用户视图中的逻辑内存与物理内存分离开来。这种技术使程序员摆脱了内存存储限制的担忧。虚拟内存还允许进程轻松共享文件并实现共享内存。此外，它提供了一个高效的进程创建机制。然而，虚拟内存不易实现，如果使用不慎可能会显著降低性能。 背景 内存">
<meta property="og:type" content="article">
<meta property="og:title" content="virtual memory">
<meta property="og:url" content="https://blackforest1990.github.io/2024/03/26/virtual-memory/index.html">
<meta property="og:site_name" content="黑暗森林">
<meta property="og:description" content="虚拟内存是一种允许执行部分未完全加载到内存中的进程的技术。这种方案的一个主要优势是程序可以比物理内存更大。此外，虚拟内存将主存储器抽象为一个非常大、统一的存储数组，将用户视图中的逻辑内存与物理内存分离开来。这种技术使程序员摆脱了内存存储限制的担忧。虚拟内存还允许进程轻松共享文件并实现共享内存。此外，它提供了一个高效的进程创建机制。然而，虚拟内存不易实现，如果使用不慎可能会显著降低性能。 背景 内存">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blackforest1990.github.io/image/blackforest.jpg">
<meta property="article:published_time" content="2024-03-26T02:22:06.000Z">
<meta property="article:modified_time" content="2024-03-31T10:24:40.976Z">
<meta property="article:author" content="BlackForest1990">
<meta property="article:tag" content="内存管理">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blackforest1990.github.io/image/blackforest.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://blackforest1990.github.io/2024/03/26/virtual-memory/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'virtual memory',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-31 18:24:40'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="黑暗森林" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/image/blackforest.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="黑暗森林"><span class="site-name">黑暗森林</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">virtual memory</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-03-26T02:22:06.000Z" title="发表于 2024-03-26 10:22:06">2024-03-26</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-03-31T10:24:40.976Z" title="更新于 2024-03-31 18:24:40">2024-03-31</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="virtual memory"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><strong>虚拟内存是一种允许执行部分未完全加载到内存中的进程的技术</strong>。这种方案的一个主要优势是程序可以比物理内存更大。此外，虚拟内存将主存储器抽象为一个非常大、统一的存储数组，将用户视图中的逻辑内存与物理内存分离开来。这种技术使程序员摆脱了内存存储限制的担忧。<strong>虚拟内存还允许进程轻松共享文件并实现共享内存</strong>。此外，它提供了一个高效的进程创建机制。然而，虚拟内存不易实现，如果使用不慎可能会显著降低性能。</p>
<h2 id="背景">背景</h2>
<p>内存管理算法是必要的，因为有一个基本要求：<strong>正在执行的指令必须在物理内存中</strong>。<strong>满足这一要求的第一种方法是将整个逻辑地址空间放置在物理内存中</strong>。动态加载可以帮助缓解这个限制，但通常需要程序员采取特殊预防措施并进行额外的工作。</p>
<p>指令必须在物理内存中才能执行的要求看起来既必要又合理；但同时也很不幸，因为它限制了程序的大小与物理内存的大小相同。事实上，对真实程序的检查表明，在许多情况下，并不需要整个程序。例如，考虑以下情况：</p>
<ul>
<li><strong>程序通常会包含处理异常错误条件的代码</strong>。由于这些错误在实践中很少发生，甚至几乎从不发生，因此这些代码几乎不会被执行。</li>
<li><strong>数组、列表和表通常分配比实际需要更多的内存</strong>。例如，一个数组可能声明为 100 行 100 列，即使它很少会超过 10 行 10 列。汇编器符号表可能有 3000 个符号的空间，尽管平均程序只有不到 200 个符号。</li>
<li><strong>程序的某些选项和功能可能很少被使用</strong>。例如，美国政府计算机上用于平衡预算的程序已经多年没有被使用过了。</li>
</ul>
<p>即使在那些需要整个程序的情况下，也不一定需要同时加载全部程序。 能够执行仅部分加载到内存中的程序将带来许多好处：</p>
<ul>
<li><strong>程序将不再受物理内存限制</strong>。用户能够为极大的虚拟地址空间编写程序，简化编程任务。</li>
<li>由于每个用户程序所需的物理内存更少，因此可以运行更多程序，CPU利用率和吞吐量相应增加，但响应时间或周转时间不会增加。</li>
<li>加载或交换用户程序到内存中将需要更少的I/O，因此每个用户将运行更快。</li>
</ul>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240326104303119.png" alt="image-20240326104303119" style="zoom:50%;">
<p>进程的虚拟地址空间是指进程在内存中存储的逻辑（或虚拟）视图。通常，这个视图是进程从某个逻辑地址（比如说，地址0）开始，并以连续的内存存在，如下图所示。然而，实际上物理内存可能是以页框（page frames）的形式组织的，而分配给一个进程的物理页框可能不是连续的。<strong>将逻辑页映射到内存中的物理页框是由内存管理单元（MMU）负责的</strong>。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240326104527703.png" alt="image-20240326104527703" style="zoom:50%;">
<p>堆通过动态内存分配向上增长。同样的，栈通过连续函数调用向内存下方增长。<strong>堆和栈之间的空白区域是虚拟地址空间的一部分，但只有在堆和栈增长时才需要实际的物理页</strong>。包含空洞的虚拟地址空间被称为稀疏地址空间sparse address space。使用稀疏地址空间是有益的，因为随着堆或栈段的增长，空洞可以被填充，或者如果我们希望在程序执行期间动态链接库（或可能是其他共享对象）。</p>
<p>除了将逻辑内存与物理内存分离外，<strong>虚拟内存还通过页面共享允许两个或多个进程共享文件和内存</strong>。这带来了以下好处：</p>
<ul>
<li><strong>系统库可以通过将共享对象映射到虚拟地址空间中而被多个进程共享</strong>。虽然每个进程都将库视为其虚拟地址空间的一部分，但库实际所在的物理内存页面是所有进程共享的。通常，每个链接到库的进程的空间中都将库映射为只读。</li>
<li><strong>类似地，进程可以共享内存。虚拟内存允许一个进程创建一个可与另一个进程共享的内存区域</strong>。共享此区域的进程将其视为其虚拟地址空间的一部分，但实际的物理内存页面是共享的。</li>
<li>在进程创建时，可以通过 fork() 系统调用共享页面，从而加快进程创建的速度。</li>
</ul>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240326105633885.png" alt="image-20240326105633885" style="zoom:50%;">
<h2 id="需求分页">需求分页</h2>
<p>考虑一下如何将可执行程序从磁盘加载到内存中。一种选择是在程序执行时将整个程序加载到物理内存中。<strong>然而，这种方法的问题是我们可能最初并不需要将整个程序加载到内存中</strong>。另一种策略是仅在需要时加载页面。这种技术称为需求分页demanding paging，常用于虚拟内存系统中。使<strong>用需求分页的虚拟内存系统仅在程序执行期间需要时加载页面</strong>。因此，从未访问过的页面也不会加载到物理内存中。</p>
<p>需求分页系统类似于带有交换的分页系统，其中进程驻留在磁盘中。当我们想要执行一个进程时，我们将其交换到内存中。然而，与将整个进程交换到内存不同，我们使用了一种惰性换页器lazy swapper。<strong>惰性换页器永远不会将一个页面交换到内存中，除非该页面将被需要</strong>。在需求分页系统的背景下，使用术语“换页器”是技术上不正确的。换页器操作整个进程，而页式存储管理器则涉及进程的单个页面。因此，我们在需求分页中使用“页式存储管理器pager”而不是“换页器swapper”。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240326110609265.png" alt="image-20240326110609265" style="zoom:50%;">
<h3 id="基本原理">基本原理</h3>
<p>当要将一个进程换入时，<strong>页式存储管理器会猜测在进程再次被交换出之前将使用哪些页面</strong>。页式存储管理器不是将整个进程换入内存，而是仅将那些页面换入内存。因此，它避免了将不会被使用的页面读入内存，从而减少了交换时间和所需物理内存的数量。</p>
<p><strong>使用这种方案，我们需要一些形式的硬件支持来区分哪些页面在内存中</strong>，哪些页面在磁盘上。有效-无效位方案可以用于这个目的。然而，这次，当该位被设置为“有效”时，相关的页面既合法又在内存中。如果该位被设置为“无效”，则页面可能无效（即不在进程的逻辑地址空间中），或者有效但当前在磁盘上。将页面带入内存的页表项被设置为通常的方式，但是不在内存中的页面的页表项要么只是标记为无效，要么包含页面在磁盘上的地址。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240326110957430.png" alt="image-20240326110957430" style="zoom:50%;">
<p>注意，如果进程从未尝试访问该页面，则将页面标记为无效将不会产生任何效果。<strong>因此，如果我们猜测正确，并且只换入实际需要的所有页面以及仅这些页面，那么该进程将与我们完全换入所有页面时运行的方式完全相同</strong>。当进程执行并访问驻留在内存中的页面时，执行会正常进行。</p>
<p>但是如果进程尝试访问未被换入内存的页面会发生什么呢？对标记为无效的页面的访问会导致页面错误(page fault)。<strong>在通过页表进行地址转换时，分页硬件会注意到无效位被设置，从而导致陷阱传递给操作系统</strong>。这个陷阱是操作系统未能将所需页面换入内存的结果。处理这个页面错误的过程很简单:</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240326111756218.png" alt="image-20240326111756218" style="zoom:50%;">
<ol>
<li>我们检查该进程的内部表（通常与进程控制块一起保存）来确定引用是有效还是无效的内存访问。</li>
<li><strong>如果引用无效，我们终止该进程</strong>。如果引用有效但我们尚未换入该页面，则现在换入该页面。</li>
<li>我们找到一个空闲帧（例如，通过从空闲帧列表中获取一个）。</li>
<li>我们安排一个磁盘操作，将所需的页面读入新分配的帧中。</li>
<li>当磁盘读取完成后，我们修改保存在进程和页表中的内部表，表示该页面现在在内存中。</li>
<li>我们重新启动被陷阱中断的指令。该进程现在可以访问该页面，就好像它一直在内存中一样。</li>
</ol>
<p><strong>在极端情况下，我们可以开始执行一个没有任何页面在内存中的进程</strong>。当操作系统将指令指针设置为进程的第一条指令，该指令位于一个非内存驻留页面上时，进程立即出现页面错误。在将此页面换入内存后，进程继续执行，必要时出现页面错误，直到它需要的每个页面都在内存中为止。在那时，它可以执行而不再出现页面错误。这种方案是纯需求分页pure demand paging：直到需要时才将页面换入内存。</p>
<p>理论上，一些程序可能在每次指令执行时访问多个新页面的内存（一个页面用于指令，多个页面用于数据），可能导致每个指令多次页面错误。<strong>这种情况将导致系统性能不可接受</strong>。幸运的是，对正在运行的进程的分析显示，这种行为极不可能发生。<strong>程序倾向于具有引用局部性</strong>，这导致了需求分页的合理性能。</p>
<p>支持需求分页的硬件与支持分页和交换的硬件相同：</p>
<ul>
<li>页表。这个表具有通过有效-无效位或保护位的特殊值来标记条目无效的能力。</li>
<li>辅助存储器。这个存储器保存那些不在主存储器中的页面。辅助存储器通常是一个高速磁盘。它被称为交换设备，用于此目的的磁盘部分称为交换空间。</li>
</ul>
<p><strong>需求分页的一个关键要求是在页面错误后能够重新启动任何指令</strong>。因为当页面错误发生时，我们会保存被中断进程的状态（寄存器、条件码、指令计数器），所以我们必须能够将进程在完全相同的位置和状态下重新启动，唯一的区别是所需页面现在在内存中并且可访问。在大多数情况下，这个要求很容易满足。页面错误可能发生在任何内存引用上。<strong>如果页面错误发生在指令取指时，我们可以重新取指再次执行指令。如果在取操作数时发生页面错误，我们必须重新取指并解码指令，然后再次取操作数</strong>。</p>
<p>作为最坏情况的示例，考虑一个三地址指令，例如将A的内容与B相加，并将结果放入C。执行该指令的步骤如下：</p>
<ol>
<li>取指并解码指令（ADD）。</li>
<li>取A。</li>
<li>取B。</li>
<li>将A和B相加。</li>
<li>将和存储在C中。</li>
</ol>
<p>如果我们尝试将结果存储在C时出现页面错误（因为C所在的页面当前不在内存中），我们将不得不获取所需的页面，将其换入内存，更新页表，并重新启动指令。<strong>重新启动将需要重新取指，重新解码指令，再次获取两个操作数，然后再次执行加法</strong>。然而，重复工作并不多（不到一个完整指令），并且只有在发生页面错误时才需要重复。</p>
<p>当一个指令可能修改多个不同的位置时，主要困难出现在这里。这个问题可以通过两种不同的方式解决。<strong>在一种解决方案中，微码计算并尝试访问两个块的两端</strong>。如果将要发生页面错误，它将发生在此步骤之前，即在任何内容被修改之前。然后可以进行移动操作；我们知道不会发生页面错误，因为所有相关页面都在内存中。<strong>另一种解决方案使用临时寄存器来保存被覆盖位置的值</strong>。如果发生页面错误，则在陷阱发生之前，所有旧值都会被写回内存。这个操作将内存恢复到指令开始之前的状态，以便可以重复执行指令。</p>
<h3 id="性能">性能</h3>
<p>需求分页可以显著影响计算机系统的性能。为了理解其中的原因，让我们计算需求分页内存的有效访问时间。<strong>对于大多数计算机系统来说，内存访问时间，表示为 ma，范围在 10 到 200 纳秒之间</strong>。只要没有页面错误，有效访问时间就等于内存访问时间。然而，如果发生页面错误，我们必须首先从磁盘读取相关页面，然后访问所需的字。</p>
<p>设 p 为页面错误的概率（0 ≤ p ≤ 1）。我们期望 p 接近于零，也就是说，我们期望只有很少的页面错误发生。那么有效访问时间可以表示为：</p>
<p>有效访问时间=(1−<em>p</em>)×ma+<em>p</em>×页面错误时间</p>
<p>我们面临三个页面错误服务时间的主要组成部分：</p>
<ol>
<li>处理页面错误中断。</li>
<li>读取页面。</li>
<li>重新启动进程。</li>
</ol>
<p><strong>第一个和第三个任务可以通过仔细编码减少到几百条指令</strong>。这些任务每个可能需要 1 到 100 微秒。<strong>然而，页面切换时间可能接近 8 毫秒。</strong>（典型硬盘的平均延迟为 3 毫秒，寻道时间为 5 毫秒，传输时间为 0.05 毫秒。因此，总的分页时间约为 8 毫秒，包括硬件和软件时间。）还要记住，我们只考虑设备服务时间。如果一系列进程正在等待设备，我们必须将设备排队时间添加到我们等待分页设备空闲以服务我们的请求的时间中，从而增加了交换的时间。</p>
<p><strong>需求分页的另一个方面是交换空间的处理和整体利用</strong>。与文件系统相比，磁盘 I/O 到交换空间通常更快。这是因为交换空间是以更大的块分配的，并且不使用文件查找和间接分配方法。因<strong>此，系统可以通过在进程启动时将整个文件映像复制到交换空间，然后从交换空间执行需求分页来获得更好的分页吞吐量</strong>。另一种选择是最初从文件系统需求页面，但在替换时将页面写入交换空间。这种方法确保只有需要的页面从文件系统中读取，而所有后续的页面都是从交换空间进行的。</p>
<p><strong>移动操作系统通常不支持交换</strong>。相反，这些系统从文件系统进行需求分页，并且如果内存受限，可以从应用程序中回收只读页面（例如代码）。如果稍后需要这些数据，可以从文件系统进行需求分页。在 iOS 下，除非应用程序被终止或明确释放内存，<strong>否则匿名内存页面永远不会从应用程序中回收</strong>。</p>
<h2 id="写时复制">写时复制</h2>
<p>我们说明了通过需求分页加载包含第一条指令的页面可以快速启动进程。然而，使用 fork() 系统调用进行进程创建可能最初会绕过对需求分页的需要，这是通过使用类似于页面共享的技术实现的。<strong>这种技术可以实现快速的进程创建，并将新创建进程所需的页面数最小化</strong>。</p>
<p>传统上，fork() 的工作方式是为子进程创建父进程的地址空间副本，复制属于父进程的页面。然而，考虑到许多子进程在创建后立即调用 exec() 系统调用，复制父进程的地址空间可能是不必要的。相反，我们可以使用一种称为写时复制（copy-on-write）的技术，该技术允许父进程和子进程最初共享相同的页面。<strong>这些共享的页面被标记为写时复制页面，这意味着如果任一进程对共享页面进行写操作，将创建共享页面的副本</strong>。</p>
<p><strong>在进程 1 修改页面 C 之前</strong></p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240326123847762.png" alt="image-20240326123847762" style="zoom:50%;">
<p><strong>在进程 1 修改页面 C 之后。</strong></p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240326123950012.png" alt="image-20240326123950012" style="zoom:50%;">
<p>例如，假设子进程尝试修改包含栈部分的页面，并将这些页面设置为写时复制。操作系统将创建此页面的副本，并将其映射到子进程的地址空间。<strong>然后，子进程将修改其复制的页面，而不是父进程的页面</strong>。显然，在使用写时复制技术时，只会复制被任一进程修改的页面；所有未修改的页面可以由父进程和子进程共享。此外，只有可能被修改的页面需要标记为写时复制。不能修改的页面（包含可执行代码的页面）可以由父进程和子进程共享。写时复制是许多操作系统使用的常见技术，包括 Windows XP、Linux 和 Solaris。</p>
<p>确定要使用写时复制来复制页面时，重要的是要注意要分配空闲页面的位置。<strong>许多操作系统为此类请求提供了一个空闲页面池</strong>。这些空闲页面通常在进程的堆栈或堆需要扩展时分配，或者在需要管理写时复制页面时分配。操作系统通常使用一种称为按需零填充（zero-fill-on-demand）的技术来分配这些页面。<strong>按需零填充页面在分配之前已经被清零，因此擦除了先前的内容</strong>。</p>
<blockquote>
<p>UNIX的几个版本（包括Solaris和Linux）提供了fork()系统调用的变体——vfork()（即虚拟内存fork），其操作方式与带有写时复制的fork()不同。使用vfork()时，父进程被挂起，而子进程使用父进程的地址空间。由于vfork()不使用写时复制，因此如果子进程更改父进程地址空间的任何页面，则修改后的页面将在父进程恢复执行后可见。因此，必须谨慎使用vfork()以确保子进程不会修改父进程的地址空间。vfork()的预期用法是当子进程在创建后立即调用exec()。<strong>由于不进行页面复制，vfork()是一种非常高效的进程创建方法，有时被用于实现UNIX命令行shell界面</strong>。</p>
</blockquote>
<h2 id="页面替换">页面替换</h2>
<p>在我们之前对页面错误率的讨论中，我们假设每个页面最多只产生一次页面错误，即在首次引用时。然而，这种表述并不严格准确。如果一个包含十页的进程实际上只使用了其中一半，那么按需分页可以节省加载那些从未被使用的五页所需的I/O操作。<strong>我们也可以通过运行两倍数量的进程来增加我们的多道程序设计程度</strong>。因此，如果我们有四十个页面帧，我们可以运行八个进程，而不是如果每个进程都需要十个页面帧（其中五个从未被使用）的话只能运行四个。</p>
<p>如果我们增加了我们的多道程序设计程度，我们会过度分配内存。如果我们运行六个进程，每个进程的大小为十页，但实际上只使用了五页，那么我们的CPU利用率和吞吐量就会更高，而且还有十个页面帧可供使用。<strong>然而，对于特定的数据集，这些进程中的每一个可能会突然尝试使用其全部十个页面，这会导致当只有四十个页面可用时需要六十个页面帧</strong>。</p>
<p>此外，还需考虑到系统内存不仅用于保存程序页面。I/O 缓冲区也占用了相当大的内存空间。这种使用会增加内存放置算法的压力。<strong>决定分配多少内存给 I/O 以及多少内存给程序页面是一个重要的挑战</strong>。一些系统会为 I/O 缓冲区分配固定百分比的内存，而其他系统则允许用户进程和 I/O 子系统竞争全部系统内存。</p>
<p>内存过度分配表现如下。当用户进程执行时，发生页面错误。操作系统确定所需页面位于磁盘上的位置，但随后发现空闲帧列表上没有可用的空闲帧；所有内存都在使用中。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240326124845496.png" alt="image-20240326124845496" style="zoom:50%;">
<p>此时，操作系统有几种选择。它可以终止用户进程。但是，分页是操作系统试图提高计算机系统利用率和吞吐量的方式。<strong>用户不应意识到他们的进程正在运行在一个分页系统上——分页应该在逻辑上对用户透明</strong>。因此，这个选项不是最佳选择。</p>
<p>操作系统可以选择将一个进程调出，释放其所有的页框，降低多道程序设计的水平。在某些情况下，这是一个很好的选择，在这里，我们讨论最常见的解决方案：页面替换。</p>
<h3 id="基础页面替换">基础页面替换</h3>
<p>页面替换采用如下方法。如果没有空闲页框，我们将找到一个当前未被使用的页框并释放它。<strong>我们可以通过将其内容写入交换空间并更改页表(以及其他所有表)以指示该页不再驻留在内存中来释放一个页框</strong>。我们现在可以使用释放的页框来保存进程发生错误的页面。我们修改页面错误服务例程以包括页面替换：</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240326125600487.png" alt="image-20240326125600487" style="zoom:50%;">
<ol>
<li>找到磁盘上所需页面的位置。</li>
<li>找到一个空闲页框： a. 如果有空闲页框，则使用它。 b. 如果没有空闲页框，则使用页面替换算法选择一个受害页框。 c. 将受害页框写入磁盘；相应地更改页面和页框表。</li>
<li>将所需页面读入新释放的页框；更改页面和页框表。</li>
<li>从页面错误发生处继续用户进程。</li>
</ol>
<p>请注意，如果没有空闲的页框，则需要两次页面传输（一次出，一次入）。<strong>这种情况有效地将页面错误服务时间加倍，并相应地增加了有效访问时间</strong>。</p>
<p><strong>我们可以通过使用修改位来减少这种开销</strong>。当使用此方案时，硬件中的每个页面或页框都与一个修改位相关联。当页面中的任何字节被写入时，硬件会设置该页面的修改位，表示该页面已被修改。当我们选择一个页面进行替换时，我们会检查其修改位。<strong>如果该位已设置，我们就知道该页面从磁盘中读取以来已被修改</strong>。在这种情况下，我们必须将页面写入磁盘。然而，如果修改位未设置，则表示该页面自从被读入内存以来尚未被修改。在这种情况下，我们不需要将内存页面写入磁盘：它已经在那里了。这种技术也适用于只读页面（例如，二进制代码的页面）。这些页面无法修改；因此，它们可以在需要时被丢弃。如果页面没有被修改，这种方案可以显著减少服务页面错误所需的时间，因为它将I/O时间减少了一半。</p>
<p><strong>页面替换是需求分页的基础</strong>。它完成了逻辑内存和物理内存之间的分离。借助这种机制，可以在较小的物理内存上为程序员提供巨大的虚拟内存。如果没有需求分页，用户地址将被映射到物理地址，而这两组地址可能是不同的。然而，一个进程的所有页面仍然必须在物理内存中。通过需求分页，逻辑地址空间的大小不再受物理内存的限制。如果我们有一个由二十个页面组成的用户进程，我们可以通过简单地使用需求分页并使用替换算法在必要时找到一个空闲帧来执行它。<strong>如果要替换已修改的页面，则其内容将被复制到磁盘。对该页面的后续引用将导致页面错误</strong>。此时，页面将重新加载到内存中，可能替换进程中的其他页面。</p>
<p>要实现需求分页，我们必须解决两个主要问题：<strong>我们必须开发一个帧分配算法和一个页面替换算法</strong>。也就是说，如果内存中有多个进程，我们必须决定为每个进程分配多少帧；当需要进行页面替换时，我们必须选择要替换的帧。设计解决这些问题的适当算法是一项重要任务，因为磁盘 I/O 成本很高。即使是对需求分页方法的轻微改进也会带来系统性能的巨大提升。</p>
<h3 id="页面替换算法">页面替换算法</h3>
<p>最简单的页面替换算法是先进先出（FIFO）算法。FIFO替换算法将每个页面与其被引入内存的时间关联起来。当需要替换页面时，选择最老的页面。注意，记录页面引入时间并不是严格必要的。<strong>我们可以创建一个FIFO队列来保存内存中的所有页面。我们替换队列头部的页面。当将页面引入内存时，我们将其插入到队列的尾部</strong>。</p>
<p>FIFO页面置换算法易于理解和编程。然而，它的性能并不总是良好的。一方面，被替换的页面可能是很久以前使用过的初始化模块，现在已经不再需要了。另一方面，它可能包含一个早期初始化并且一直被频繁使用的变量。</p>
<p><strong>贝雷迪异常：对于某些页面替换算法，随着分配的页面数增加，页面错误率可能会增加</strong>。贝雷迪异常的发现导致人们寻找最优页面替换算法——即所有算法中页面错误率最低且永远不会受到贝雷迪异常影响的算法。这样的算法确实存在，并被称为 OPT 或 MIN。它就是这样的：<strong>替换最长时间不会被使用的页面</strong>。使用这种页面替换算法可以保证在固定数量的页面帧下获得最低的可能页面错误率。</p>
<p>不幸的是，最佳页面替换算法很难实现，因为它需要对参考字符串的未来知识。因此，最佳算法主要用于比较研究。例如，了解到尽管一个新算法不是最佳的，但在最差情况下它与最佳的差距不超过12.3%，平均差距不超过4.7%，可能是有用的。</p>
<p>如果最佳算法不可行，也许可以使用最佳算法的近似。这种方法就是最近最少使用（LRU）算法。LRU替换将每个页面与其上次使用的时间关联起来。当需要替换页面时，LRU选择最长时间未被使用的页面。我们可以将这种策略看作是最佳页面替换算法向后查找时间，而不是向前查找。（奇怪的是，如果我们让S^R是参考字符串S的反转，那么OPT算法在S上的页面错误率与OPT算法在S^R上的页面错误率相同。同样，LRU算法在S上的页面错误率与LRU算法在S^R上的页面错误率相同。）</p>
<p><strong>LRU策略通常被用作页面替换算法，并被认为是有效的</strong>。主要问题是如何实现LRU替换。LRU页面替换算法可能需要大量的硬件辅助。问题在于确定由最后使用时间定义的帧的顺序。有两种可行的实现方式：</p>
<ul>
<li>计数器。<strong>在最简单的情况下，我们将每个页表条目与一个使用时间字段关联，并在CPU中添加一个逻辑时钟或计数器</strong>。每次内存引用时，时钟都会递增。每当对某个页面进行引用时，时钟寄存器的内容会被复制到该页面的页表条目中的使用时间字段中。通过这种方式，我们始终可以获得对每个页面的最后引用的“时间”。我们用最小的时间值替换页面。<strong>这个方案需要在页表中搜索LRU页面，并且对于每次内存访问都需要写入内存（写入页表中的使用时间字段）。当页表发生变化（由于CPU调度）时，也必须维护时间。必须考虑时钟的溢出</strong>。</li>
<li>栈。<strong>实现LRU替换的另一种方法是保持一个页面号的栈</strong>。每当引用一个页面时，它就会被从栈中移除并放在顶部。通过这种方式，最近使用的页面总是在栈的顶部，而最近不使用的页面总是在底部。由于条目必须从栈的中间移除，<strong>最好使用一个带有头指针和尾指针的双向链表来实现这种方法</strong>。从栈中删除一个页面并将其放在栈顶最多需要更改六个指针。每次更新的成本略高一些，但是不需要搜索替换；尾指针指向栈底，即LRU页面。这种方法特别适用于LRU替换的软件或微码实现。</li>
</ul>
<p><strong>请注意，如果没有标准TLB寄存器以外的硬件支持，LRU的任何实现都是不可想象的</strong>。时钟字段或堆栈的更新必须针对每个内存引用进行。如果我们为每个引用使用中断来允许软件更新这些数据结构，那么每个内存引用的速度将至少减慢十倍，因此每个用户进程的速度也将减慢十倍。很少有系统能够容忍这种级别的内存管理开销。</p>
<p><strong>除了特定的页面替换算法外，通常还会使用其他程序</strong>。例如，系统通常保持一组空闲页面帧池。当发生页面错误时，会像以前一样选择一个牺牲页面帧。但是，在将牺牲页面写出之前，会将所需的页面从空闲页面帧池中读入一个空闲页面帧中。这个过程允许进程尽快重新启动，而无需等待牺牲页面被写出。当牺牲页面稍后被写出时，其页面帧将被添加到空闲页面帧池中。 这个想法的扩展是维护一个已修改页面的列表。<strong>每当分页设备空闲时，就会选择一个已修改的页面，并将其写入磁盘</strong>。然后将其修改位重置。这个方案增加了选择替换页面时页面干净的可能性，并且不需要被写出。</p>
<h2 id="分配帧">分配帧</h2>
<p>接下来我们转向分配的问题。我们如何将固定数量的空闲内存分配给各个进程？如果我们有93个空闲帧和两个进程，每个进程会得到多少个帧？</p>
<p>最简单的情况是单用户系统。考虑一个单用户系统，具有128 KB内存，由1 KB大小的页面组成。该系统有128个帧。操作系统可能占用35 KB，留下93个帧供用户进程使用。在纯需求分页下，所有93个帧最初都会被放在空闲帧列表上。当用户进程开始执行时，它会生成一系列页面错误。前93个页面错误都会从空闲帧列表中获取空闲帧。当空闲帧列表用尽时，会使用页面替换算法来选择将内存中的93个页面之一替换为第94个页面，以此类推。当进程终止时，这93个帧将再次被放置在空闲帧列表上。</p>
<p>这种简单策略有许多变体。我们可以要求操作系统从空闲帧列表中分配所有的缓冲区和表空间。当操作系统不使用这些空间时，它可以用于支持用户分页。我们可以尝试始终在空闲帧列表中保留三个空闲帧。因此，当发生页面错误时，可以使用一个空闲帧进行分页。在进行页面交换时，可以选择替换页面，然后将其写入磁盘，而用户进程继续执行。还有其他变体也是可能的，<strong>但基本策略是清楚的：为用户进程分配任何空闲帧</strong>。</p>
<h3 id="最小帧数">最小帧数</h3>
<p>最少分配最低数量的帧的一个原因涉及性能。显然，随着分配给每个进程的帧数减少，页面错误率会增加，从而减慢进程执行速度。此外，在执行指令尚未完成时发生页面错误时，必须重新启动该指令。<strong>因此，我们必须有足够的帧来容纳任何单个指令可能引用的所有不同页面</strong>。</p>
<p>例如，考虑一台机器，其中所有的内存引用指令可能只引用一个内存地址。在这种情况下，我们至少需要一个帧用于指令，一个帧用于内存引用。此外，如果允许一级间接寻址（例如，对于在页面16上的加载指令可以引用页面0上的地址，这是对页面23的间接引用），那么分页需要每个进程至少三个帧。想象一下如果一个进程只有两个帧会发生什么。</p>
<p><strong>最小帧数由计算机体系结构定义</strong>。例如，PDP-11的移动指令对于某些寻址模式包含多个字，因此指令本身可能横跨两个页面。此外，它的两个操作数可能是间接引用，总共需要六个帧。另一个例子是IBM 370的MVC指令。由于该指令是从存储位置到存储位置，它占据6个字节，可能横跨两个页面。要移动的字符块和要移动到的区域也可能各自横跨两个页面。这种情况需要六个帧。当MVC指令是EXECUTE指令的操作数，而EXECUTE指令横跨页面边界时，情况最糟，这种情况下需要八个帧。</p>
<p>最坏情况发生在允许多级间接寻址的计算机体系结构中（例如，每个16位字可以包含一个15位地址加上一个1位间接指示器）。理论上，一个简单的加载指令可以引用一个间接地址，该地址可以引用另一个页面上的间接地址，依此类推，直到虚拟内存中的每个页面都被访问。因此，在最坏的情况下，整个虚拟内存必须存在于物理内存中。为了克服这个困难，我们必须对间接级别设置限制（例如，将指令的间接级别限制在最多16级）。<strong>当第一次间接引用发生时，一个计数器被设置为16；对于该指令的每个后续间接引用，计数器都会递减。如果计数器递减到0，则会触发陷阱</strong>。这种限制将指令中每条的最大内存引用次数减少到17，需要相同数量的帧。</p>
<p>虽然每个进程的最小帧数由体系结构定义，但最大帧数由可用物理内存量定义。在这之间，我们仍然有很大的选择余地来进行帧分配。</p>
<h3 id="分配算法">分配算法</h3>
<p>最简单的将 m 个帧分配给 n 个进程的方法是给每个进程平均分配 m/n 个帧（暂时忽略操作系统所需的帧）。例如，如果有 93 个帧和五个进程，则每个进程将获得 18 个帧。剩下的三个帧可以用作自由帧缓冲池。<strong>这种方案称为等量分配</strong>equal allocation。</p>
<p><strong>另一种选择是意识到各个进程将需要不同数量的内存</strong>。考虑一个帧大小为 1 KB 的系统。如果一个小型学生进程占用 10 KB，而一个交互式数据库占用 127 KB，在一个有 62 个空闲帧的系统中，给每个进程分配 31 个帧并不合理。</p>
<p>为了解决这个问题，我们可以使用<strong>比例分配</strong>proportional allocation，根据进程的大小分配可用内存。设进程 pi 的虚拟内存大小为 si，定义 S = Σ si。 然后，如果总可用帧数为 m，则将 ai 个帧分配给进程 pi，其中 ai 大约为 ai = si/S × m。当然，我们必须将每个 ai 调整为一个整数，该整数大于指令集所需的最小帧数，并且总和不超过 m。</p>
<p>在等量分配和比例分配中，<strong>分配当然可能会根据多道程序设计水平而变化</strong>。如果增加了多道程序设计水平，每个进程都会失去一些帧以提供新进程所需的内存。相反，如果多道程序设计水平降低，分配给已离开的进程的帧可以分配给其余的进程。</p>
<p>请注意，无论是等量分配还是比例分配，高优先级进程都会和低优先级进程被同等对待。然而，根据定义，我们可能希望给予高优先级进程更多的内存以加速其执行，而对低优先级进程产生不利影响。一种解决方案是使用比例分配方案，其中帧的比例取决于进程的优先级而不是相对大小，或者取决于大小和优先级的组合。</p>
<h3 id="全局分配-vs-本地分配">全局分配 vs 本地分配</h3>
<p>**另一个影响帧分配给各个进程方式的重要因素是页面置换。**在多个进程竞争帧的情况下，我们可以将页面置换算法分类为两类：全局置换和局部置换。<strong>全局置换允许一个进程从所有帧的集合中选择一个替换帧，即使该帧当前已分配给另一个进程</strong>。<strong>局部置换要求每个进程仅从自己分配的帧集合中进行选择</strong>。</p>
<p>例如，考虑一种分配方案，其中我们允许高优先级进程从低优先级进程中选择帧进行替换。一个进程可以从自己的帧或任何低优先级进程的帧中选择替换。这种方法允许高优先级进程以牺牲低优先级进程为代价增加其帧分配量。使用局部置换策略，分配给一个进程的帧数不会改变。而使用全局置换时，一个进程可能只会选择已分配给其他进程的帧，从而增加其分配给它的帧数（假设其他进程不选择它的帧进行替换）。</p>
<p><strong>全局替换算法的一个问题是，一个进程无法控制自己的页面错误率</strong>。一个进程在内存中的页面集合不仅取决于该进程的页面行为，还取决于其他进程的页面行为。因此，同一个进程可能会因为完全外部的情况而表现出不同的性能（例如，一次执行需要0.5秒，而下一次执行需要10.3秒）。而使用局部替换算法则不会出现这种情况。在局部替换下，一个进程在内存中的页面集合仅受该进程的页面行为影响。然而，局部替换可能会通过不向进程提供其他不常用的页面来妨碍进程。因此，全局替换通常会导致更高的系统吞吐量，因此更常用。</p>
<h3 id="Non-Uniform-Memory-Access-NUMA">Non-Uniform Memory Access(NUMA)</h3>
<p>到目前为止，在我们对虚拟内存的覆盖范围中，我们假设所有的主存储器都是相等的——或者至少是平等地访问的。然而，在许多计算机系统中，并非如此。通常情况下，在具有多个CPU的系统中，<strong>给定的CPU可以比其他部分更快地访问某些主存储器部分</strong>。这些性能差异是由CPU和存储器在系统中的连接方式引起的。通常情况下，这样的系统由多个系统板组成，每个系统板包含多个CPU和一些内存。这些系统板之间的连接方式各不相同，从系统总线到高速网络连接都有。<strong>位于特定系统板上的CPU可以比在系统中其他板上的内存访问内存时的延迟要小</strong>。<strong>内存访问时间差异明显的系统统称为非一致性存储访问（NUMA）系统</strong>，毫无例外，它们比内存和CPU位于同一主板上的系统更慢。</p>
<p>在NUMA系统中，<strong>管理哪些页面框架存储在哪些位置可以显着影响性能</strong>。如果我们在这样的系统中将内存视为均匀的，那么与修改内存分配算法以考虑NUMA的情况相比，CPU可能会等待更长时间以访问内存。调度系统必须进行类似的更改。这些更改的目标是使内存框架“尽可能接近”于运行进程的CPU。 “接近”的定义是“具有最小的延迟”，通常意味着与CPU位于同一系统板上。 算法上的更改包括使调度程序跟踪每个进程上次运行的最后一个CPU。如果调度程序尝试将每个进程调度到其先前的CPU，并且内存管理系统尝试将页面框架分配给接近所调度的CPU的进程，那么将会产生改善的缓存命中率和减少的内存访问时间。</p>
<h2 id="抖动">抖动</h2>
<p><strong>如果分配给低优先级进程的页面数低于计算机体系结构所需的最小数量，那么我们必须暂停该进程的执行</strong>。然后，我们应该将其余页面换出，释放所有已分配的页面。这一规定引入了一种中间CPU调度级别的换入换出。 实际上，看任何没有“足够”页面的进程。如果该进程没有足够的页面来支持活跃使用的页面，它将很快发生页面错误。此时，它必须替换某些页面。然而，由于它的所有页面都在活跃使用中，它必须立即替换一个将再次需要的页面。因此，它很快又发生了故障，一次又一次地替换页面。</p>
<p>这种高频繁的页面交换活动称为抖动tharshing。<strong>如果一个进程花费的时间用于页面交换比执行还要多，那么这个进程就是在抖动</strong>。</p>
<h3 id="抖动原因">抖动原因</h3>
<p>抖动会导致严重的性能问题。考虑以下场景，这是基于早期分页系统的实际行为。 操作系统监视CPU利用率。如果CPU利用率过低，我们会通过引入一个新进程来增加多道程序设计的程度。使用全局页面替换算法；它替换页面时不考虑它们所属的进程。现在假设一个进程进入了执行的新阶段并需要更多的帧。它开始发生故障并从其他进程那里取走帧。然而，这些进程需要这些页面，因此它们也发生故障，并从其他进程那里取走帧。这些发生故障的进程必须使用分页设备进行页面交换。当它们排队等待分页设备时，就绪队列就会清空。当进程等待分页设备时，CPU利用率下降。 CPU调度程序看到CPU利用率下降，因此增加了多道程序设计的程度。新进程试图通过从运行中的进程中获取帧来启动，导致更多的页面故障和更长的分页设备队列。结果，CPU利用率进一步下降，CPU调度程序试图进一步增加多道程序设计的程度。<strong>发生了抖动，系统吞吐量急剧下降</strong>。页面故障率大大增加。因此，有效的内存访问时间增加。没有进行任何工作，因为进程花费了所有时间来进行分页。</p>
<img src="/2024/03/26/virtual-memory/Users\Micheal\AppData\Roaming\Typora\typora-user-images\image-20240330153030478.png" alt="image-20240330153030478" style="zoom:50%;">
<p>随着多道程序设计的程度增加，CPU利用率也会增加，尽管增长速度变慢，直到达到最大值。<strong>如果进一步增加多道程序设计的程度，抖动就会开始，并且CPU利用率会急剧下降</strong>。在这一点上，为了增加CPU利用率并停止抖动，我们必须减少多道程序设计的程度。</p>
<p><strong>我们可以通过使用本地替换算法（或优先级替换算法）来限制抖动的影响</strong>。使用本地替换算法时，如果一个进程开始抖动，它就无法从另一个进程那里窃取帧并导致后者也抖动。然而，问题并没有完全解决。如果进程在抖动，它们大部分时间都会排队等待分页设备。由于分页设备的平均队列时间更长，页面错误的平均服务时间会增加。因此，即使是一个没有抖动的进程，其有效访问时间也会增加。</p>
<p>为了防止抖动，我们必须为一个进程提供它所需的尽可能多的帧。但是我们如何知道它需要多少帧呢？有几种技术可以做到这一点。工作集策略首先查看一个进程实际使用了多少帧。该方法定义了进程执行的局部性模型。局部性模型表明，当一个进程执行时，它会从一个局部性移动到另一个。局部性是一组一起被活跃使用的页面。一个程序通常由几个不同的局部性组成，这些局部性locality可能会重叠。</p>
<img src="/2024/03/26/virtual-memory/Users\Micheal\AppData\Roaming\Typora\typora-user-images\image-20240330154126336.png" alt="image-20240330154126336" style="zoom:33%;">
<p>例如，当调用一个函数时，它定义了一个新的局部性。在这个局部性中，会对函数调用的指令、其本地变量以及全局变量的子集进行内存引用。当我们退出函数时，进程离开了这个局部性，因为函数的局部变量和指令不再活跃使用。我们可能会稍后返回到这个局部性。</p>
<p><strong>因此，我们可以看到，局部性是由程序结构及其数据结构定义的</strong>。局部性模型表明，所有的程序都会展现出这种基本的内存引用结构。请注意，局部性模型是本书迄今讨论缓存的未明确说明的原则。如果对任何类型的数据的访问是随机的而不是有模式的，那么缓存将毫无用处。假设我们为一个进程分配了足够多的帧来容纳其当前的局部性。它将因局部性中的页面而出现页面错误，直到所有这些页面都在内存中；然后，在它改变局部性之前，它将不会再出现页面错误。如果我们没有分配足够多的帧来容纳当前局部性的大小，那么进程将出现抖动，因为它无法将所有正在活跃使用的页面保留在内存中。</p>
<h3 id="工作集模型">工作集模型</h3>
<p><strong>如前所述，工作集模型基于局部性的假设</strong>。该模型使用一个参数，表示工作集窗口。<strong>其思想是检查最近的个页面引用</strong>。最近的个页面引用中的页面集合是工作集。如果一个页面正在活跃使用，则它将位于工作集中。如果不再使用，则在其上一次引用后经过个时间单位后，它将从工作集中删除。因此，工作集是程序局部性的一个近似值。例如，下图中显示的内存引用序列，如果个内存引用，则在时间 t1 时的工作集为 {1, 2, 5, 6, 7}。到时间 t2 时，工作集已变为 {3, 4}。工作集的准确性取决于的选择。如果太小，它将无法涵盖整个局部性；如果太大，它可能会重叠几个局部性。在极端情况下，如果为无穷大，则工作集是在进程执行期间访问的页面集合。</p>
<img src="/2024/03/26/virtual-memory/Users\Micheal\AppData\Roaming\Typora\typora-user-images\image-20240330154407090.png" alt="image-20240330154407090" style="zoom:50%;">
<p>因此，工作集最重要的属性是其大小。如果我们为系统中的每个进程计算工作集大小 WSSi，那么我们可以考虑到 D=∑WSSi, 其中 D 是对页面帧的总需求。每个进程都在活跃使用其工作集中的页面。因此，进程 i 需要 WSSi个页面帧。如果总需求大于可用页面帧的总数（D&gt;m），则会发生抖动，因为某些进程将没有足够的页面帧。 一旦选择了 ω，使用工作集模型就很简单了。操作系统监视每个进程的工作集，并为该工作集分配足够的页面帧，以满足其工作集大小。如果有足够多的额外页面帧，则可以启动另一个进程。如果工作集大小之和增加，超过了可用页面帧的总数，则操作系统会选择一个进程进行挂起。该进程的页面将被写出（交换），其页面帧将被重新分配给其他进程。挂起的进程可以稍后重新启动。</p>
<p>这种工作集策略可以防止抖动，同时保持尽可能高的多道程序设计程度。因此，它优化了 CPU 利用率。<strong>工作集模型的困难在于跟踪工作集</strong>。工作集窗口是一个移动窗口。在每个内存引用时，一个新的引用出现在其中一个端点，最老的引用从另一个端点消失。如果一个页面在工作集窗口中的任何位置被引用，则它就在工作集中。</p>
<p><strong>我们可以用一个固定间隔的定时器中断和一个引用位来近似工作集模型</strong>。例如，假设  ▲等于 10,000 次引用，并且我们可以在每 5,000 次引用时触发一个定时器中断。当我们收到一个定时器中断时，我们会复制并清除每个页面的引用位值。因此，如果发生页面错误，我们可以检查当前的引用位和内存中的两个位，以确定一个页面是否在最近的 10,000 到 15,000 次引用中被使用过。如果它被使用过，这些位中至少有一个会被打开。如果它没有被使用过，这些位会关闭。至少有一个位打开的页面将被视为在工作集中。</p>
<p>需要注意的是，这种安排并不完全准确，因为我们无法确定在 5,000 次引用内引用发生的位置。我们可以通过增加历史位和中断频率（例如，每 1,000 次引用一个中断和 10 位）来减少不确定性。<strong>然而，为了处理这些更频繁的中断，服务的成本也将相应增加</strong>。</p>
<h3 id="页面错误频率">页面错误频率</h3>
<p>工作集模型取得了成功，了解工作集对于预取页面也可能非常有用，但它似乎是一种笨拙的控制抖动的方法。<strong>使用页面错误频率（PFF）的策略采取了更直接的方法</strong>。</p>
<p>抖动会导致页面错误率高。因此，我们希望控制页面错误率。当页面错误率过高时，我们知道该进程需要更多帧。相反，如果页面错误率过低，则进程可能拥有太多帧。<strong>我们可以为所需的页面错误率建立上下限</strong>。如果实际页面错误率超过上限，我们为进程分配另一个帧。如果页面错误率低于下限，则从进程中删除一个帧。因此，我们可以直接测量和控制页面错误率以防止抖动。</p>
<img src="/2024/03/26/virtual-memory/Users\Micheal\AppData\Roaming\Typora\typora-user-images\image-20240330155620790.png" alt="image-20240330155620790" style="zoom:50%;">
<p>与工作集策略类似，我们可能需要交换出一个进程。如果页面错误率增加且没有空闲帧可用，我们必须选择某些进程并将其交换到后备存储。然后，释放的帧将分配给页面错误率高的进程。</p>
<blockquote>
<p>实际上，磁盘交换引起的抖动对性能影响很大。在实施计算机设施时，当前的最佳实践是尽可能提供足够的物理内存，以避免抖动和交换。从智能手机到大型机，除非在极端情况下，提供足够的内存以同时保持所有工作集在内存中，可以为用户提供最佳的使用体验。</p>
</blockquote>
<h2 id="Memory-Mapped-Files">Memory-Mapped Files</h2>
<p>考虑使用标准系统调用 open()、read() 和 write() 对磁盘上的文件进行顺序读取。每个文件访问都需要一个系统调用和磁盘访问。另外，我们可以利用到目前为止讨论的虚拟内存技术，将文件 I/O 视为常规的内存访问。<strong>这种方法被称为内存映射文件，它允许将虚拟地址空间的一部分与文件逻辑关联起来</strong>。正如我们将要看到的，这可以显著提高性能。</p>
<h3 id="基本机制">基本机制</h3>
<p><strong>内存映射文件通过将磁盘块映射到内存中的一个页面（或多个页面）来实现</strong>。对文件的初始访问通过普通的需求分页进行，导致页面错误。然而，文件的一页大小的部分被从文件系统读入到物理页面（一些系统可能选择一次读入多于一页大小的内存块）。对文件的后续读写操作被处理为常规的内存访问。通过内存而不是使用 read() 和 write() 系统调用的开销来操作文件，简化了文件访问和使用，并提高了速度。</p>
<p><strong>需要注意的是，对内存中映射的文件的写入不一定是立即的（同步的）写入到磁盘上的文件</strong>。一些系统可能选择在操作系统定期检查内存中的页面是否已修改时更新物理文件。当文件关闭时，所有内存映射的数据都被写回磁盘，并从进程的虚拟内存中移除。</p>
<p><strong>多个进程可以同时映射同一个文件，以实现数据的共享</strong>。任何一个进程的写操作都会修改虚拟内存中的数据，并且可以被所有映射了同一文件段的其他进程看到。通过我们之前对虚拟内存的讨论，应该清楚内存映射段的共享是如何实现的：每个共享进程的虚拟内存映射指向同一物理内存页面，即保存着磁盘块副本的页面。内存映射系统调用还可以支持写时复制功能，允许进程以只读模式共享文件，但在修改任何数据时拥有自己的副本。为了协调对共享数据的访问，涉及的进程可能会使用互斥机制。</p>
<img src="/2024/03/26/virtual-memory/Users\Micheal\AppData\Roaming\Typora\typora-user-images\image-20240330162419553.png" alt="image-20240330162419553" style="zoom:50%;">
<p>通常情况下，共享内存实际上是通过内存映射文件实现的。在这种情况下，进程可以通过将通信进程将同一个文件映射到它们的虚拟地址空间来进行通信。<strong>内存映射文件充当了通信进程之间的共享内存区域</strong>。</p>
<p>​	<img src="/2024/03/26/virtual-memory/Users\Micheal\AppData\Roaming\Typora\typora-user-images\image-20240330162647325.png" alt="image-20240330162647325" style="zoom:50%;"></p>
<h3 id="Memory-Mapped-I-O">Memory-Mapped I/O</h3>
<p>在I/O方面，每个I/O控制器都包括用于保存命令和正在传输的数据的寄存器。通常，特殊的I/O指令允许在这些寄存器和系统内存之间进行数据传输。为了更方便地访问I/O设备，<strong>许多计算机体系结构提供了内存映射I/O</strong>。在这种情况下，一段内存地址范围被保留，并映射到设备寄存器。对这些内存地址进行读写会导致数据与设备寄存器之间的传输。这种方法适用于具有快速响应时间的设备，例如视频控制器。在IBM PC上，屏幕上的每个位置都映射到一个内存位置。在屏幕上显示文本几乎和将文本写入适当的内存映射位置一样简单。</p>
<p><strong>内存映射I/O对于连接调制解调器和打印机等其他设备的串行和并行端口也很方便</strong>。CPU通过读写几个设备寄存器（称为I/O端口）来通过这些设备传输数据。要通过内存映射的串行端口发送一长串字节，CPU将一个数据字节写入数据寄存器，并设置控制寄存器中的一个位来表示该字节可用。设备接收数据字节，然后清除控制寄存器中的位，以表示它已准备好接收下一个字节。然后CPU可以传输下一个字节。如果CPU使用轮询来监视控制位，不断地循环以查看设备是否准备就绪，这种操作方法称为programmed I/O（PIO）。如果CPU不轮询控制位，而是在设备准备好接收下一个字节时接收到中断，则数据传输被称为中断驱动interrupt driven。</p>
<h2 id="分配内核内存">分配内核内存</h2>
<p>当运行在用户模式下的进程请求额外的内存时，<strong>页面将从内核维护的空闲页面帧列表中分配</strong>。这个列表通常是通过页面替换算法来填充的，并且很可能包含分散在物理内存中的空闲页面。此外，<strong>如果用户进程请求一个字节的内存，将会产生内部碎片，因为进程将被授予整个页面帧</strong>。<br>
内核内存通常从一个与用于满足普通用户模式进程的列表不同的空闲内存池中分配。这主要有两个原因：</p>
<ol>
<li>内核请求的内存用于各种大小的数据结构，其中一些大小小于一页。因此，内核必须谨慎使用内存，并尽量减少由于碎片化而造成的浪费。这一点尤为重要，因为许多操作系统不会将内核代码或数据置于分页系统中。</li>
<li>分配给用户模式进程的页面不一定需要在连续的物理内存中。然而，某些硬件设备直接与物理内存交互——没有虚拟内存接口的好处——因此可能需要驻留在物理连续页面中的内存。</li>
</ol>
<h3 id="Buddy-system">Buddy system</h3>
<p>伙伴系统从一个由物理上连续的页面组成的固定大小段中分配内存。内存是使用一个以2的幂为单位的分配器从这个段中分配的，该分配器按2的幂大小的单位满足请求（例如4 KB、8 KB、16 KB等）。以不合适大小的单位发出的请求会向上舍入到最接近的2的幂。例如，对于11 KB的请求，会使用一个16 KB的段来满足。</p>
<p>让我们考虑一个简单的例子。假设内存段的大小最初为256 KB，内核请求21 KB的内存。该段最初被划分为两个伙伴——我们将其称为AL和AR，每个128 KB大小。其中一个伙伴进一步划分为两个64 KB的伙伴——BL和BR。然而，从21 KB到最接近的2的幂是32 KB，因此BL或BR中的一个再次被划分为两个32 KB的伙伴，CL和CR。其中一个伙伴用于满足21 KB的请求，其中CL是分配给21 KB请求的段。</p>
<img src="/2024/03/26/virtual-memory/Users\Micheal\AppData\Roaming\Typora\typora-user-images\image-20240330164105428.png" alt="image-20240330164105428" style="zoom:50%;">
<p><strong>伙伴系统的一个优点是，使用一种称为合并的技术，可以很快地将相邻的伙伴组合成更大的段</strong>。例如，当内核释放其分配的CL单元时，系统可以将CL和CR合并成一个64 KB的段。这个段BL，可以进一步与其伙伴BR合并，形成一个128 KB的段。最终，我们可以得到原始的256 KB段。</p>
<p>伙伴系统的明显缺点是，<strong>将大小向上舍入到下一个最高的2的幂很可能会导致分配的段内部发生碎片化</strong>。例如，一个33 KB的请求只能用一个64 KB的段来满足。事实上，我们无法保证分配的单元少于50%的空间会因为内部碎片而浪费掉。在接下来的部分中，我们将探讨一种内存分配方案，其中没有因碎片化而导致的空间浪费。</p>
<h3 id="slab-allocation">slab allocation</h3>
<p>第二种内核内存分配策略称为“slab分配”。<strong>一个slab由一个或多个物理连续的页面组成。一个cache包含一个或多个slab。对于每个唯一的内核数据结构，都有一个单独的cache</strong>，例如，一个用于表示进程描述符的数据结构的单独cache，一个用于文件对象的单独cache，一个用于信号量的单独cache，依此类推。每个cache都填充有实例化为该cache表示的内核数据结构的对象。例如，表示信号量的cache存储信号量对象的实例，表示进程描述符的cache存储进程描述符对象的实例，依此类推。slab、cache和对象之间的关系如下图所示。图中显示了两个大小为3 KB的内核对象和三个大小为7 KB的对象，每个对象都存储在单独的cache中。</p>
<img src="/2024/03/26/virtual-memory/Users\Micheal\AppData\Roaming\Typora\typora-user-images\image-20240330164506603.png" alt="image-20240330164506603" style="zoom:50%;">
<p>slab分配算法使用cache来存储内核对象。当创建一个cache时，一些对象被分配给该cache，并且最初被标记为free。cache中的对象数量取决于关联slab的大小。例如，一个12KB的slab（由三个连续的4KB页面组成）可以存储六个2KB的对象。最初，cache中的所有对象都被标记为自由。当需要一个新的内核数据结构对象时，分配器可以分配cache中的任何自由对象来满足请求。从cache分配的对象被标记为已使用。</p>
<p><strong>让我们考虑这样一个场景：内核向slab分配器请求内存，以获取表示进程描述符的对象</strong>。在Linux系统中，进程描述符的类型是struct task_struct，大约需要1.7 KB的内存。当Linux内核创建一个新任务时，它会从其cache中请求所需内存以获取struct task_struct对象。cache将使用一个已经在slab中分配并标记为自由的struct task_struct对象来满足请求。</p>
<p>在Linux中，一个slab可以处于以下三种可能的状态之一：</p>
<ol>
<li>Full。slab中的所有对象都被标记为已使用。</li>
<li>Empty。slab中的所有对象都被标记为free。</li>
<li>Partial。slab包含已使用和free对象。</li>
</ol>
<p>slab分配器首先尝试从部分slab中的空闲对象中满足请求。如果不存在空闲对象，则从空slab中分配一个空闲对象。如果没有可用的空slab，则从连续的物理页面中分配一个新的slab，并分配给一个cache；对象的内存从这个slab中分配。</p>
<p>slab分配器提供了两个主要好处：</p>
<ol>
<li>由于每个唯一的内核数据结构都有一个关联的缓存，而每个缓存由一个或多个slab组成，这些slab被划分为与所表示对象大小相同的块，<strong>因此不存在由于碎片化而浪费内存的问题</strong>。因此，当内核请求内存以表示对象时，slab分配器返回所需内存的确切量。</li>
<li><strong>内存请求可以快速满足</strong>。slab分配方案在管理内存时特别有效，因为内核经常会请求分配和释放对象，这是常见的情况。分配和释放内存的行为可能是耗时的过程。然而，对象是提前创建的，因此可以从缓存中快速分配。此外，当内核使用完一个对象并释放它时，它会被标记为自由，并返回到其缓存中，因此可以立即供内核的后续请求使用。</li>
</ol>
<p>从Linux内核2.6.24版本开始，SLUB分配器取代SLAB成为默认的分配器。<strong>SLUB通过减少SLAB分配器所需的大部分开销来解决slab分配的性能问题</strong>。一个改变是将在SLAB分配下与每个slab存储的元数据移动到Linux内核用于每个页面的页面结构中。此外，SLUB移除了SLAB分配器为每个缓存中的对象维护的 per CPU队列。对于拥有大量处理器的系统来说，分配给这些队列的内存量是相当可观的。因此，随着系统中处理器数量的增加，SLUB提供了更好的性能。</p>
<h2 id="其他考量">其他考量</h2>
<h3 id="prepaging">prepaging</h3>
<p>纯需求分页的一个明显特点是在启动进程时会发生大量的页面错误。这种情况是由于尝试将初始局部性装入内存而导致的。同样的情况可能在其他时候也会出现。例如，当重新启动一个被交换出的进程时，它的所有页面都在磁盘上，每个页面都必须通过自己的页面错误来带入内存。<strong>预取页是为了防止这种高水平的初始分页而采取的一种尝试</strong>。该策略是一次性将所有需要的页面带入内存。一些操作系统，特别是Solaris，会为小文件的页面帧进行预分页。 在使用工作集模型的系统中，例如，我们可以为每个进程保留一个其工作集中页面的列表。如果我们必须暂停一个进程（由于I/O等待或缺少空闲页面），我们会记住该进程的工作集。当进程要被恢复时（因为I/O已经完成或者足够的空闲页面已经可用），我们会在重新启动进程之前自动将其整个工作集带回内存。</p>
<p>预取页在某些情况下可能会带来优势。<strong>问题只是使用预取页的成本是否比处理相应的页面错误的成本低</strong>。很可能许多由预取页带回内存的页面将不会被使用。 假设预取了 s 个页面，并且其中的一部分  实际上被使用了（0 ≤  ≤ 1）。问题是 s*  a个节省的页面错误的成本是否大于或小于预取 s*（1− a ）个不必要的页面的成本。如果 a 接近于 0，那么预取失败；如果a 接近于 1，那么预取成功。</p>
<h3 id="Page-Size">Page Size</h3>
<p>现有机器的操作系统设计者很少有选择页面大小的机会。然而，当设计新的机器时，必须对最佳页面大小做出决定。正如你所预料的那样，没有单一的最佳页面大小。相反，有一系列因素支持各种大小。页面大小通常是2的幂，通常范围从4,096（2^12）到4,194,304（2^22）字节。</p>
<p>我们如何选择页面大小？一个考虑因素是页表的大小。对于给定的虚拟内存空间，减小页面大小会增加页面数量，因此增加了页表的大小。例如，对于一个4 MB（2^22）的虚拟内存，将有4,096个1,024字节大小的页面，但只有512个8,192字节大小的页面。<strong>因为每个活动进程都必须有自己的页表副本，所以较大的页面大小是可取的</strong>。</p>
<p><strong>然而，使用较小的页面可以更好地利用内存</strong>。如果一个进程从位置00000开始分配内存，并持续分配直到满足其需要，那么它可能不会正好结束在一个页面边界上。因此，最后一页的一部分必须被分配（因为页面是分配的单位），但将不会被使用（造成内部碎片）。假设进程大小和页面大小是独立的，我们可以预期，每个进程的最后一页平均将浪费一半。对于一个512字节的页面，这种损失只有256字节，但对于一个8,192字节的页面，这种损失就是4,096字节。为了最小化内部碎片，我们需要一个较小的页面大小。</p>
<p>另一个问题是读取或写入一个页面所需的时间。<strong>I/O 时间由搜索、延迟和传输时间组成</strong>。传输时间与传输的量成正比（即页面大小）——这一事实似乎支持使用较小的页面大小。然而，延迟时间和搜索时间通常会远远超过传输时间。以每秒2 MB的传输速率为例，传输512字节只需要0.2毫秒。然而，延迟时间可能是8毫秒，搜索时间是20毫秒。因此，总的 I/O 时间（28.2毫秒）中，只有1%归因于实际的传输。将页面大小加倍只会将 I/O 时间增加到28.4毫秒。读取1024字节大小的单个页面需要28.4毫秒，但读取两个页面，每个页面大小为512字节，需要56.4毫秒。因此，希望最小化 I/O 时间支持使用较大的页面大小。</p>
<p><strong>然而，较小的页面大小应该会减少总的 I/O，因为局部性将会得到改善</strong>。较小的页面大小使每个页面更准确地与程序的局部性匹配。例如，考虑一个大小为200 KB的进程，其中只有一半（100 KB）在执行中实际使用。如果我们只有一个大页面，我们必须将整个页面带入内存，总共传输和分配200 KB。相反，如果我们只有1字节大小的页面，那么我们只需要带入实际使用的100 KB，结果只需要传输和分配100 KB。因此，较小的页面大小使我们有更好的分辨率，允许我们隔离出实际需要的内存。而较大的页面大小，我们不仅需要分配和传输所需的内容，还需要分配和传输页面中的任何其他内容，无论是否需要。因此，较小的页面大小应该会导致更少的 I/O 和更少的总分配内存。</p>
<p><strong>但你是否注意到，如果页面大小为1字节，我们将为每个字节生成一个页面错误</strong>？一个只使用了一半内存的200 KB进程在页面大小为200 KB时只会生成一个页面错误，但在页面大小为1字节时会生成102,400个页面错误。每个页面错误都会产生大量的开销，需要处理中断、保存寄存器、替换页面、排队等待页面设备以及更新表格。为了最小化页面错误的数量，我们需要有较大的页面大小。</p>
<p>还必须考虑其他因素（例如页面大小与分页设备上扇区大小之间的关系）。这个问题没有最佳答案。正如我们所见，一些因素（内部碎片、局部性）支持较小的页面大小，而另一些因素（表格大小、I/O 时间）支持较大的页面大小。然而，<strong>历史趋势是朝着更大的页面大小发展</strong>，即使是对于移动系统也是如此。</p>
<h3 id="TLB-Reach">TLB Reach</h3>
<p>TLB的命中率指的是在TLB而不是页面表中解析的虚拟地址转换的百分比。显然，命中率与TLB中的条目数相关，提高命中率的方法是增加TLB中的条目数。然而，这并不是廉价的，<strong>因为用于构建TLB的关联内存既昂贵又耗电量大</strong>。</p>
<p>与命中率相关的是一个类似的指标：TLB覆盖范围（TLB reach）。TLB覆盖范围指的是从TLB可访问的内存量，简单地说，<strong>就是条目数乘以页面大小</strong>。理想情况下，进程的工作集应存储在TLB中。如果没有存储在其中，进程将花费大量时间在页面表而不是TLB中解析内存引用。如果我们将TLB中的条目数量加倍，那么TLB的覆盖范围也会加倍。然而，对于一些内存密集型应用程序而言，这可能仍然不足以存储工作集。</p>
<p><strong>增加TLB覆盖范围的另一种方法是增加页面大小或提供多种页面大小</strong>。如果我们增加页面大小——比如，从8 KB增加到32 KB——我们将使TLB覆盖范围增加四倍。然而，这可能会导致一些不需要如此大页面大小的应用程序出现碎片化。或者，操作系统可以提供多种不同的页面大小。例如，UltraSPARC支持8 KB、64 KB、512 KB和4 MB的页面大小。在这些可用的页面大小中，Solaris使用8 KB和4 MB页面大小。并且通过64个条目的TLB，Solaris的TLB覆盖范围从8 KB页面的512 KB到4 MB页面的256 MB不等。对于大多数应用程序来说，8 KB页面大小是足够的，尽管Solaris使用两个4 MB页面映射了内核代码和数据的前4 MB。Solaris还允许应用程序（如数据库）利用大的4 MB页面大小。</p>
<p>**提供支持多种页面大小需要操作系统而不是硬件来管理TLB。**例如，TLB条目中的一个字段必须指示与TLB条目对应的页面帧的大小。在软件中管理TLB而不是硬件会带来性能成本。然而，增加的命中率和TLB覆盖范围可以抵消性能成本。事实上，最近的趋势表明，向软件管理的TLB和操作系统支持多种页面大小的方向发展。</p>
<h3 id="倒排列表">倒排列表</h3>
<p><strong>这种页面管理形式的目的是减少跟踪虚拟地址到物理地址转换所需的物理内存量</strong>。我们通过创建一个表来实现这种节省，该表每页物理内存有一个条目，通过 &lt;进程ID，页号&gt; 这一对索引。</p>
<p>因为倒排页表保存了每个物理帧中存储了哪个虚拟内存页面的信息，所以它们减少了存储这些信息所需的物理内存量。<strong>然而，倒排页表不再包含关于进程的逻辑地址空间的完整信息</strong>，而这些信息在引用的页面当前不在内存中时是必需的。需求分页需要这些信息来处理页面错误。为了使信息可用，必须保留一个外部页表（每个进程一个）。每个这样的表看起来像传统的每个进程页表，并包含每个虚拟页面的位置信息。</p>
<p>但是外部页表是否抵消了倒排页表的效用呢？由于这些表只在发生页面错误时才被引用，它们不需要快速可用。相反，它们根据需要自身被分页进入和退出内存。不幸的是，一个页面错误现在可能会导致虚拟内存管理器生成另一个页面错误，因为它正在将其需要的外部页表分页到内存中，以定位在后备存储上的虚拟页面。这种特殊情况需要在内核中进行仔细处理，并延迟页面查找处理。</p>
<h3 id="程序结构">程序结构</h3>
<p>需求分页设计为对用户程序透明。在许多情况下，用户完全不知道内存的分页性质。然而，在其他情况下，<strong>如果用户（或编译器）了解底层的需求分页机制，系统性能可以得到改善</strong>。</p>
<p>让我们看一个刻意构造但信息丰富的例子。假设页面大小为128个字。考虑一个C程序，其功能是将一个128乘以128的数组的每个元素初始化为0。以下代码是典型的：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> i, j;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span>[<span class="number">128</span>]][<span class="number">128</span>] data;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; <span class="number">128</span>; j++)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">128</span>; i++)</span><br><span class="line"></span><br><span class="line">		data[i][j] = <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
<p>请注意，数组是按行主序存储的；也就是说，数组按顺序存储为</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="number">0</span>][<span class="number">0</span>]，data[<span class="number">0</span>][<span class="number">1</span>]，···，data[<span class="number">0</span>][<span class="number">127</span>]，data[<span class="number">1</span>][<span class="number">0</span>]，data[<span class="number">1</span>][<span class="number">1</span>]，···，data[<span class="number">127</span>][<span class="number">127</span>]</span><br></pre></td></tr></table></figure>
<p>对于每个128个字的页面，每行占用一个页面。因此，前面的代码会在每个页面中将一个字清零，然后在每个页面中将另一个字清零，依此类推。如果操作系统为整个程序分配的帧数少于128帧，则其执行将导致128 × 128 = 16,384个页面错误。相比之下，假设我们将代码更改为</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> i, j;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span>[<span class="number">128</span>][<span class="number">128</span>] data;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">128</span>; i++)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; <span class="number">128</span>; j++)</span><br><span class="line"></span><br><span class="line">		data[i][j] = <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
<p>这段代码在开始下一页之前会将一页上的所有字清零，将页面错误的数量减少到了128个。</p>
<p><strong>精心选择数据结构和编程结构可以增加局部性，从而降低页面错误率和工作集中的页面数量</strong>。例如，栈具有良好的局部性，因为访问总是发生在顶部。相比之下，哈希表设计为分散引用，产生了较差的局部性。当然，引用的局部性只是衡量数据结构使用效率的一个指标。其他具有较高权重的因素包括搜索速度、总内存引用数以及触及的总页面数。</p>
<p><strong>在后期阶段，编译器和加载器对分页可能会产生重大影响</strong>。将代码和数据分离，并生成可重入代码意味着代码页面可以是只读的，因此永远不会被修改。干净的页面不必被分页出去以进行替换。加载器可以避免将程序置于页面边界之间，使每个程序完全位于一个页面中。多次调用彼此的程序可以被打包到同一个页面中。这种打包是运筹学中操作的一种变体：<strong>尝试将可变大小的加载段打包到固定大小的页面中，以最小化页面间的引用</strong>。这种方法对于大页面大小特别有用。</p>
<h3 id="I-O互锁和页面锁定">I/O互锁和页面锁定</h3>
<p>在使用需求分页时，<strong>有时我们需要允许部分页面在内存中被锁定</strong>。这种情况之一发生在对用户（虚拟）内存进行I/O 时。I/O 通常由单独的I/O 处理器实现。例如，USB存储设备的控制器通常会给出要传输的字节数以及缓冲区的内存地址。当传输完成时，CPU会被中断。</p>
<img src="/2024/03/26/virtual-memory/Users\Micheal\AppData\Roaming\Typora\typora-user-images\image-20240331180846816.png" alt="image-20240331180846816" style="zoom:50%;">
<p>我们必须确保不会发生以下事件序列：一个进程发出一个I/O 请求，并被放入该I/O 设备的队列中。与此同时，CPU 被分配给其他进程。这些进程引起页面错误，其中一个进程使用全局替换算法替换了包含等待进程的内存缓冲区的页面。页面被分页出去。一段时间后，当I/O 请求前进到设备队列的头部时，I/O 发生在指定的地址上。<strong>然而，这个帧现在正在被另一个进程的不同页面使用</strong>。</p>
<p>有两种常见的解决方案来解决这个问题。<strong>一种解决方案是永远不要对用户内存执行I/O 操作</strong>。相反，数据总是在系统内存和用户内存之间进行复制。I/O 只在系统内存和I/O 设备之间进行。要在磁带上写一个块，我们首先将块复制到系统内存，然后再写入磁带。这种额外的复制可能会导致不可接受的高开销。 <strong>另一种解决方案是允许页面被锁定到内存中</strong>。在这里，与每个帧相关联的是一个锁定位。如果帧被锁定，它就不能被选择进行替换。在这种方法下，要在磁带上写一个块，我们会将包含该块的页面锁定到内存中。系统然后可以继续正常进行。被锁定的页面不能被替换。当I/O 完成后，这些页面将被解锁。</p>
<p><strong>锁定位在各种情况下都被使用</strong>。通常，操作系统内核被锁定到内存中。许多操作系统不能容忍由内核或特定内核模块（包括执行内存管理的模块）引起的页面错误。用户进程也可能需要将页面锁定到内存中。例如，数据库进程可能希望管理一块内存，自己移动磁盘和内存之间的块，因为它最了解如何使用数据。在内存中固定页面是相当普遍的，大多数操作系统都有一个系统调用，<strong>允许应用程序请求将其逻辑地址空间的某个区域固定在内存中</strong>。注意，这个特性可能被滥用，并且可能导致内存管理算法的压力。因此，应用程序通常需要特殊权限才能提出这样的请求。</p>
<p><strong>锁定位的另一个用途涉及正常的页面替换</strong>。考虑以下事件序列：一个低优先级进程发生页面错误。选择一个替换帧，分页系统将必要的页面读入内存。准备继续，低优先级进程进入就绪队列，并等待CPU。由于它是一个低优先级进程，可能有一段时间内不会被CPU调度程序选中。在低优先级进程等待时，一个高优先级进程发生页面错误。在寻找替换页面时，<strong>分页系统看到了一个在内存中但尚未被引用或修改的页面：它就是低优先级进程刚刚带入的页面</strong>。这个页面看起来是一个完美的替换：它是干净的，不需要写出去，而且显然已经很长时间没有被使用了。</p>
<p><strong>高优先级进程是否应该能够替换低优先级进程是一个策略决定</strong>。毕竟，我们只是为了高优先级进程的利益而推迟了低优先级进程。然而，我们浪费了为低优先级进程带入页面所花费的工作。如果我们决定在新带入的页面至少被使用一次之前阻止替换，则我们可以使用锁定位来实现这种机制。<strong>当选择一个页面进行替换时，它的锁定位被打开。它会保持打开状态，直到故障处理进程再次被调度</strong>。</p>
<p><strong>使用锁定位可能是危险的：锁定位可能被打开但从未关闭</strong>。如果发生这种情况（例如，由于操作系统中的错误），锁定的帧将变得无法使用。在单用户系统中，过度使用锁定只会影响执行锁定的用户。多用户系统必须对用户保持更少的信任。例如，Solaris允许锁定“提示”，但如果空闲帧池变得太小，或者某个单独进程请求在内存中锁定过多的页面，系统可以自由地忽略这些提示。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blackforest1990.github.io">BlackForest1990</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blackforest1990.github.io/2024/03/26/virtual-memory/">https://blackforest1990.github.io/2024/03/26/virtual-memory/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blackforest1990.github.io" target="_blank">黑暗森林</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/">内存管理</a></div><div class="post_share"><div class="social-share" data-image="/image/blackforest.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>谢谢支持</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechatpay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechatpay.jpg"/></a><div class="post-qr-code-desc"></div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/03/22/CPU%E5%AF%84%E5%AD%98%E5%99%A8/" title="CPU寄存器"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">CPU寄存器</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/03/19/mainmemory/" title="main memory"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2024-03-20</div><div class="title">main memory</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">1.</span> <span class="toc-text">背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9C%80%E6%B1%82%E5%88%86%E9%A1%B5"><span class="toc-number">2.</span> <span class="toc-text">需求分页</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">2.1.</span> <span class="toc-text">基本原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%A7%E8%83%BD"><span class="toc-number">2.2.</span> <span class="toc-text">性能</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%99%E6%97%B6%E5%A4%8D%E5%88%B6"><span class="toc-number">3.</span> <span class="toc-text">写时复制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%B5%E9%9D%A2%E6%9B%BF%E6%8D%A2"><span class="toc-number">4.</span> <span class="toc-text">页面替换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E9%A1%B5%E9%9D%A2%E6%9B%BF%E6%8D%A2"><span class="toc-number">4.1.</span> <span class="toc-text">基础页面替换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A1%B5%E9%9D%A2%E6%9B%BF%E6%8D%A2%E7%AE%97%E6%B3%95"><span class="toc-number">4.2.</span> <span class="toc-text">页面替换算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E9%85%8D%E5%B8%A7"><span class="toc-number">5.</span> <span class="toc-text">分配帧</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%B0%8F%E5%B8%A7%E6%95%B0"><span class="toc-number">5.1.</span> <span class="toc-text">最小帧数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E9%85%8D%E7%AE%97%E6%B3%95"><span class="toc-number">5.2.</span> <span class="toc-text">分配算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E5%B1%80%E5%88%86%E9%85%8D-vs-%E6%9C%AC%E5%9C%B0%E5%88%86%E9%85%8D"><span class="toc-number">5.3.</span> <span class="toc-text">全局分配 vs 本地分配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Non-Uniform-Memory-Access-NUMA"><span class="toc-number">5.4.</span> <span class="toc-text">Non-Uniform Memory Access(NUMA)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%96%E5%8A%A8"><span class="toc-number">6.</span> <span class="toc-text">抖动</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8A%96%E5%8A%A8%E5%8E%9F%E5%9B%A0"><span class="toc-number">6.1.</span> <span class="toc-text">抖动原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%A5%E4%BD%9C%E9%9B%86%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.2.</span> <span class="toc-text">工作集模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A1%B5%E9%9D%A2%E9%94%99%E8%AF%AF%E9%A2%91%E7%8E%87"><span class="toc-number">6.3.</span> <span class="toc-text">页面错误频率</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Memory-Mapped-Files"><span class="toc-number">7.</span> <span class="toc-text">Memory-Mapped Files</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%9C%BA%E5%88%B6"><span class="toc-number">7.1.</span> <span class="toc-text">基本机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Memory-Mapped-I-O"><span class="toc-number">7.2.</span> <span class="toc-text">Memory-Mapped I&#x2F;O</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E9%85%8D%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98"><span class="toc-number">8.</span> <span class="toc-text">分配内核内存</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Buddy-system"><span class="toc-number">8.1.</span> <span class="toc-text">Buddy system</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#slab-allocation"><span class="toc-number">8.2.</span> <span class="toc-text">slab allocation</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E8%80%83%E9%87%8F"><span class="toc-number">9.</span> <span class="toc-text">其他考量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#prepaging"><span class="toc-number">9.1.</span> <span class="toc-text">prepaging</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Page-Size"><span class="toc-number">9.2.</span> <span class="toc-text">Page Size</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TLB-Reach"><span class="toc-number">9.3.</span> <span class="toc-text">TLB Reach</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%80%92%E6%8E%92%E5%88%97%E8%A1%A8"><span class="toc-number">9.4.</span> <span class="toc-text">倒排列表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A8%8B%E5%BA%8F%E7%BB%93%E6%9E%84"><span class="toc-number">9.5.</span> <span class="toc-text">程序结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#I-O%E4%BA%92%E9%94%81%E5%92%8C%E9%A1%B5%E9%9D%A2%E9%94%81%E5%AE%9A"><span class="toc-number">9.6.</span> <span class="toc-text">I&#x2F;O互锁和页面锁定</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By BlackForest1990</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">如果只允许一种声音存在，那么，唯一存在的那个声音就是谎言。</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>