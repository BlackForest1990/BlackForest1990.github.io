<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>main memory | 黑暗森林</title><meta name="author" content="BlackForest1990"><meta name="copyright" content="BlackForest1990"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="背景 内存是现代计算机系统运行的核心。内存由大量的字节组成，每个字节都有自己的地址。CPU根据程序计数器的值从内存中获取指令。这些指令可能会导致从特定的内存地址进行额外的加载和存储。 我们从讨论与管理内存相关的几个问题开始讨论：基本硬件、符号内存地址与实际物理地址的绑定，以及逻辑地址和物理地址之间的区别。以讨论动态链接和共享库来结束这个blog。 基本硬件 主存储器和内置于处理器中的寄存器是 CP">
<meta property="og:type" content="article">
<meta property="og:title" content="main memory">
<meta property="og:url" content="https://blackforest1990.github.io/2024/03/19/mainmemory/index.html">
<meta property="og:site_name" content="黑暗森林">
<meta property="og:description" content="背景 内存是现代计算机系统运行的核心。内存由大量的字节组成，每个字节都有自己的地址。CPU根据程序计数器的值从内存中获取指令。这些指令可能会导致从特定的内存地址进行额外的加载和存储。 我们从讨论与管理内存相关的几个问题开始讨论：基本硬件、符号内存地址与实际物理地址的绑定，以及逻辑地址和物理地址之间的区别。以讨论动态链接和共享库来结束这个blog。 基本硬件 主存储器和内置于处理器中的寄存器是 CP">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blackforest1990.github.io/image/blackforest.jpg">
<meta property="article:published_time" content="2024-03-19T03:49:14.000Z">
<meta property="article:modified_time" content="2024-03-20T03:50:35.076Z">
<meta property="article:author" content="BlackForest1990">
<meta property="article:tag" content="内存管理">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blackforest1990.github.io/image/blackforest.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://blackforest1990.github.io/2024/03/19/mainmemory/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'main memory',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-20 11:50:35'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="黑暗森林" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/image/blackforest.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">21</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="黑暗森林"><span class="site-name">黑暗森林</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">main memory</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-03-19T03:49:14.000Z" title="发表于 2024-03-19 11:49:14">2024-03-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-03-20T03:50:35.076Z" title="更新于 2024-03-20 11:50:35">2024-03-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">操作系统</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="main memory"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="背景">背景</h2>
<p>内存是现代计算机系统运行的核心。内存由大量的字节组成，每个字节都有自己的地址。CPU根据程序计数器的值从内存中获取指令。这些指令可能会导致从特定的内存地址进行额外的加载和存储。</p>
<p>我们从讨论与管理内存相关的几个问题开始讨论：基本硬件、符号内存地址与实际物理地址的绑定，以及逻辑地址和物理地址之间的区别。以讨论动态链接和共享库来结束这个blog。</p>
<h3 id="基本硬件">基本硬件</h3>
<p><strong>主存储器和内置于处理器中的寄存器是 CPU 可直接访问的唯一通用存储器</strong>。有一些机器指令以内存地址作为参数，但没有以磁盘地址作为参数的指令。因此，任何正在执行的指令以及指令正在使用的任何数据都必须位于这些直接访问存储设备之一中。如果数据不在内存中，则必须将其移至内存，然后 CPU 才能对其进行操作。</p>
<p>内置于 CPU 中的寄存器通常在 CPU 时钟周期内可访问。大多数 CPU 可以以每个时钟周期一个或多个操作的速率解码指令并对寄存器内容执行简单操作。<strong>而主存储器却不能这样，它是通过内存总线进行访问的</strong>。完成内存访问可能需要许多 CPU 时钟周期。在这种情况下，处理器通常需要停顿，因为它没有完成正在执行的指令所需的数据。由于内存访问的频率，这种情况是不可容忍的。解决的方法是在 CPU 和主存储器之间添加快速存储器，通常在 CPU 芯片上以实现快速访问。<strong>为了管理内置于 CPU 中的高速缓存，硬件会自动加速内存访问，无需任何操作系统控制</strong>。</p>
<p>我们不仅关注访问物理内存的相对速度，还必须确保正确操作。为了正确运行系统，我们必须保护操作系统免受用户进程的访问。在多用户系统中，我们还必须保护用户进程免受彼此的影响。这种保护必须由硬件提供，因为操作系统通常不会介入 CPU 和其内存访问之间（由于所产生的性能损失）。</p>
<p><strong>首先，我们需要确保每个进程都拥有单独的内存空间</strong>。为了分隔内存空间，我们需要确定进程可以访问的合法地址范围，并确保进程只能访问这些合法地址。我们可以通过使用两个寄存器来提供这种保护，<strong>通常是一个基址寄存器和一个限界寄存器</strong>。基址寄存器保存最小的合法物理内存地址；限界寄存器指定了地址范围的大小。例如，如果基址寄存器保存了 300040，而限界寄存器是 120900，那么程序可以合法地访问从 300040 到 420939（包括边界）的所有地址。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319122807771.png" alt="image-20240319122807771" style="zoom:50%;">
<p><strong>通过让 CPU 硬件将用户模式下生成的每个地址与寄存器进行比较来实现对内存空间的保护</strong>。任何在用户模式下执行的程序企图访问操作系统内存或其他用户内存的尝试都会导致陷阱（trap）到操作系统，操作系统会将该尝试视为致命错误。这种方案可以防止用户程序修改操作系统或其他用户的代码或数据结构。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319123020667.png" alt="image-20240319123020667" style="zoom:40%;">
<p>base和limit寄存器只能由操作系统加载，而操作系统使用特殊的特权指令进行加载，特权指令只能在内核模式下执行。该方案允许操作系统更改寄存器的值但不允许用户程序去修改。</p>
<p><strong>在内核模式下执行的操作系统对操作系统内存和用户内存都具有无限制的访问权限</strong>。这项规定允许操作系统将用户程序加载到用户内存中，以便在出现错误时将这些程序卸载，访问和修改系统调用的参数，与用户内存进行 I/O 操作，并提供许多其他服务。例如，考虑一个多处理系统的操作系统必须执行上下文切换，在将下一个进程的上下文从主内存加载到寄存器之前，将一个进程的状态从寄存器存储到主内存中。</p>
<h3 id="地址绑定">地址绑定</h3>
<p>通常，一个程序以二进制可执行文件的形式存在于磁盘上。<strong>要执行该程序，必须将其加载到内存中，并放置到一个进程内</strong>。根据所使用的内存管理方式，在执行过程中，该进程可能会在磁盘和内存之间移动。<strong>等待被加载到内存以供执行的磁盘上的进程形成输入队列</strong>。正常的单任务处理过程是从输入队列中选择一个进程，并将该进程加载到内存中。随着进程的执行，它会从内存中访问指令和数据。最终，进程终止，其内存空间被声明为空闲。</p>
<p>大多数系统允许用户进驻驻留在物理内存的任何部分。因此，尽管计算机的地址空间可能从00000开始，但用户进程的第一个地址不一定是00000。</p>
<p>在大多数情况下，用户程序在执行前经历几个步骤：在这些步骤中，地址可以用不同方式表示。源程序中的地址通常是符号的(count), 编译器通常讲这些符号地址绑定到可重定位地址。(例如“从这个模块开头的14字节”)。链接器又将可重定向地址绑定到绝对地址(例如74014)。<strong>每个绑定都是从一个地址空间到另一个地址空间的映射</strong>。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319124434374.png" alt="image-20240319124434374" style="zoom:30%;">
<p>传统上，指令和数据与内存地址的绑定可以在沿途的任何步骤中完成：</p>
<ul>
<li><strong>编译时</strong>：如果在编译时知道进程将驻留在内存中的位置，则可以生成绝对代码。</li>
<li><strong>加载时</strong>：如果在编译时不知道进程将驻留在内存中的位置，则编译器必须生成可重定向代码。在这种情况下，最终的绑定被延迟到加载时。如果起始地址发生变化，我们只需要重新加载用户代码以将此更改的值纳入其中。</li>
<li><strong>执行时</strong>：如果进程在执行过程中可以从一个内存段移动到另一个内存段，则绑定必须延迟到运行时。为了使这种方案正常工作，必须有特殊的硬件可用。大多数通用操作系统采用这种方案。</li>
</ul>
<h3 id="逻辑空间与物理空间">逻辑空间与物理空间</h3>
<p>CPU生成的地址通常成为逻辑地址，而被内存单元看到的地址–即加载到内存地址寄存器中的地址–通常被称为物理地址。</p>
<p><strong>编译时和加载时地址绑定方法生成相同的逻辑地址和物理地址</strong>。然而，<strong>执行时地址绑定方案导致不同的逻辑地址和物理地址</strong>。在这种情况下，<strong>我们通常将逻辑地址称为虚拟地址</strong>。在本文中，我们将逻辑地址和虚拟地址互换使用。由程序生成的所有逻辑地址的集合称为逻辑地址空间。与这些逻辑地址对应的所有物理地址的集合称为物理地址空间。</p>
<p>虚拟地址到物理地址的运行时映射是由称为内存管理单元（MMU）的硬件设备完成的。目前，我们将用一个简单的 MMU 方案来说明这种映射。<strong>现在，基址寄存器被称为重定位寄存器</strong>。在将用户进程生成的每个地址发送到内存时，重定位寄存器中的值会被添加到该地址上。例如，如果基址是 14000，那么用户试图访问位置 0 将被动态重定位到位置 14000；访问位置 346 将被映射到位置 14346。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319125823989.png" alt="image-20240319125823989" style="zoom:50%;">
<p>用户程序永远不会看到真实的物理地址。<strong>程序可以创建一个指向位置 346 的指针，将其存储在内存中，对其进行操作，并将其与其他地址进行比较——所有这些都是作为数字 346</strong>。只有当它被用作内存地址（例如在间接加载或存储中）时，它才相对于基址寄存器进行重定位。用户程序处理逻辑地址。内存映射硬件将逻辑地址转换为物理地址。<strong>被引用的内存地址的最终位置直到引用被执行时才确定</strong>。</p>
<p>现在我们有两种不同类型的地址：逻辑地址（在范围 0 到 max 内）和物理地址（对于基址值 R，范围为 R + 0 到 R + max）。用户程序仅生成逻辑地址，并认为进程在位置 0 到 max 运行。然而，在使用这些逻辑地址之前，它们必须映射到物理地址。<strong>将逻辑地址空间绑定到单独的物理地址空间的概念是正确的内存管理的核心</strong>。</p>
<h3 id="动态加载">动态加载</h3>
<p>到目前为止，在我们的讨论中，为了执行进程，进程的整个程序和所有数据都必须在物理内存中。因此，进程的大小被限制为物理内存的大小。为了获得更好的内存空间利用率，我们可以使用动态加载。<strong>使用动态加载，直到调用时才加载例程</strong>。<strong>所有例程以可重定位的加载格式保存在磁盘上</strong>。主程序被加载到内存中并执行。当一个例程需要调用另一个例程时，调用例程首先检查另一个例程是否已加载。如果没有，<strong>就调用可重定位链接加载器将所需的例程加载到内存中</strong>，并更新程序的地址表以反映此更改。然后控制传递给新加载的例程。</p>
<p><strong>动态加载的优点是只有在需要时才加载例程</strong>。当需要大量代码来处理不经常发生的情况时，例如错误例程时，这种方法特别有用。在这种情况下，虽然总程序大小可能很大，但使用的部分（因此加载的部分）可能要小得多。</p>
<p>动态加载不需要操作系统的特殊支持。<strong>将程序设计为利用这种方法是用户的责任</strong>。然而，操作系统可能通过提供库例程来实现动态加载，从而帮助程序员。</p>
<h3 id="动态链接和共享库">动态链接和共享库</h3>
<p><strong>动态链接库是系统库，当用户程序运行时，它们会被链接到用户程序</strong>。一些操作系统仅支持静态链接，其中系统库被视为任何其他对象模块，并由加载程序合并到二进制程序图像中。相比之下，动态链接类似于动态加载。在这里，链接而不是加载被推迟到执行时期。此功能通常与系统库一起使用，例如语言子例程库。如果没有此功能，系统上的每个程序都必须在可执行映像中包含其语言库的副本。<strong>这个要求浪费了磁盘空间和主内存</strong>。</p>
<p><strong>使用动态链接，每个库例程引用都包含在映像中的一个存根stub</strong>。存根是一小段代码，指<strong>示如何定位适当的内存驻留库例程</strong>，或者如何加载库，如果例程尚未存在的话。当存根执行时，它会检查所需的例程是否已经在内存中。如果没有，程序将例程加载到内存中。无论哪种方式，<strong>存根都将自身替换为例程的地址并执行该例程</strong>。因此，下一次达到特定的代码段时，库例程将直接执行，动态链接不会产生任何成本。在这个方案下，使用语言库的所有进程只执行一份库代码的副本。</p>
<p>**这个特性可以扩展到库的更新（如修复错误）。一个库可以被一个新版本替换，所有引用该库的程序将自动使用新版本。**如果没有动态链接，所有这些程序都需要重新链接才能访问新的库。为了防止程序意外执行新的不兼容版本的库，版本信息被包含在程序和库中。<strong>一个库的多个版本可能被加载到内存中，每个程序使用它的版本信息来决定使用哪个库副本</strong>。因此，只有使用新库版本编译的程序才会受到其中包含的任何不兼容更改的影响。在安装新库之前链接的其他程序将继续使用旧库。这个系统也被称为共享库。</p>
<p><strong>与动态加载不同，动态链接和共享库通常需要操作系统的帮助</strong>。如果内存中的进程相互保护，则操作系统是唯一能够检查所需例程是否在另一个进程的内存空间中或允许多个进程访问相同内存地址的实体。</p>
<h2 id="交换">交换</h2>
<p>一个进程必须在内存中执行。然而，一个进程可以暂时交换到后备存储中去，然后再次被带回内存继续执行。交换使得所有进程的总物理地址空间可以超过系统的真实内存，从而增加了多道程序设计的程度。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319134007557.png" alt="image-20240319134007557" style="zoom:50%;">
<h3 id="标准交换">标准交换</h3>
<p>标准交换涉及将进程在主内存和后备存储之间移动。<strong>后备存储通常是一个快速磁盘。它必须足够大，以容纳所有用户的所有内存镜像的副本，并且必须提供对这些内存镜像的直接访问</strong>。系统维护一个准备队列，其中包含所有内存镜像位于后备存储或内存中且准备运行的进程。每当 CPU 调度程序决定执行一个进程时，它就会调用调度程序。调度程序检查队列中的下一个进程是否在内存中。如果不是，并且没有空闲的内存区域，调度程序就会将当前在内存中的一个进程换出，并换入所需的进程。然后，它重新加载寄存器并将控制转移到所选的进程。</p>
<p>交换时间的主要开销在传输上。<strong>标准的交换在现代操作系统中不再使用。它需要太长的交换时间，提供的执行时间太少，无法成为合理的内存管理解决方案</strong>。然而，修改过的交换版本在许多系统上都可以找到，包括 UNIX、Linux 和 Windows。<strong>在一个常见的变体中，交换通常被禁用，但如果空闲内存的量（供操作系统或进程使用的未使用内存）低于一个阈值时，交换将开始</strong>。当空闲内存的量增加时，交换将停止。另一个变体涉及交换进程的部分而不是整个进程，以减少交换时间。通常，这些修改过的交换形式与虚拟内存一起使用。</p>
<h3 id="移动系统交换">移动系统交换</h3>
<p>尽管大多数 PC 和服务器的操作系统支持某种修改过的交换版本，<strong>但移动系统通常不支持任何形式的交换</strong>。移动设备通常使用闪存而不是更宽敞的硬盘作为它们的持久存储。<strong>由此产生的空间限制是移动操作系统设计者避免交换的原因之一</strong>。其他原因包括闪存在变得不可靠之前所能容忍的有限写入次数，以及这些设备中主内存与闪存之间的低吞吐量。</p>
<p>当空闲内存下降到一定阈值以下时，苹果的iOS不使用交换，<strong>而是要求应用程序自愿释放分配的内存</strong>。只读数据（例如代码）从系统中删除，并在需要时从闪存中重新加载。已修改的数据（例如堆栈）永远不会被删除。然而，任何未能释放足够内存的应用程序可能会被操作系统终止。</p>
<p>Android 不支持交换，并采用了类似 iOS 的策略。如果内存不足，它可能会终止一个进程。<strong>然而，在终止进程之前，Android 会将其应用程序状态写入闪存，以便可以快速重新启动</strong>。</p>
<p>由于这些限制，移动系统的开发人员必须谨慎地分配和释放内存，以确保他们的应用程序不会使用过多的内存或遭受内存泄漏的问题。请注意，<strong>iOS 和 Android 都支持分页，因此它们确实具有内存管理能力</strong>。</p>
<h2 id="连续内存分配">连续内存分配</h2>
<p>主内存必须容纳操作系统和各种用户进程。因此，我们需要以尽可能高效的方式分配主内存。<strong>本节将解释一种早期的方法</strong>，连续内存分配。</p>
<p>内存通常分为两个分区：<strong>一个用于驻留操作系统，另一个用于用户进程</strong>。我们可以将操作系统放置在低内存或高内存中。影响此决定的主要因素是中断向量的位置。由于中断向量通常位于低内存中，程序员通常也将操作系统放置在低内存中。</p>
<p>我们通常希望多个用户进程同时驻留在内存中。因此，我们需要考虑如何将可用内存分配给等待被载入内存的进程。在连续内存分配中，每个进程都包含在内存的一个单独部分中，该部分与包含下一个进程的部分相邻。</p>
<h3 id="内存保护">内存保护</h3>
<p><strong>在进一步讨论内存分配之前，我们必须讨论内存保护的问题</strong>。通过结合之前讨论过的两个想法，我们可以防止一个进程访问它不拥有的内存。如果我们有一个具有重定位寄存器和一个限制寄存器的系统，我们就可以实现我们的目标。重定位寄存器包含最小物理地址的值；限制寄存器包含逻辑地址的范围（例如，重定位 = 100040，限制 = 74600）。每个逻辑地址必须落在限制寄存器指定的范围内。内存管理单元（MMU）通过将重定位寄存器中的值添加到逻辑地址来动态地映射逻辑地址。这个映射地址被发送到内存。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319135923122.png" alt="image-20240319135923122" style="zoom:50%;">
<p>当CPU调度程序选择一个进程进行执行时，<strong>调度程序作为上下文切换的一部分将重定位和限制寄存器加载为正确的值</strong>。因为CPU生成的每个地址都会与这些寄存器进行比较，所以我们可以保护操作系统和其他用户的程序和数据，防止该运行进程对其进行修改。</p>
<p><strong>重定位寄存器方案提供了一种有效的方法来允许操作系统的大小动态变化</strong>。这种灵活性在许多情况下都是可取的。例如，操作系统包含设备驱动程序的代码和缓冲区空间。如果一个设备驱动程序（或其他操作系统服务）不常用，我们不希望保留代码和数据在内存中，因为我们可能能够将该空间用于其他用途。因此，在程序执行期间使用此代码会改变操作系统的大小。</p>
<h3 id="内存分配">内存分配</h3>
<p>现在我们准备转向内存分配。一种最简单的内存分配方法是将内存分成几个固定大小的分区。每个分区可能包含一个进程。因此，多道程序设计的程度受到分区数量的限制。<strong>在这种多分区方法中，当一个分区为空闲时，从输入队列中选择一个进程，并将其加载到空闲分区中。当进程终止时，该分区变为另一个进程可用</strong>。这种方法现在已不再使用。接下来描述的方法是固定分区方案的一种泛化（称为MVT）；它主要用于批处理环境。<strong>这里提出的许多想法也适用于使用纯分段进行内存管理的分时环境</strong>。</p>
<p>在可变分区方案中，<strong>操作系统维护一张表，指示内存的哪些部分是可用的，哪些是占用的</strong>。最初，所有内存都可用于用户进程，并被视为一个可用内存的大块，一个空闲块。随着你将会看到的，内存最终包含了一组不同大小的空闲块。</p>
<p>当进程进入系统时，它们被放置在一个输入队列中。<strong>操作系统考虑每个进程的内存需求以及可用内存空间的数量，以确定哪些进程被分配内存</strong>。当一个进程被分配空间时，它被加载到内存中，<strong>然后可以竞争CPU时间</strong>。当一个进程终止时，它释放其内存，操作系统随后可以用来填充输入队列中的另一个进程。</p>
<p><strong>因此，在任何给定时间，我们都有一个可用块大小的列表和一个输入队列</strong>。操作系统可以根据调度算法对输入队列进行排序。内存被分配给进程，直到最终无法满足下一个进程的内存需求为止，也就是说，没有足够大的可用内存块（或空闲块）来容纳该进程。然后，操作系统可以等待直到有足够大的块可用，或者可以跳过输入队列，看看是否可以满足其他一些进程的较小内存需求。</p>
<p>通常情况下，正如前面提到的，可用的内存块包括散布在整个内存中的一组不同大小的空闲块。当一个进程到达并需要内存时，系统会在这组空闲块中搜索一个足够大的空闲块来容纳该进程。如果空闲块太大，它将被分成两部分。一部分分配给到达的进程；另一部分则返回到空闲块集合中。<strong>当一个进程终止时，它释放其内存块，然后将其放回到空闲块集合中。如果新的空闲块与其他空闲块相邻，则这些相邻的空闲块将合并成一个更大的空闲块</strong>。此时，系统可能需要检查是否有等待内存的进程，以及这些新释放和合并的内存是否能够满足任何一个等待中的进程的需求。</p>
<p>这个过程是一种特殊情况，涉及到如何从一组空闲块中满足大小为n的请求的一般动态存储分配问题。对于这个问题有很多解决方案。<strong>首次适应、最佳适应和最坏适应策略</strong>是从可用空闲块集合中选择一个空闲块的最常用方法。</p>
<p>• <strong>首次适应</strong>。分配第一个足够大的空闲块。搜索可以从空闲块集合的开头开始，也可以从上次首次适应搜索结束的位置开始。一旦找到一个足够大的空闲块，我们就可以停止搜索。</p>
<p>• <strong>最佳适应</strong>。分配最小的足够大的空闲块。除非列表按大小排序，否则我们必须搜索整个列表。该策略产生的剩余空闲块最小。</p>
<p>• <strong>最坏适应</strong>。分配最大的空闲块。同样，除非列表按大小排序，否则我们必须搜索整个列表。该策略产生的剩余空闲块最大，可能比最佳适应方法产生的较小剩余空闲块更有用。</p>
<p>模拟结果表明，<strong>在减少时间和存储利用方面，首次适应和最佳适应都优于最坏适应</strong>。在存储利用方面，首次适应和最佳适应都没有明显的优势，但是首次适应通常速度更快。</p>
<h3 id="内存碎片化">内存碎片化</h3>
<p>首次适应和最佳适应的内存分配策略都存在外部碎片问题。随着进程被加载到内存中并从内存中移除，空闲内存空间被分割成小块。<strong>当总内存空间足够满足请求，但可用空间不连续时，就存在外部碎片化：存储被分割成大量小块</strong>。这种碎片化问题可能非常严重。在最坏的情况下，我们可能在每两个进程之间都有一块空闲（或浪费的）内存。如果所有这些小块内存都在一个大的空闲块中，我们可能能够运行更多的进程。</p>
<p>我们使用首次适应还是最佳适应策略都会影响碎片化的程度。另一个因素是空闲块的哪一端被分配。无论使用哪种算法，外部碎片化都将是一个问题。根据总内存存储量和平均进程大小的不同，外部碎片化可能是一个轻微或严重的问题。例如，对首次适应进行统计分析显示，即使进行了一些优化，对于给定的N个分配块，另外的0.5N块将被碎片化浪费。也就是说，<strong>有三分之一的内存可能无法使用</strong>！这一特性被称为50%规则。</p>
<p>内存碎片化不仅可以是外部的，还可以是内部的。考虑一个带有18,464字节空洞的多分区分配方案。<strong>假设下一个进程请求18,462字节。如果我们精确地分配所请求的块，就会剩下2字节的空洞</strong>。跟踪这个空洞的开销将远远大于空洞本身。<strong>避免这个问题的一般方法是将物理内存分成固定大小的块，并根据块大小单位分配内存</strong>。采用这种方法，分配给一个进程的内存可能略大于请求的内存。<strong>这两个数字之间的差异就是内部碎片化——分区内部未使用的内存</strong>。</p>
<p><strong>解决外部碎片化问题的一个方法是压缩</strong>。其目标是重新排列内存内容，以便将所有的空闲内存放在一个大的块中。然而，压缩并非总是可行的。<strong>如果重定位是静态的，并且在汇编或加载时进行，那么无法进行压缩</strong>。<strong>只有在重定位是动态的，并且在执行时进行时才可能</strong>。如果地址是动态重定位的，则重定位仅需要移动程序和数据，然后更改基址寄存器以反映新的基址。<strong>当压缩是可能的时，我们必须确定其成本</strong>。最简单的压缩算法是将所有进程移向内存的一端；所有的空洞向另一个方向移动，产生一个大的可用内存空洞。</p>
<p><strong>解决外部碎片化问题的另一个可能方法是允许进程的逻辑地址空间是非连续的，从而允许进程在任何可用的物理内存中分配内存</strong>。两种互补的技术实现了这个解决方案：分段和分页。</p>
<h2 id="分段">分段</h2>
<p>如果硬件能够提供一种将程序员的视图映射到实际物理内存的内存机制会怎样呢？系统会有更多的自由来管理内存，而程序员将拥有更自然的编程环境。分段segmentation提供了这样一种机制。</p>
<h3 id="基本方法">基本方法</h3>
<p>程序员是否将内存视为一组包含指令和数据的字节的线性数组？大多数程序员会说“不是”。相反，他们更倾向于将内存视为一组可变大小的段，这些段之间没有必要的顺序关系。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319142518626.png" alt="image-20240319142518626" style="zoom:50%;">
<p>在编写程序时，程序员将其视为一个主程序，其中包含一组方法、过程或函数。它还可能包括各种数据结构：对象、数组、堆栈、变量等等。每个模块或数据元素都通过名称引用。<strong>程序员会谈论“堆栈”、“数学库”和“主程序”，而不关心这些元素在内存中占据的地址</strong>。她不关心堆栈是存储在Sqrt()函数之前还是之后。<strong>段的长度各不相同，每个段的长度都是由其在程序中的目的固定定义的</strong>。段内的元素由它们相对于段开头的偏移量来标识：程序的第一条语句，堆栈中第七个堆栈帧条目，Sqrt()的第五条指令等等。</p>
<p>分段是一种支持程序员对内存这种视图的内存管理方案。逻辑地址空间是段的集合。每个段都有一个名称和一个长度。地址指定了段的名称和段内的偏移量。因此，程序员通过两个量来指定每个地址：<strong>一个段名称和一个偏移量</strong>。段被编号并通过段号来引用，而不是通过段名。因此，逻辑地址由一个二元组组成：<strong>&lt;段号，偏移量&gt;</strong>。</p>
<p>通常，当程序被编译时，编译器会自动构建反映输入程序的段。</p>
<ol>
<li>代码</li>
<li>全局变量</li>
<li>堆，用于分配内存</li>
<li>每个线程使用的栈</li>
<li>标准C库</li>
</ol>
<p>在编译时链接的库可能会被分配给单独的段。加载器会获取所有这些段并为它们分配段号。</p>
<h3 id="Segmentation-Hardware">Segmentation Hardware</h3>
<p>尽管程序员现在可以通过二维地址引用程序中的对象，但实际的物理内存仍然是一维字节序列。因此，我们必须定义一种实现，将二维用户定义的地址映射到一维物理地址。<strong>这种映射是通过一个段表实现的。段表中的每个条目都有一个段基址segment base和一个段限长segment limit。段基址包含段在内存中的起始物理地址，而段限长指定了段的长度。</strong></p>
<p>段表的使用: 一<strong>个逻辑地址由两部分组成：段号s和该段中的偏移量d</strong>。段号被用作段表的索引。逻辑地址的偏移量d必须在0到段限长之间。如果不是，则会陷入操作系统（尝试超出段末尾的逻辑寻址）。<strong>当偏移量是合法的时，它会加到段基址上，以产生所需字节的物理内存地址</strong>。因此，<strong>段表实质上是一组基址-限长寄存器对的数组</strong>。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319143549375.png" alt="image-20240319143549375" style="zoom:50%;">
<p>举例来说。我们有从0到4编号的五个段。段存储在物理内存中。段表为每个段单独提供一个条目，给出段在物理内存中的起始地址（或基址）和该段的长度（或限长）。例如，段2长400字节，从位置4300开始。因此，对段2的字节53的引用被映射到位置4300 + 53 = 4353。对段3，字节852的引用被映射到3200（段3的基址） + 852 = 4052。对<strong>段0的字节1222的引用将导致陷阱到操作系统，因为这个段只有1000字节长</strong>。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319143907005.png" alt="image-20240319143907005" style="zoom:50%;">
<h2 id="分页">分页</h2>
<p>分段允许物理地址空间是非连续的。分页Paging另一种内存管理方案。<strong>分页避免了外部碎片化和压缩的需要，而分段则没有</strong>。<strong>它还解决了将不同大小的内存块适应到后备存储的问题</strong>。在分页引入之前使用的大多数内存管理方案都存在这个问题。问题的出现是因为，当驻留在主存储器中的代码片段或数据需要被换出时，必须在后备存储器中找到空间。后备存储器具有与主内存中讨论的碎片化问题相同的问题，但访问速度要慢得多，因此无法进行压缩。由于其优点，分页在各种形式下被用于大多数操作系统，从大型机到智能手机的操作系统都是如此。<strong>分页通过操作系统与计算机硬件的协作实现</strong>。</p>
<h3 id="基本方法-2">基本方法</h3>
<p><strong>实现分页的基本方法包括将物理内存划分为固定大小的块，称为页框frames，将逻辑内存划分为相同大小的块，称为页面pages</strong>。当一个进程要执行时，它的页面从其源（文件系统或后备存储）加载到任何可用的内存页框中。后备存储被划分为与内存页框大小相同的固定大小的块，或者是多个页框的聚类。<strong>这个相当简单的想法具有很强的功能性和广泛的影响</strong>。例如，逻辑地址空间现在完全与物理地址空间分离，因此即使系统的物理内存少于 2的64次方字节，进程也可以拥有逻辑 64 位地址空间。</p>
<p>硬件对分页的支持如下图所示。<strong>CPU 生成的每个地址分为两部分：页号page number (p) 和页偏移量page offset (d)。页号用作页表page table的索引</strong>。页表包含物理内存中每个页面的基地址。<strong>这个基地址与页偏移量相结合，定义了发送到内存单元的物理内存地址</strong>。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319145634256.png" alt="image-20240319145634256" style="zoom:50%;">
<p>内存的分页模型如下图所示。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319145912586.png" alt="image-20240319145912586" style="zoom:50%;">
<p><strong>页面大小（与frame大小一样）由硬件定义</strong>。页面的大小是 2 的幂，根据计算机体系结构的不同，每个页面的大小可变，介于 512 字节到 1 GB 之间。选择 2 的幂作为页面大小使得将逻辑地址转换为页号和页偏移量特别容易。<strong>如果逻辑地址空间的大小为 2^m，而页面大小为 2^n 字节，则逻辑地址的高 m − n 位表示页号，低 n 位表示页偏移量</strong>。因此，逻辑地址如下所示：</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319150234824.png" alt="image-20240319150234824" style="zoom:50%;">
<p>其中，p 是页表的索引，d 是页内的位移。</p>
<p>作为一个具体的（虽然微小的）例子，考虑下图中的内存。在这里，逻辑地址中，n= 2，m = 4。使用页面大小为4字节和物理内存为32字节（8页），我们展示了如何将程序员对内存的视图映射到物理内存中。逻辑地址0是页面0，偏移0。索引到页表中，我们发现页面0在frame 5中。因此，逻辑地址0映射到物理地址20 [=（5 × 4）+ 0]。逻辑地址3（页面0，偏移3）映射到物理地址23 [=（5 × 4）+ 3]。逻辑地址4是页面1，偏移0；根据页表，页面1映射到帧6。因此，逻辑地址4映射到物理地址24 [=（6 × 4）+ 0]。逻辑地址13映射到物理地址9。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319150429478.png" alt="image-20240319150429478" style="zoom:40%;">
<p>你可能已经注意到，分页本身是一种动态重定位的形式。<strong>每个逻辑地址都由分页硬件绑定到某个物理地址</strong>。使用分页类似于使用基址（或重定位）寄存器表，每个内存frame对应一个。</p>
<p><strong>当我们使用分页方案时，不存在外部碎片：任何空闲帧都可以分配给需要的进程</strong>。然而，我们可能会有一些内部碎片。请注意，frame是作为单元分配的。如果一个进程的内存需求恰好不与页面边界相符，那么最后分配的frame可能不会完全填满。例如，如果页面大小为 2,048 字节，一个大小为 72,766 字节的进程将需要 35 个页面加上 1,086 字节。它将被分配 36 个frame，导致内部碎片为 2,048 − 1,086 = 962 字节。在最坏的情况下，一个进程将需要 n 个页面加上 1 个字节。它将被分配 n + 1 个frame，导致几乎整个frame的内部碎片。</p>
<p><strong>如果进程大小与页面大小无关，我们预期每个进程平均会有一半页面的内部碎片</strong>。这个考虑表明小的页面大小是理想的。然而，每个页表项都涉及一定的开销，随着页面大小的增加，这种开销会减少。此外，当传输的数据量较大时，磁盘 I/O 更有效率。<strong>通常，随着进程、数据集和主内存的增大，页面大小也在不断增长</strong>。如今，页面通常介于 4 KB 到 8 KB 之间，一些系统甚至支持更大的页面大小。一些 CPU 和内核甚至支持多个页面大小。例如，Solaris 使用 8 KB 和 4 MB 的页面大小，具体取决于页面存储的数据。<strong>研究人员正在开发支持可变即时页面大小的技术</strong>。</p>
<p>通常情况下，在 32 位 CPU 上，每个页表项长为 4 个字节，但这个大小也可能会变化。一个 32 位的页表项可以指向 2^32 个物理页帧中的一个。如果帧大小为 4 KB（2^12），那么具有 4 个字节的页表项的系统可以寻址 2^44 字节（或 16 TB）的物理内存。我们应该注意的是，在分页内存系统中，物理内存的大小与进程的最大逻辑大小是不同的。随着我们进一步探索分页，我们会介绍必须保留在页表项中的其他信息。<strong>这些信息减少了用于寻址页帧的可用位数</strong>。因此，具有 32 位页表项的系统可能会寻址比可能的最大物理内存更少。32 位 CPU 使用 32 位地址，这意味着给定进程空间只能是 2^32 字节（4 TB）。因此，分页让我们可以使用比 CPU 地址指针长度所能寻址的更大的物理内存。</p>
<p>当一个进程到达系统准备执行时，系统会检查其大小，以页为单位。<strong>进程的每一页都需要一个帧</strong>。<strong>因此，如果进程需要 n 页，那么至少需要 n 个帧在内存中可用</strong>。如果有 n 个帧可用，它们将被分配给这个到达的进程。进程的第一页被加载到分配的一个帧中，并且该帧号被放入该进程的页表中。接下来的一页被加载到另一个帧中，其帧号也被放入页表中，依此类推。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319151959603.png" alt="image-20240319151959603" style="zoom:50%;">
<p><strong>分页的一个重要方面是程序员对内存和实际物理内存之间的清晰分离</strong>。程序员将内存视为一个单一的空间，仅包含这一个程序。实际上，用户程序分散在物理内存中，物理内存还包含其他程序。<strong>程序员对内存的视图与实际物理内存之间的差异是由地址转换硬件进行调和的</strong>。逻辑地址被转换为物理地址。这种映射对程序员来说是隐藏的，并由操作系统控制。<strong>请注意，根据定义，用户进程无法访问它不拥有的内存</strong>。它无法寻址页表之外的内存，而页表只包含进程拥有的那些页面。</p>
<p>由于操作系统正在管理物理内存，它必须了解物理内存的分配细节——哪些帧已分配，哪些帧可用，总共有多少帧等等**。这些信息通常保存在一个称为页帧表frame table的数据结构中**。页帧表为每个物理页面帧保留一个条目，指示该页面帧是否空闲或已分配，如果已分配，则分配给哪个进程或多个进程的哪个页面。</p>
<p>此外，操作系统必须意识到用户进程运行在用户空间，<strong>所有逻辑地址必须映射为物理地址</strong>。如果用户进行系统调用并提供一个地址作为参数，<strong>那么该地址必须映射为正确的物理地址</strong>。操作系统为每个进程维护一个页表的副本，就像它维护指令计数器和寄存器内容的副本一样。这个副本用于在操作系统必须手动映射逻辑地址到物理地址时，将逻辑地址转换为物理地址。<strong>它也被CPU调度程序用于在分配CPU给一个进程时定义硬件页表。因此，分页增加了上下文切换时间</strong>。</p>
<h3 id="硬件支持">硬件支持</h3>
<p>每个操作系统都有自己的方法来存储页表。一些操作系统为每个进程分配一个页表。指向页表的指针与进程控制块中的其他寄存器值（如指令计数器）一起存储。当调度程序被告知要启动一个进程时，它必须重新加载用户寄存器，<strong>并从存储的用户页表中定义正确的硬件页表值</strong>。其他操作系统提供一个或最多几个页表，这样在进行进程上下文切换时，减少了相关开销。</p>
<p>页表的硬件实现可以有几种方式。<strong>在最简单的情况下，页表被实现为一组专用寄存器</strong>。<strong>这些寄存器应该采用非常高速的逻辑构建，以使分页地址转换高效</strong>。每次访问内存都必须通过分页映射，因此效率是一个重要考虑因素。CPU调度程序重新加载这些寄存器，就像重新加载其他寄存器一样。加载或修改页表寄存器的指令当然是特权的，这样只有操作系统才能更改内存映射。DEC PDP-11就是这种架构的一个例子。地址由16位组成，页面大小为8 KB。<strong>因此，页表由八个条目组成，这些条目存储在快速寄存器中</strong>。</p>
<p>如果页表相对较小（例如，256个条目），则使用寄存器来实现页表是令人满意的。然而，大多数当代计算机允许页表非常庞大（例如，100万个条目）。对于这些机器，使用快速寄存器来实现页表是不可行的。<strong>相反，页表保存在主存储器中，并且页表基址寄存器（PTBR）指向页表。更改页表仅需要更改这一个寄存器，大大减少了上下文切换时间</strong>。</p>
<p>这种方法的问题在于访问用户内存位置所需的时间。如果我们想要访问位置 i，我们必须首先使用页表基址寄存器（PTBR）中的值按照 i 的页号进行索引。这个任务需要一次内存访问。它为我们提供了页框号，将其与页面偏移组合以产生实际地址。然后我们可以访问内存中的所需位置。<strong>使用这种方案，访问一个字节需要两次内存访问（一次用于页表条目，一次用于字节）</strong>。因此，内存访问速度减慢了一倍。在大多数情况下，这种延迟是无法容忍的。我们可能还不如使用交换！</p>
<p>解决这个问题的标准方法是使用一种特殊的、小型的、快速查找的硬件缓存，称为translation look-aside buffer（TLB）。<strong>TLB 是关联的、高速的内存</strong>。<strong>TLB 中的每个条目由两部分组成：一个键（或标签）和一个值</strong>。当关联内存收到一个条目时，该条目将与所有键同时进行比较。如果找到了该条目，则返回相应的值字段。搜索速度很快；在现代硬件中，TLB 查找是指令流水线的一部分，基本上不会增加性能开销。然而，为了能够在流水线步骤内执行搜索，TLB 必须保持较小。它通常的大小在 32 到 1,024 个条目之间。一些 CPU 实现了单独的指令和数据地址 TLB。这样可以增加可用的 TLB 条目数量，因为这些查找发生在不同的流水线步骤中。我们可以看到在这个发展中 CPU 技术的演变示例：系统从没有 TLB 发展到具有多级 TLB，就像它们具有多级缓存一样。</p>
<p>TLB 与页表结合使用的方式如下。TLB 仅包含少量的页表条目。当 CPU 生成一个逻辑地址时，它的页号被提供给 TLB。<strong>如果找到了页号，其帧号将立即可用，并用于访问内存</strong>。正如刚才提到的，这些步骤是作为 CPU 内的指令流水线的一部分执行的，与不实现分页的系统相比，不会增加性能开销。</p>
<p>如果页号不在 TLB 中（称为 TLB 未命中），<strong>则必须进行对页表的内存引用</strong>。根据 CPU 的不同，这可能是通过硬件自动完成，也可能是通过向操作系统发出中断。获取了帧号后，我们可以用它来访问内存。此外，我们将页号和帧号添加到 TLB 中，以便在下一次引用时快速找到它们。<strong>如果 TLB 已经装满了条目，则必须选择一个现有条目进行替换</strong>。替换策略从最近最少使用（LRU）到循环轮询再到随机都有。<strong>一些 CPU 允许操作系统参与 LRU 条目替换，而其他 CPU 则自行处理此事</strong>。此外，一些 TLB 允许将某些条目固定下来，意味着它们无法从 TLB 中移除。通常，<strong>对关键内核代码的 TLB 条目进行固定</strong>。</p>
<p><strong>一些 TLB 在每个 TLB 条目中存储地址空间标识符（ASID）</strong>。ASID 唯一标识每个进程，并用于为该进程提供地址空间保护。当 TLB 尝试解析虚拟页号时，它确保当前运行的进程的 ASID 与与虚拟页关联的 ASID 匹配。<strong>如果 ASID 不匹配，则将该尝试视为 TLB 未命中</strong>。除了提供地址空间保护外，ASID 还允许 TLB 同时包含多个不同进程的条目。如果 TLB 不支持单独的 ASID，则每次选择新的页表（例如，每次上下文切换时），都必须清空（或擦除）TLB，以确保下一个执行的进程不会使用错误的转换信息。否则，TLB 可能包含旧条目，这些条目包含有效的虚拟地址，但从前一个进程留下的物理地址是错误的或无效的。</p>
<p><strong>页面号在 TLB 中被找到的百分比被称为命中率</strong>。例如，80% 的命中率意味着我们在 TLB 中找到所需的页面号的次数占总次数的 80%。如果访问内存需要 100 纳秒，那么当页面号在 TLB 中时，映射内存访问需要 100 纳秒。如果我们在 TLB 中找不到页面号，则我们必须先访问页面表和帧号（100 纳秒），然后访问内存中所需的字节（100 纳秒），总共需要 200 纳秒。（我们假设页面表查找只需要一次内存访问，但实际可能需要更多，我们稍后会看到。）为了找到有效的内存访问时间，<strong>我们根据其概率进行加权</strong>： 有效访问时间 = 0.80 × 100 + 0.20 × 200 = 120 纳秒</p>
<p>正如我们前面所指出的，当今的 CPU 可能提供多级 TLB。因此，在现代 CPU 中计算内存访问时间要比上面的示例复杂得多。例如，Intel Core i7 CPU 具有 128 个条目的 L1 指令 TLB 和 64 个条目的 L1 数据 TLB。在 L1 中发生未命中的情况下，<strong>CPU 需要六个周期来检查 L2 中的条目</strong>。L2 中的未命中意味着 CPU 必须要么遍历内存中的页面表条目以找到相关的帧地址（可能需要数百个周期），要么中断到操作系统以让其完成这项工作。</p>
<p>TLB 是一种硬件特性，因此似乎对操作系统及其设计者来说并不重要。但设计者需要了解 TLB 的功能和特性，因为这些特性因硬件平台而异。**为了实现最佳操作，针对特定平台的操作系统设计必须根据该平台的 TLB 设计来实现分页。**同样，TLB 设计的更改（例如，在英特尔 CPU 的不同世代之间）可能需要操作系统的分页实现发生变化。</p>
<h3 id="保护">保护</h3>
<p>在分页环境中，<strong>内存保护是通过与每个页面关联的保护位来实现的</strong>。通常，这些位被保存在页表中。</p>
<p>每个比特可以将一个页面定义为读写或只读。每次对内存的引用都通过页表以找到正确的页框号。<strong>同时，在计算物理地址的同时，可以检查保护位，以验证是否对只读页面进行了写操作</strong>。尝试向只读页面写入会导致硬件trap到操作系统（或内存保护违规）。</p>
<p>通常，每个页表条目都会附加一个额外的位：有效-无效位。当<strong>该位被设置为有效时，关联的页面位于进程的逻辑地址空间中，因此是合法的（或有效的）页面</strong>。当该位被设置为无效时，页面不在进程的逻辑地址空间中。非法地址通过使用有效-无效位被捕获。操作系统为每个页面设置此位，以允许或禁止对页面的访问。</p>
<p>例如，在一个具有14位地址空间（从0到16383）的系统中，假设我们有一个程序，应该仅使用地址0到10468。假设页面大小为2 KB。页面0、1、2、3、4和5中的地址通过页表正常映射。然而，任何尝试生成页面6或7中的地址都会发现有效-无效位被设置为无效，计算机将陷入操作系统（无效页面引用）。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319194020769.png" alt="image-20240319194020769" style="zoom:50%;">
<p>请注意，这种方案引入了一个问题。因为程序仅扩展到地址10468，所以超出该地址的任何引用都是非法的。然而，对于页面5的引用被分类为有效，因此对地址12287及其以下的访问是有效的。只有从12288到16383的地址是无效的。<strong>这个问题是2 KB页面大小的结果，反映了分页的内部碎片问题。</strong></p>
<p>很少有进程使用其整个地址范围。实际上，许多进程只使用它们可用的地址空间的一小部分。在这些情况下，为每个地址范围内的页面创建一个页表将是浪费的。大多数情况下，这个表都是未使用的，但会占用宝贵的内存空间。一**些系统提供了硬件支持，以页表长度寄存器（PTLR）的形式指示页表的大小。**该值与每个逻辑地址进行比较，以验证地址是否在进程的有效范围内。如果这个测试失败，就会导致操作系统发生错误陷阱。</p>
<h3 id="共享页面">共享页面</h3>
<p>分页的一个优点是共享公共代码的可能性。在时间共享环境中，这一考虑尤为重要。考虑一个支持40个用户的系统，每个用户都执行一个文本编辑器。如果文本编辑器包含150 KB的代码和50 KB的数据空间，我们需要8000 KB来支持这40个用户。<strong>然而，如果代码是可重入代码（或纯代码），它就可以被共享</strong>。在这里，我们看到三个进程共享一个三页的编辑器——每页大小为50 KB（使用大页面大小是为了简化图示）。每个进程都有自己的数据页。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240319195407627.png" alt="image-20240319195407627" style="zoom:50%;">
<p><strong>每个进程都有自己的寄存器副本和数据存储，用于保存进程执行所需的数据</strong>。两个不同进程的数据当然是不同的。只需在物理内存中保留一个编辑器的副本。<strong>每个用户的页表映射到相同的编辑器物理副本，但数据页映射到不同的帧</strong>。因此，要支持40个用户，我们只需要一个编辑器副本（150 KB），加上每个用户50 KB的数据空间的40个副本。现在所需的总空间是2150 KB，而不是8000 KB——这是一个显著的节省。其他使用频繁的程序也可以被共享——编译器、窗口系统、运行时库、数据库系统等等。为了可以共享，代码必须是可重入的。共享代码的只读特性不应该依赖代码的正确性；操作系统应该强制执行这个属性。</p>
<h2 id="页表结构">页表结构</h2>
<h3 id="分层页表">分层页表</h3>
<p>大多数现代计算机系统支持大型的逻辑地址空间（从2^32到2^64）。在这样的环境中，页表本身变得过于庞大。例如，考虑一个具有32位逻辑地址空间的系统。如果在这样的系统中，页面大小为4 KB（2^12），那么一个页表最多可以包含100万个条目（2^32/2^12）。假设每个条目由4字节组成，那么每个进程可能需要多达4 MB 的物理地址空间来存储页面表。<strong>显然，我们不希望在主存储器中连续分配页面表</strong>。解决这个问题的一个简单方法是将页面表分成较小的部分。我们可以通过几种方式实现这种划分。</p>
<p><strong>一种方法是使用双层分页算法</strong>，其中页面表本身也被分页。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320095712740.png" alt="image-20240320095712740" style="zoom:40%;">
<p>例如，再次考虑具有32位逻辑地址空间和页面大小为4 KB的系统。逻辑地址被划分为包含20位的页号和包含12位的页偏移量。因为我们对页表进行分页，所以页号进一步被划分为10位的页号和10位的页偏移量。因此，逻辑地址如下：</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320095919626.png" alt="image-20240320095919626" style="zoom:50%;">
<p>其中 p1 是外部页面表的索引，p2 是内部页面表中的位移。该体系结构的地址转换方法如下图所示。由于地址转换是从外部页面表向内部进行的，因此该方案也被称为前向映射的页表(foward-mapped page table)。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320100100927.png" alt="image-20240320100100927" style="zoom:50%;">
<p>VAX是数字设备公司（DEC）于1977年至2000年间销售的最受欢迎的小型计算机。<strong>VAX架构支持一种变体的双级分页</strong>。VAX是一台32位机器，页面大小为512字节。<strong>进程的逻辑地址空间被划分为四个相等的部分，每个部分包含2^30字节</strong>。每个部分代表进程的逻辑地址空间的不同部分。<strong>逻辑地址的前2位高位指定了相应的部分。接下来的21位表示该部分的逻辑页号，最后的9位表示所需页的偏移量</strong>。通过以这种方式对页面表进行分区，操作系统可以将分区保留未使用，直到进程需要它们。整个虚拟地址空间的部分经常未被使用，并且多级页面表对这些空间没有条目，大大减少了存储虚拟内存数据结构所需的内存量。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320100457652.png" alt="image-20240320100457652" style="zoom:50%;">
<p>在这个方案中，s表示节号，p是页面表的索引，d是页面内的位移。即使使用了这种方案，对于使用一个部分的VAX进程，一个级别的页面表的大小为2^21位 * 4字节每个条目 = 8 MB。为了进一步减少主存储器的使用，VAX对用户进程的页面表进行了分页。</p>
<p>64位的UltraSPARC需要七级分页，这将导致非常多的内存访问来转换每个逻辑地址。从这个例子中可以看出，<strong>对于64位架构来说，分层页表通常被认为是不合适的</strong>。</p>
<h3 id="哈希页表">哈希页表</h3>
<p><strong>处理大于32位的地址空间的常见方法是使用哈希页表</strong>，其中哈希值是虚拟页号。哈希表中的每个条目包含一个链表，<strong>其中包含哈希到相同位置的元素</strong>（用于处理冲突）。每个元素包含三个字段：（1）虚拟页号，（2）映射的页帧的值，以及（3）指向链表中下一个元素的指针。</p>
<p><strong>该算法的工作原理如下</strong>：虚拟地址中的虚拟页号被哈希到哈希表中。将虚拟页号与链表中的第一个元素中的字段1进行比较。如果存在匹配，则使用相应的页帧(字段2)来形成所需的物理地址。如果没有匹配项，则在链表中搜索后续条目以查找匹配的虚拟页号。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320102807837.png" alt="image-20240320102807837" style="zoom:50%;">
<p><strong>这种方案有一种适用于64位地址空间的变体</strong>。这种变体使用了聚簇式页表clustered page tables，它类似于散列页表，但哈希表中的每个条目不是指向单个页面，而是指向多个页面（例如16个）。因此，单个页表条目可以存储多个物理页面帧的映射关系。<strong>聚簇式页表对于稀疏地址空间特别有用，其中内存引用是不连续的，分散在整个地址空间中</strong>。</p>
<h3 id="倒置页表">倒置页表</h3>
<p><strong>通常，每个进程都有一个关联的页表</strong>。页表中的每个条目对应着进程正在使用的每一页（或者对每个虚拟地址都有一个插槽，无论其有效性如何）。这种表示是自然的，因为进程通过页面的虚拟地址引用页面。然后，操作系统必须将此引用转换为物理内存地址。由于表是按虚拟地址排序的，因此操作系统能够计算出关联的物理地址条目位于表中的位置，并直接使用该值。<strong>这种方法的一个缺点是，每个页表可能包含数百万个条目</strong>。这些表可能会消耗大量物理内存，仅用于跟踪其他物理内存的使用情况。</p>
<p>为了解决这个问题，我们可以使用倒置页表inverted page table。倒置页表为内存中的每一页（或帧）都有一个条目。每个条目包含存储在该实际内存位置上的页面的虚拟地址，以及拥有该页面的进程的信息。因此，系统中只有一个页表，对于每一页物理内存只有一个条目。<strong>倒置页表通常要求在页表的每个条目中存储地址空间标识符</strong>，因为该表通常包含映射物理内存的几个不同地址空间。存储地址空间标识符可以确保特定进程的逻辑页面映射到相应的物理页面帧。使用倒置页表的系统包括64位UltraSPARC和PowerPC。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320103759603.png" alt="image-20240320103759603" style="zoom:50%;">
<p><strong>为了说明这种方法，我们描述了IBM RT中使用的倒置页表的简化版本</strong>。IBM是第一个使用倒置页表的主要公司，从IBM System 38开始，一直延续到RS/6000和当前的IBM Power CPU。对于IBM RT，<strong>系统中的每个虚拟地址都由三个部分组成：&lt;进程ID，页号，偏移量&gt;</strong>。<strong>每个倒置页表条目都是一对&lt;进程ID，页号&gt;</strong>，其中进程ID扮演地址空间标识符的角色。当发生内存引用时，虚拟地址的一部分，即&lt;进程ID，页号&gt;，被呈现给内存子系统。然后在倒置页表中搜索匹配项。如果找到匹配项，比如在条目i处找到了匹配项，那么将生成物理地址&lt;i，偏移量&gt;。如果找不到匹配项，那么就尝试访问非法地址。</p>
<p>尽管这种方案减少了存储每个页表所需的内存量，<strong>但当发生页引用时，搜索表所需的时间却增加了</strong>。由于倒置页表是按物理地址排序的，但查找是基于虚拟地址进行的，可能需要搜索整个表才能找到匹配项。这种搜索将耗费太长时间。<strong>为了缓解这个问题，我们使用哈希表</strong>，将搜索限制在一个或最多几个页表条目上。当然，<strong>每次访问哈希表都会向过程中添加一个内存引用</strong>，<strong>因此一个虚拟内存引用至少需要两次真实内存读取——一次用于哈希表条目，一次用于页表</strong>。（请注意，在查询哈希表之前首先搜索TLB，这会提供一些性能改进。）</p>
<p><strong>使用倒置页表的系统在实现共享内存时会遇到困难</strong>。共享内存通常被实现为多个虚拟地址映射到一个物理地址。这种标准方法不能用于倒置页表；因为每个物理页只有一个虚拟页条目，一个物理页不能有两个共享的虚拟地址**。解决此问题的一个简单技术是允许页表仅包含一个虚拟地址到共享物理地址的映射**。这意味着对未映射的虚拟地址的引用会导致页面错误。</p>
<h3 id="Oracle-SPARC-Solaris">Oracle SPARC Solaris</h3>
<p>考虑一个现代的64位CPU和操作系统，它们紧密集成以提供低开销的虚拟内存。在SPARC CPU上运行的Solaris是一个完全64位的操作系统，<strong>因此必须解决虚拟内存的问题，而不会用尽所有物理内存来保存多级页表</strong>。它的方法有点复杂，但是使用了散列页表有效地解决了这个问题。有两个散列表——一个用于内核，另一个用于所有用户进程。**每个散列表将内存地址从虚拟内存映射到物理内存。每个散列表条目表示一个连续的虚拟内存映射区域，这比为每个页面单独设置散列表条目更有效率。**每个条目都有一个基地址和一个表示条目代表的页面数的跨度。</p>
<p>如果每个地址都需要通过散列表进行搜索，虚拟到物理的转换将需要太长时间，<strong>因此CPU实现了一个TLB</strong>，用于保存转换表条目（TTE），以进行快速的硬件查找。这些TTE的缓存驻留在转换存储缓冲区（TSB）中，其中包括最近访问的每个页面的条目。当发生虚拟地址引用时，硬件会在TLB中搜索转换。如果没有找到，则硬件将通过内存中的TSB查找导致查找的虚拟地址对应的TTE。<strong>这种TLB遍历功能在许多现代CPU中都可以找到</strong>。如果在TSB中找到匹配项，CPU将TTE复制到TLB中，内存转换完成。<strong>如果在TSB中找不到匹配项，则会中断内核以搜索散列表</strong>。然后，内核从相应的散列表创建一个TTE，并将其存储在TSB中，以便由CPU内存管理单元自动加载到TLB中。最后，中断处理程序将控制返回给MMU，完成地址转换，并从主内存中检索所请求的字节或字。</p>
<h2 id="Example-Intel-32-and-64-bit-Architectures">Example: Intel 32 and 64-bit Architectures</h2>
<p>英特尔芯片的架构在个人计算机领域主导了数年。16位英特尔8086出现在1970年代末，很快又出现了另一款16位芯片——英特尔8088，后者因为被用于最初的IBM PC而引人注目。8086芯片和8088芯片都基于分段架构。后来，英特尔推出了一系列32位芯片——IA-32，其中包括32位奔腾处理器系列。IA-32架构支持分页和分段。最近，英特尔推出了一系列基于x86-64架构的64位芯片。目前，所有最受欢迎的个人计算机操作系统都运行在英特尔芯片上，包括Windows、Mac OS X和Linux（当然，Linux也运行在其他几种架构上）。值得注意的是，然而，英特尔的主导地位并没有扩展到移动系统，ARM架构目前在移动领域取得了相当大的成功。在本节中，我们将分别讨论IA-32和x86-64架构的地址转换。</p>
<h3 id="IA-32-系统">IA-32 系统</h3>
<p>IA-32系统中的内存管理分为两个组件–分段和分页，工作原理如下：CPU生成逻辑地址，这些地址传递给分段单元。分段单元为每个逻辑地址生成一个线性地址。然后将线性地址传递给分页单元，分页单元再生成主内存中的物理地址。因此，分段和分页单元形成了内存单元(MMU)的等效。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320105938623.png" alt="image-20240320105938623" style="zoom:50%;">
<h4 id="IA-32-分段">IA-32 分段</h4>
<p>IA-32架构允许一个段的大小最大为4 GB，每个进程的最大段数为16K。一个进程的逻辑地址空间被划分为两个部分。第一个部分包含最多8K个对该进程私有的段。第二个部分包含最多8K个在所有进程之间共享的段。<strong>关于第一个部分的信息保存在本地描述符表（LDT）中；关于第二个部分的信息保存在全局描述符表（GDT）中</strong>。LDT和GDT中的每个条目都由一个包含有关特定段的详细信息的8字节段描述符组成，包括该段的基址和限制。</p>
<p>逻辑地址是一个二元组(selector, offset)，其中selector是一个16位的数字：</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320110755945.png" alt="image-20240320110755945" style="zoom:50%;">
<p>其中s表示段号，g指示段是否在GDT或LDT中，p处理保护。偏移量是一个32位的数字，指定了所讨论段内的字节位置。</p>
<p>该计算机有六个段寄存器，允许进程同时访问六个段。它还有六个8字节的微程序寄存器，用于保存来自LDT或GDT的相应描述符。<strong>这个缓存使得 Pentium 能够避免在每次内存引用时都从内存中读取描述符</strong>。</p>
<p><strong>在 IA-32 上，线性地址是 32 位长</strong>，形成如下。段寄存器指向 LDT 或 GDT 中的适当条目。关于所讨论段的基址和限制信息被用来生成线性地址。首先，限制信息用于检查地址的有效性。如果地址无效，则生成内存故障，导致操作系统产生陷阱。如果地址有效，则将偏移量的值加到基址的值上，得到一个32位的线性地址。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320111311398.png" alt="image-20240320111311398" style="zoom:50%;">
<h4 id="IA-32分页">IA-32分页</h4>
<p>IA-32 架构允许页面大小为 4 KB 或 4 MB。对于 4 KB 页面，IA-32 使用两级分页方案，其中 32 位线性地址的划分如下：</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320112111344.png" alt="image-20240320112111344" style="zoom:50%;">
<p>前 10 位高阶位引用了外层页表的一个条目，IA-32 称之为页目录。（CR3 寄存器指向当前进程的页目录。）页目录条目指向一个内部页表，该表由线性地址中最内层的 10 位内容进行索引。最后，低阶位 0 到 11 指的是在页表中指向的 4 KB 页中的偏移量。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320112626277.png" alt="image-20240320112626277" style="zoom:50%;">
<p><strong>为了提高物理内存的使用效率，IA-32 页表可以被交换到磁盘上</strong>。在这种情况下，页<strong>目录条目中使用一个无效位来指示该条目指向的表是在内存中还是在磁盘上</strong>。如果表在磁盘上，操作系统可以使用其余的 31 位来指定表的磁盘位置。然后可以根据需要将表调入内存中。</p>
<p>随着软件开发人员开始发现 32 位架构的 4GB 内存限制，英特尔采用了页地址扩展page address extension（PAE），允许 32 位处理器访问超过 4GB 的物理地址空间。PAE 支持引入的根本区别是，分页从两级方案变为三级方案，其中顶部两位指向一个页目录指针表。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320112959187.png" alt="image-20240320112959187" style="zoom:50%;">
<p>PAE还将页目录和页表条目的大小从32位增加到64位，这使得页表和页面框的基地址从20位扩展到24位。结合12位偏移量，为IA-32增加PAE支持将地址空间扩展到36位，支持最多64GB的物理内存。需要注意的是，操作系统必须支持使用PAE。Linux和英特尔的Mac OS X都支持PAE。但是，即使启用了PAE，Windows桌面操作系统的32位版本仍然仅支持4GB物理内存。</p>
<h3 id="x86-64">x86-64</h3>
<p>在历史上，AMD经常基于英特尔的架构开发芯片，但现在情况却有所不同，因为英特尔采用了AMD的x86-64架构。在讨论这一架构时，我们将使用更通用的术语x86-64，而不是商业名称AMD64和Intel 64。</p>
<p><strong>64位地址空间的支持可以提供令人惊讶的2^64字节的可寻址内存</strong>，这个数字超过了16万亿。然而，尽管64位系统理论上可以寻址这么多内存，但在当前设计中，用于地址表示的位数远远少于64位。<strong>x86-64架构目前提供了48位虚拟地址</strong>，<strong>并使用四级分页层次支持4 KB、2 MB或1 GB的页面大小</strong>。由于这种寻址方案可以使用PAE，虚拟地址的大小为48位，但支持52位物理地址。</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320114314938.png" alt="image-20240320114314938" style="zoom:50%;">
<h2 id="Example-ARM-Architecture">Example: ARM Architecture</h2>
<p>尽管英特尔芯片在个人计算机市场上占据主导地位已经超过30年，<strong>但智能手机和平板电脑等移动设备的芯片通常采用32位ARM处理器</strong>。有趣的是，英特尔既设计又制造芯片，而ARM只负责设计芯片，然后将其设计授权给芯片制造商。苹果已经为其iPhone和iPad移动设备授权了ARM设计，而一些基于安卓的智能手机也使用ARM处理器。</p>
<p>32位ARM架构支持以下页面大小：</p>
<ol>
<li>4KB和16KB页面</li>
<li>1MB和16MB页面(termed sections)</li>
</ol>
<p>所使用的分页系统取决于是引用页面还是段。1MB和16MB段使用单级分页；4KB和16KB页面使用双级分页。ARM MMU的地址转换如下图所示</p>
<img src="https://raw.githubusercontent.com/BlackForest1990/Mypic/img/img/image-20240320114817563.png" alt="image-20240320114817563" style="zoom:50%;">
<p>ARM架构还支持两级TLB。外层有两个micro TLB，一个用于数据，另一个用于指令。micro TLB也支持ASIDs。内层是一个主TLB。地址转换从micro TLB级别开始。如果发生未命中，则会检查主TLB。如果两个TLB都未命中，则必须在硬件中执行页表遍历。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://blackforest1990.github.io">BlackForest1990</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blackforest1990.github.io/2024/03/19/mainmemory/">https://blackforest1990.github.io/2024/03/19/mainmemory/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blackforest1990.github.io" target="_blank">黑暗森林</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/">内存管理</a></div><div class="post_share"><div class="social-share" data-image="/image/blackforest.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>谢谢支持</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechatpay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechatpay.jpg"/></a><div class="post-qr-code-desc"></div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/03/21/Linux-Booting/" title="Linux Booting"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Linux Booting</div></div></a></div><div class="next-post pull-right"><a href="/2024/02/19/deadlock/" title="deadlock"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">deadlock</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/03/26/virtual-memory/" title="virtual memory"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="fas fa-history fa-fw"></i> 2024-03-31</div><div class="title">virtual memory</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">1.</span> <span class="toc-text">背景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E7%A1%AC%E4%BB%B6"><span class="toc-number">1.1.</span> <span class="toc-text">基本硬件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%B0%E5%9D%80%E7%BB%91%E5%AE%9A"><span class="toc-number">1.2.</span> <span class="toc-text">地址绑定</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E7%A9%BA%E9%97%B4%E4%B8%8E%E7%89%A9%E7%90%86%E7%A9%BA%E9%97%B4"><span class="toc-number">1.3.</span> <span class="toc-text">逻辑空间与物理空间</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD"><span class="toc-number">1.4.</span> <span class="toc-text">动态加载</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E5%92%8C%E5%85%B1%E4%BA%AB%E5%BA%93"><span class="toc-number">1.5.</span> <span class="toc-text">动态链接和共享库</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%A4%E6%8D%A2"><span class="toc-number">2.</span> <span class="toc-text">交换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%87%E5%87%86%E4%BA%A4%E6%8D%A2"><span class="toc-number">2.1.</span> <span class="toc-text">标准交换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A7%BB%E5%8A%A8%E7%B3%BB%E7%BB%9F%E4%BA%A4%E6%8D%A2"><span class="toc-number">2.2.</span> <span class="toc-text">移动系统交换</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9E%E7%BB%AD%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D"><span class="toc-number">3.</span> <span class="toc-text">连续内存分配</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E4%BF%9D%E6%8A%A4"><span class="toc-number">3.1.</span> <span class="toc-text">内存保护</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D"><span class="toc-number">3.2.</span> <span class="toc-text">内存分配</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%E5%8C%96"><span class="toc-number">3.3.</span> <span class="toc-text">内存碎片化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E6%AE%B5"><span class="toc-number">4.</span> <span class="toc-text">分段</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95"><span class="toc-number">4.1.</span> <span class="toc-text">基本方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Segmentation-Hardware"><span class="toc-number">4.2.</span> <span class="toc-text">Segmentation Hardware</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E9%A1%B5"><span class="toc-number">5.</span> <span class="toc-text">分页</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95-2"><span class="toc-number">5.1.</span> <span class="toc-text">基本方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A1%AC%E4%BB%B6%E6%94%AF%E6%8C%81"><span class="toc-number">5.2.</span> <span class="toc-text">硬件支持</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%9D%E6%8A%A4"><span class="toc-number">5.3.</span> <span class="toc-text">保护</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B1%E4%BA%AB%E9%A1%B5%E9%9D%A2"><span class="toc-number">5.4.</span> <span class="toc-text">共享页面</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%B5%E8%A1%A8%E7%BB%93%E6%9E%84"><span class="toc-number">6.</span> <span class="toc-text">页表结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B1%82%E9%A1%B5%E8%A1%A8"><span class="toc-number">6.1.</span> <span class="toc-text">分层页表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%88%E5%B8%8C%E9%A1%B5%E8%A1%A8"><span class="toc-number">6.2.</span> <span class="toc-text">哈希页表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%80%92%E7%BD%AE%E9%A1%B5%E8%A1%A8"><span class="toc-number">6.3.</span> <span class="toc-text">倒置页表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Oracle-SPARC-Solaris"><span class="toc-number">6.4.</span> <span class="toc-text">Oracle SPARC Solaris</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Example-Intel-32-and-64-bit-Architectures"><span class="toc-number">7.</span> <span class="toc-text">Example: Intel 32 and 64-bit Architectures</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#IA-32-%E7%B3%BB%E7%BB%9F"><span class="toc-number">7.1.</span> <span class="toc-text">IA-32 系统</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#IA-32-%E5%88%86%E6%AE%B5"><span class="toc-number">7.1.1.</span> <span class="toc-text">IA-32 分段</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#IA-32%E5%88%86%E9%A1%B5"><span class="toc-number">7.1.2.</span> <span class="toc-text">IA-32分页</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#x86-64"><span class="toc-number">7.2.</span> <span class="toc-text">x86-64</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Example-ARM-Architecture"><span class="toc-number">8.</span> <span class="toc-text">Example: ARM Architecture</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By BlackForest1990</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">如果只允许一种声音存在，那么，唯一存在的那个声音就是谎言。</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>